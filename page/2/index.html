<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover"><title>ZWN's blog</title><meta name="author" content="洛雪"><meta name="copyright" content="洛雪"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="我虽无意逐鹿，却知苍生苦楚"><meta property="og:type" content="website"><meta property="og:title" content="ZWN&#39;s blog"><meta property="og:url" content="https://zwn2001.space/page/2/index.html"><meta property="og:site_name" content="ZWN&#39;s blog"><meta property="og:description" content="我虽无意逐鹿，却知苍生苦楚"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://zwn2001.space/img/favicon.webp"><meta property="article:author" content="洛雪"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://zwn2001.space/img/favicon.webp"><link rel="shortcut icon" href="/img/favicon.webp"><link rel="canonical" href="https://zwn2001.space/page/2/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://unpkg.com/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://unpkg.com/@fancyapps/ui/dist/fancybox/fancybox.css" media="print" onload='this.media="all"'><script>const GLOBAL_CONFIG={root:"/",algolia:void 0,localSearch:{path:"/search.xml",preload:!0,top_n_per_article:-1,unescape:!1,languages:{hits_empty:"找不到您查询的内容：${query}",hits_stats:"共找到 ${hits} 篇文章"}},translate:{defaultEncoding:2,translateDelay:0,msgToTraditionalChinese:"繁",msgToSimplifiedChinese:"简"},noticeOutdate:{limitDay:200,position:"top",messagePrev:"距离上次更新已经过去",messageNext:"天啦！注意内容可能过时。"},highlight:{plugin:"highlighjs",highlightCopy:!0,highlightLang:!0,highlightHeightLimit:300},copy:{success:"复制成功",error:"复制错误",noSupport:"浏览器不支持"},relativeDate:{homepage:!1,post:!1},runtime:"天",dateSuffix:{just:"刚刚",min:"分钟前",hour:"小时前",day:"天前",month:"个月前"},copyright:void 0,lightbox:"fancybox",Snackbar:void 0,source:{justifiedGallery:{js:"https://unpkg.com/flickr-justified-gallery/dist/fjGallery.min.js",css:"https://unpkg.com/flickr-justified-gallery/dist/fjGallery.css"}},isPhotoFigcaption:!0,islazyload:!0,isAnchor:!0,percent:{toc:!0,rightside:!0},autoDarkmode:!1}</script><script id="config-diff">var GLOBAL_CONFIG_SITE={title:"ZWN's blog",isPost:!1,isHome:!0,isHighlightShrink:!1,isToc:!1,postUpdate:"2024-07-03 17:57:21"}</script><noscript><style type="text/css">#nav{opacity:1}.justified-gallery img{opacity:1}#post-meta time,#recent-posts time{display:inline!important}</style></noscript><script>(e=>{e.saveToLocal={set:function(e,t,a){0!==a&&(a=864e5*a,t={value:t,expiry:(new Date).getTime()+a},localStorage.setItem(e,JSON.stringify(t)))},get:function(e){var t=localStorage.getItem(e);if(t){t=JSON.parse(t);if(!((new Date).getTime()>t.expiry))return t.value;localStorage.removeItem(e)}}},e.getScript=o=>new Promise((t,e)=>{const a=document.createElement("script");a.src=o,a.async=!0,a.onerror=e,a.onload=a.onreadystatechange=function(){var e=this.readyState;e&&"loaded"!==e&&"complete"!==e||(a.onload=a.onreadystatechange=null,t())},document.head.appendChild(a)}),e.getCSS=(o,n=!1)=>new Promise((t,e)=>{const a=document.createElement("link");a.rel="stylesheet",a.href=o,n&&(a.id=n),a.onerror=e,a.onload=a.onreadystatechange=function(){var e=this.readyState;e&&"loaded"!==e&&"complete"!==e||(a.onload=a.onreadystatechange=null,t())},document.head.appendChild(a)}),e.activateDarkMode=function(){document.documentElement.setAttribute("data-theme","dark"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#0d0d0d")},e.activateLightMode=function(){document.documentElement.setAttribute("data-theme","light"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","ffffff")};e=saveToLocal.get("theme"),"dark"===e?activateDarkMode():"light"===e&&activateLightMode(),e=saveToLocal.get("aside-status");void 0!==e&&("hide"===e?document.documentElement.classList.add("hide-aside"):document.documentElement.classList.remove("hide-aside"));/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)&&document.documentElement.classList.add("apple")})(window)</script><link rel="stylesheet" href="/css/transpancy.css"><link rel="stylesheet" href="/css/iconfont.css"><link rel="stylesheet" href="/css/rightmenu.css"><link rel="stylesheet" href="/css/loadimg.css"><link rel="stylesheet" href="/css/project.css"><link type="text/html" rel="stylesheet" href="/css/wide_screen.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-double-row-display@1.00/cardlistpost.min.css"><style>#recent-posts>.recent-post-item>.recent-post-info>.article-meta-wrap>.tags:before{content:"\A";white-space:pre}#recent-posts>.recent-post-item>.recent-post-info>.article-meta-wrap>.tags>.article-meta__separator{display:none}</style><meta name="generator" content="Hexo 5.4.0"></head><body><div id="loading-box" onclick="document.getElementById(&quot;loading-box&quot;).classList.add(&quot;loaded&quot;)"><div class="loading-bg"><img class="loading-img nolazyload" src="/img/favicon.webp"><div class="loading-image-dot"></div><div id="loading-percentage"></div></div></div><script>const loadingPercentage=document.getElementById("loading-percentage");loadingPercentage.style.color="black";let loadingPercentageTimer=setInterval(function(){var e=document.querySelector(".pace-progress");e&&(e=e.getAttribute("data-progress-text"))!==loadingPercentage.textContent&&"60%"===(loadingPercentage.textContent=e)&&clearInterval(loadingPercentageTimer)},100);const preloader={endLoading:()=>{document.body.style.overflow="auto",document.getElementById("loading-box").classList.add("loaded")},initLoading:()=>{document.body.style.overflow="",document.getElementById("loading-box").classList.remove("loaded")}};window.addEventListener("load",()=>{preloader.endLoading()})</script><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/favicon.webp" onerror='onerror=null,src="/img/friend_404.gif"' alt="avatar"></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">142</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">46</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">9</div></a></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="page" id="body-wrap"><header class="full_page" id="page-header" style="background-image:url(/img/bg.webp)"><nav id="nav"><span id="blog-info"><a href="/" title="ZWN's blog"><span class="site-name">ZWN's blog</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);" rel="external nofollow noreferrer"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);" rel="external nofollow noreferrer"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="site-info"><h1 id="site-title">ZWN's blog</h1><div id="site-subtitle"><span id="subtitle"></span></div><div id="site_social_icons"><a class="social-icon" href="https://github.com/ZWN2001" rel="external nofollow noreferrer" target="_blank" title="Github"><i class="fab fa-github"></i></a></div></div><div id="scroll-down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="post_cover left"><a href="/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E4%BB%A3%E4%BB%B7%E6%95%8F%E6%84%9F%E5%AD%A6%E4%B9%A0/" title="机器学习-代价敏感学习"><img class="post-bg" src="/img/cover3/31.jpg" onerror='this.onerror=null,this.src="/img/404.webp"' alt="机器学习-代价敏感学习"></a></div><div class="recent-post-info"><a class="article-title" href="/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E4%BB%A3%E4%BB%B7%E6%95%8F%E6%84%9F%E5%AD%A6%E4%B9%A0/" title="机器学习-代价敏感学习">机器学习-代价敏感学习</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2023-03-15T13:10:02.000Z" title="发表于 2023-03-15 21:10:02">2023-03-15</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0-%E8%AF%BE%E5%86%85%E7%9F%A5%E8%AF%86/">学习-课内知识</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><div class="content">代价敏感学习 Background 传统学习中，我们的目标通常是错误率最低，这默认了不同错误分类的代价是一样的，但实际上很多情况下把positive判断为negative跟把把negative判断为positive的代价是不一样的。也就是说： 如果在学习时考虑错误分类的代价，那么我们就可以称之为是代价敏感学习。我们最终的目标也变成最小化总代价。 对于 K分类问题，我们有类似于如下的 K×KK\times KK×K 代价矩阵，C(i,j)C(i,j)C(i,j) 指的是将一个实际上属于 jjj 的样本分类为 iii 所带来的代价。 [C(1,1)C(1,2)...C(1,K)C(2,1)C(2,2)...C(2,K)⋮⋮⋱⋮C(K,1)C(K,2)...C(K,K)]\left[ \begin{matrix} C(1, 1) &amp; C(1, 2) &amp; ...&amp;C(1, K) \\ C(2, 1) &amp; C(2, 2) &amp; ...&amp;C(2, K) \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9%E5%92%8C%E7%89%B9%E5%BE%81%E6%8A%BD%E5%8F%96/" title="机器学习-特征选择和特征抽取"><img class="post-bg" src="/img/cover3/29.jpg" onerror='this.onerror=null,this.src="/img/404.webp"' alt="机器学习-特征选择和特征抽取"></a></div><div class="recent-post-info"><a class="article-title" href="/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9%E5%92%8C%E7%89%B9%E5%BE%81%E6%8A%BD%E5%8F%96/" title="机器学习-特征选择和特征抽取">机器学习-特征选择和特征抽取</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2023-03-14T13:10:02.000Z" title="发表于 2023-03-14 21:10:02">2023-03-14</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0-%E8%AF%BE%E5%86%85%E7%9F%A5%E8%AF%86/">学习-课内知识</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><div class="content">特征选择和特征抽取 特征选择和降维（特征提取）有着些许的相似点，这两者达到的效果是一样的，就是试图去减少特征数据集中的属性 (或者称为特征) 的数目；但是两者所采用的方式方法却不同：降维的方法主要是通过属性间的关系，如组合不同的属性得到新的属性，这样就改变了原来的特征空间；而特征选择的方法是从原始特征数据集中选择出子集，是一种包含的关系，没有更改原始的特征空间。 特征抽取（Feature Extraction）:Creatting a subset of new features by combinations of the exsiting features. 也就是说，特征抽取后的新特征是原来特征的一个映射。 特征选择（Feature Selection）:choosing a subset of all the features(the ones more informative)。也就是说，特征选择后的特征是原来特征的一个子集。   特征选择 我们希望获取尽可能小的特征子集，不显著降低分类精度、不影响分类分布以及特征子集应具有稳定、适应性强等特点。 为什么要做特征选择 在机 ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/" title="机器学习-半监督学习"><img class="post-bg" src="/img/cover2/11-min.jpg" onerror='this.onerror=null,this.src="/img/404.webp"' alt="机器学习-半监督学习"></a></div><div class="recent-post-info"><a class="article-title" href="/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/" title="机器学习-半监督学习">机器学习-半监督学习</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2023-03-13T13:10:02.000Z" title="发表于 2023-03-13 21:10:02">2023-03-13</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0-%E8%AF%BE%E5%86%85%E7%9F%A5%E8%AF%86/">学习-课内知识</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><div class="content">半监督学习 推荐 https://www.huaxiaozhuan.com/统计学习/chapters/12_semi_supervised.html ，太强了，太强了 啥是半监督学习（Semi-supervised Learning） 让学习器不依赖外界交互、自动地利用未标记样本来提升学习性能，就是半监督学习，现实生活中，我们很容易收集无标签数据，但有标签数据并不容易收集，所以我们需要一种模型，以少量标签数据作为参照，利用大量无标签数据进行训练，得到一个更高效的学习器。 也可以这样理解，半监督学习就是监督学习和无监督学习的折中版，而监督学习的核心就是回归，无监督学习的核心是分类，半监督学习一般的目标是找到一个函数迎合（也就是回归任务），然后用分类任务的信息去优化回归函数。 给定有标记样本集合 Dl={(x⃗1,y1),(x⃗2,y2),⋯ ,(x⃗l,yl)}\mathbb D_l=\{(\mathbf{\vec x}_1,y_1),(\mathbf{\vec x}_2,y_2),\cdots,(\mathbf{\vec x}_l,y_l)\}Dl​={(x1​,y1​), ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E8%81%9A%E7%B1%BB/" title="机器学习-聚类"><img class="post-bg" src="/img/cover3/34.jpg" onerror='this.onerror=null,this.src="/img/404.webp"' alt="机器学习-聚类"></a></div><div class="recent-post-info"><a class="article-title" href="/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E8%81%9A%E7%B1%BB/" title="机器学习-聚类">机器学习-聚类</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2023-03-12T13:10:02.000Z" title="发表于 2023-03-12 21:10:02">2023-03-12</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0-%E8%AF%BE%E5%86%85%E7%9F%A5%E8%AF%86/">学习-课内知识</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><div class="content">聚类 在无监督学习（unsupervised learning）中，训练样本的标记信息是未知的，学习的目的是揭示数据的内在性质及规律，为进一步的数据分析提供基础。这类学习任务中研究最多，应用最广的是聚类（clustering）。 这一章的内容大致如下： 聚类任务：聚类过程是怎样的？聚类有什么用途？聚类的两个基本问题是什么？ 性能度量：聚类的目标是什么？聚类性能度量的两大类指什么？各包含哪些度量指标？ 距离计算：距离度量需要满足哪些基本性质？怎样度量有序属性？怎样度量无序属性？相似度度量和距离度量有什么区别？ 原型聚类：什么是原型聚类？k均值算法是怎样的？学习向量量化算法是怎样的？高斯混合聚类是怎样的？ 密度聚类：什么是密度聚类？DBSCAN算法是怎样的？ 层次聚类：什么是层次聚类？AGNES算法是怎样的？ 聚类任务 聚类（clustering） 定义 聚类试图将数据集中的样本划分为若干个通常是不相交的子集，每个子集称为一个簇（cluster）。通常来说每个簇可能对应一些特征，比方说音乐可以聚类成古典音乐、摇滚乐、流行乐等等。但聚类过程仅产生簇结构，簇对应的概 ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/" title="机器学习-集成学习"><img class="post-bg" src="/img/cover1/15.jpg" onerror='this.onerror=null,this.src="/img/404.webp"' alt="机器学习-集成学习"></a></div><div class="recent-post-info"><a class="article-title" href="/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/" title="机器学习-集成学习">机器学习-集成学习</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2023-03-11T13:10:02.000Z" title="发表于 2023-03-11 21:10:02">2023-03-11</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0-%E8%AF%BE%E5%86%85%E7%9F%A5%E8%AF%86/">学习-课内知识</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><div class="content">集成学习 传统机器学习算法 (例如：决策树，人工神经网络，支持向量机，朴素贝叶斯等) 的目标都是寻找一个最优分类器尽可能的将训练数据分开。集成学习 (Ensemble Learning) 算法的基本思想就是将多个分类器组合，从而实现一个预测效果更好的集成分类器。集成算法可以说从一方面验证了中国的一句老话：三个臭皮匠，赛过诸葛亮。 Thomas G. Dietterich 指出了集成算法在统计，计算和表示上的有效原因： 统计上的原因 一个学习算法可以理解为在一个假设空间 H\mathcal HH 中选找到一个最好的假设。但是，当训练样本的数据量小到不够用来精确的学习到目标假设时，学习算法可以找到很多满足训练样本的分类器。所以，学习算法选择任何一个分类器都会面临一定错误分类的风险，因此将多个假设集成起来可以降低选择错误分类器的风险。 计算上的原因 很多学习算法在进行最优化搜索时很有可能陷入局部最优的错误中，因此对于学习算法而言很难得到一个全局最优的假设。事实上人工神经网络和决策树已经被证实为是一 个NP 问题。集成算法可以从多个起始点进行局部搜索，从而分散陷入局部最优的风险。 ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E5%A4%9A%E6%A0%87%E7%AD%BE%E5%AD%A6%E4%B9%A0/" title="机器学习-多标签学习"><img class="post-bg" src="/img/cover2/14-min.jpg" onerror='this.onerror=null,this.src="/img/404.webp"' alt="机器学习-多标签学习"></a></div><div class="recent-post-info"><a class="article-title" href="/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E5%A4%9A%E6%A0%87%E7%AD%BE%E5%AD%A6%E4%B9%A0/" title="机器学习-多标签学习">机器学习-多标签学习</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2023-03-10T13:10:02.000Z" title="发表于 2023-03-10 21:10:02">2023-03-10</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0-%E8%AF%BE%E5%86%85%E7%9F%A5%E8%AF%86/">学习-课内知识</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><div class="content">多标签学习 主要摘自http://palm.seu.edu.cn/zhangml/files/mla11-mll.pdf，部分参考https://link.springer.com/referenceworkentry/10.1007/978-1-4899-7687-1_910 推荐一篇知乎文章，也还不错，可惜我看到的时候笔记已经写完了。 Structure of Learning System 问题定义 X=Rd\mathcal{X} = \mathbb{R}^{d}X=Rd 表示 ddd 维的输入空间，Y={y1,y2,…,yq}\mathcal{Y} =\{ y_{1},y_{2},\ldots,y_{q}\}Y={y1​,y2​,…,yq​} 表示带有 qqq 个可能标签的标签空间。 训练集 D={(xi,Yi)∣1≤i≤m}\mathcal{D} =\{ (\boldsymbol{x}_{i},Y _{i})\mid 1 \leq i \leq m\}D={(xi​,Yi​)∣1≤i≤m} ，mmm 表示训练集的大小，有时候会省略。 任务就是要学习一个多标签分类器 h:X↦ ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/" title="机器学习-强化学习"><img class="post-bg" src="/img/cover3/12-min.jpg" onerror='this.onerror=null,this.src="/img/404.webp"' alt="机器学习-强化学习"></a></div><div class="recent-post-info"><a class="article-title" href="/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/" title="机器学习-强化学习">机器学习-强化学习</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2023-03-09T13:10:02.000Z" title="发表于 2023-03-09 21:10:02">2023-03-09</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0-%E8%AF%BE%E5%86%85%E7%9F%A5%E8%AF%86/">学习-课内知识</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><div class="content">强化学习 强化学习的主要任务就是通过在环境中不断地尝试，根据尝试获得的反馈信息调整策略，最终生成一个较好的策略π，机器根据这个策略便能知道在什么状态下应该执行什么动作。 我觉得比较重要的几个观点： RL is learning from trial and error interaction with the world. RL is training by rewards and punishments. 增强学习的研究建立在经典物理学的范畴上，也就是没有量子计算也没有相对论。这个世界的时间是可以分割成一个一个时间片的，并且有完全的先后顺序，因此可以形成这样的状态，动作和反馈系列。这些数据样本是进行增强学习的基础。 另一个很重要的假设就是 「上帝不掷筛子！」 在增强学习的世界，我们相信如果输入是确定的，那么输出也一定是确定的。试想一下，有一个机械臂在练习掷筛子，以掷出 6 点作为目标。但是如果无论机械臂如何调整其关节的角度及扭矩，掷出的点数永远是随机的，那么无论如何也不可能通过算法使机械臂达成目标。因此，增强学习算法要有用，就是相信在增强学习中每一次参数的调整都会对世界造成确定性的 ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" title="机器学习-神经网络"><img class="post-bg" src="/img/cover3/24-min.jpg" onerror='this.onerror=null,this.src="/img/404.webp"' alt="机器学习-神经网络"></a></div><div class="recent-post-info"><a class="article-title" href="/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" title="机器学习-神经网络">机器学习-神经网络</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2023-03-08T13:10:02.000Z" title="发表于 2023-03-08 21:10:02">2023-03-08</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0-%E8%AF%BE%E5%86%85%E7%9F%A5%E8%AF%86/">学习-课内知识</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><div class="content">神经网络 在机器学习中，神经网络（neural networks）一般是指“神经网络学习”。所谓神经网络，目前用得最广泛的一个定义是“神经网络是由具有适应性的简单单元组成的广泛并行互连的网络，它的组织能够模拟生物神经系统对真实世界物体所做出的反应”。它是一种黑箱模型，解释性较差，但效果很好。目前已有一些工作尝试改善神经网络的可解释性。 这一章的内容大致如下： 神经元模型：什么是神经元模型？它的构造是怎样的？激活函数是什么？如何组建神经网络？ 感知机与多层网络：感知机的构造是怎样的？感知机不能解决什么问题？多层网络是怎样的？多层前馈神经网络有什么特点？ 误差逆传播算法：BP算法如何调整参数？有什么值得注意的地方？标准BP算法和累积BP算法有什么区别？如何设置隐层神经元的个数？如何处理BP神经网络的过拟合问题？ 全局最小与局部极小：什么是全局最小？什么是局部极小？如何跳出局部极小？ 其他常见神经网络：有哪些常见的神经网络？它们各自有什么特点？什么是竞争型学习？可塑性、稳定性、增量学习、在线学习各指什么？（没讲） 深度学习：深度学习是如何提升模型容量的？如何训练深度神经网络？怎么理解深度学 ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/" title="机器学习-线性模型"><img class="post-bg" src="/img/cover1/13.jpg" onerror='this.onerror=null,this.src="/img/404.webp"' alt="机器学习-线性模型"></a></div><div class="recent-post-info"><a class="article-title" href="/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/" title="机器学习-线性模型">机器学习-线性模型</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2023-03-07T13:10:02.000Z" title="发表于 2023-03-07 21:10:02">2023-03-07</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0-%E8%AF%BE%E5%86%85%E7%9F%A5%E8%AF%86/">学习-课内知识</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><div class="content">线性模型 给定一个包含d个属性的实例 令梯度为零可以得到x=(x1;x2;...;xd)令梯度为零可以得到\mathbf{x} = (x_1;x_2;...;x_d)令梯度为零可以得到x=(x1​;x2​;...;xd​)，线性模型（linear model）的原理是学得一个可以通过属性的线性组合来进行预测的函数，也即： f(x)=w1x1+w2x2+...+wdxx+bf(x) = w_1x_1 + w_2x_2 + ... + w_dx_x + b f(x)=w1​x1​+w2​x2​+...+wd​xx​+b 一般写作向量形式：f(x)=wTx+bf(x) = w^Tx + bf(x)=wTx+b。其中权重向量 www和偏置项 bbb就是我们需要学习的参数。 线性模型有良好的可解释性，每个属性对应的权重可以理解为它对预测的重要性。并且建模较为简单，许多功能更为强大的非线性模型都是在线性模型的基础上引入层级结构或高维映射得到的。   线性回归 离散属性连续化 由于不同模型对数据的要求不一样，在建模之前，我们需要对数据做相应的处理。一般的线性回归模型要求属性的数据类型为连续值，故需要 ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-KNN/" title="机器学习-KNN"><img class="post-bg" src="/img/cover2/20-min.jpg" onerror='this.onerror=null,this.src="/img/404.webp"' alt="机器学习-KNN"></a></div><div class="recent-post-info"><a class="article-title" href="/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-KNN/" title="机器学习-KNN">机器学习-KNN</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2023-03-06T13:10:02.000Z" title="发表于 2023-03-06 21:10:02">2023-03-06</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0-%E8%AF%BE%E5%86%85%E7%9F%A5%E8%AF%86/">学习-课内知识</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><div class="content">KNN KNN简介 KNN的原理就是当预测一个新的值x的时候，根据它距离最近的K个点是什么类别来判断x属于哪个类别。 思路是：如果一个样本在特征空间中的k个最邻近的样本中的大多数属于某一个类别，则该样本也划分为这个类别。 KNN算法中，所选择的邻居都是已经正确分类的对象。该方法在定类决策上只依据最邻近的一个或者几个样本的类别来决定待分样本所属的类别。 该算法假定所有的实例对应于N维欧式空间 A^nÂ_nA^n​ 中的点。通过计算一个点与其他所有点之间的距离，取出与该点最近的K个点，然后统计这K个点里面所属分类比例最大的，则这个点属于该分类。 该算法涉及3个主要因素：实例集、距离或相似的衡量、k的大小。 一个实例的最近邻是根据标准欧氏距离定义的。更精确地讲，把任意的实例x表示为下面的特征向量： &lt;a1(x)，a2(x)，...，an(x)&gt;&lt;a_1(x)，a_2(x)，...，a_n(x)&gt; &lt;a1​(x)，a2​(x)，...，an​(x)&gt; 其中 ar(x)a_r(x)ar​(x) 表示实例 xxx 的第 rrr 个属性值。那么两个实例 xix_i ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-SVM/" title="机器学习-SVM"><img class="post-bg" src="/img/cover2/3-min.jpg" onerror='this.onerror=null,this.src="/img/404.webp"' alt="机器学习-SVM"></a></div><div class="recent-post-info"><a class="article-title" href="/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-SVM/" title="机器学习-SVM">机器学习-SVM</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2023-03-05T13:10:02.000Z" title="发表于 2023-03-05 21:10:02">2023-03-05</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0-%E8%AF%BE%E5%86%85%E7%9F%A5%E8%AF%86/">学习-课内知识</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><div class="content">SVM 很多摘自 https://tangshusen.me/2018/10/27/SVM/ 后期整合其他博客与学校课程PPT SVM是什么 支持向量机（英语：support vector machine，常简称为SVM，又名支持向量网络）是在分类与回归分析中分析数据的监督式学习模型与相关的学习算法。给定一组训练实例，每个训练实例被标记为属于两日函数求导并令导数个类别中的一个或另一个，SVM训练算法创建一个将新的实例分配给两个类别之一的模型，使其成为非概率二元线性分类器。SVM模型是将实例表示为空间中的点，这样映射就使得单独类别的实例被尽可能宽的明显的间隔分开。然后，将新的实例映射到同一空间，并基于它们落在间隔的哪一侧来预测所属类别。 简单点讲，SVM就是一种二类分类模型，他的基本模型是的定义在特征空间上的间隔最大的线性分类器，SVM的学习策略就是间隔最大化。 直观理解 我们先来看看下面这个图 图中有分别属于两类的一些二维数据点和三条直线。如果三条直线分别代表三个分类器的话，请问哪一个分类器比较好？ 我们凭直观感受应该觉得答案是H3。首先H1不能把类别分开，这个分类器肯定是不行的 ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E5%86%B3%E7%AD%96%E6%A0%91/" title="机器学习-决策树"><img class="post-bg" src="/img/cover2/22-min.jpg" onerror='this.onerror=null,this.src="/img/404.webp"' alt="机器学习-决策树"></a></div><div class="recent-post-info"><a class="article-title" href="/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E5%86%B3%E7%AD%96%E6%A0%91/" title="机器学习-决策树">机器学习-决策树</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2023-03-04T13:10:02.000Z" title="发表于 2023-03-04 21:10:02">2023-03-04</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0-%E8%AF%BE%E5%86%85%E7%9F%A5%E8%AF%86/">学习-课内知识</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><div class="content">决策树 这一章的内容大致如下： 基本流程：决策树是如何决策的？决策树学习的目的是什么？如何生成一颗决策树？ 划分选择：怎样选择最优划分属性？有哪些判断指标？具体是怎样运作的？ 剪枝处理：为什么要剪枝？如何判断剪枝后决策树模型的泛化性能是否提升？预剪枝和后剪枝是怎样工作的？有什么优缺点？ 连续与缺失值：如何把连续属性离散化？如何基于离散化后的属性进行划分？和离散属性有何不同？如何在属性值缺失的情况下选择最优划分属性？给定划分属性，如何划分缺失该属性值的样本？ 多变量决策树：决策树模型的分类边界的特点是怎样的？多变量决策数是如何定义的？又是如何工作的？   基本流程 决策树（decision tree）是一种模仿人类决策的学习方法。举个例子，比方说买电脑，我们首先看看外观帅不帅气，然后再看看性能怎么样，还得看看价格如何，最终经过一系列的判断做出是否购买电脑的决策。 一棵决策树可以分成三个部分：叶节点，非叶节点，分支。叶节点对应决策结果，也即分类任务中的类别标记；非叶节点（包括根节点）对应一个判定问题（某属性=？）；分支对应父节点判定问题的不同答案（可能的属性值），可 ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8/" title="机器学习-贝叶斯分类器"><img class="post-bg" src="/img/cover3/6-min.jpg" onerror='this.onerror=null,this.src="/img/404.webp"' alt="机器学习-贝叶斯分类器"></a></div><div class="recent-post-info"><a class="article-title" href="/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8/" title="机器学习-贝叶斯分类器">机器学习-贝叶斯分类器</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2023-03-03T13:10:02.000Z" title="发表于 2023-03-03 21:10:02">2023-03-03</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0-%E8%AF%BE%E5%86%85%E7%9F%A5%E8%AF%86/">学习-课内知识</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><div class="content">贝叶斯分类器 基础知识：什么是贝叶斯定理 这现实生活中的问题，大部分都是“逆概率”问题。因为生活中绝大多数决策面临的信息都是不全的，我们手中只有有限的信息。既然无法得到全面的信息，我们就只能在信息有限的情况下，尽可能做出一个好的预测。 比如天气预报说，明天降雨的概率是30%，这是什么意思呢？我们无法像计算频率概率那样，重复地把明天过上100次，然后计算出大约有30次会下雨（下雨的天数/总天数），而是只能利用有限的信息（过去天气的测量数据），用贝叶斯定理来预测出明天下雨的概率是多少。 同样的，在现实世界中，我们每个人都需要预测。想要深入分析未来、思考是否买股票、政策给自己带来哪些机遇、提出新产品构想，或者只是计划一周的饭菜。 贝叶斯定理就是为了解决这些问题而诞生的，它可以根据过去的数据来预测出未来事情发生概率。贝叶斯定理的思考方式为我们提供了有效的方法来帮助我们做决策，以便更好地预测未来的商业、金融、以及日常生活。 贝叶斯定理： P(A∣B)=P(A)P(B∣A)P(B)P(A|B)=P(A)\dfrac{P(B|A)}{P(B)} P(A∣B)=P(A)P(B)P(B∣A)​ 比如我经 ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E4%B8%8E%E9%80%89%E6%8B%A9/" title="机器学习-模型评估与选择"><img class="post-bg" src="/img/cover2/19-min.jpg" onerror='this.onerror=null,this.src="/img/404.webp"' alt="机器学习-模型评估与选择"></a></div><div class="recent-post-info"><a class="article-title" href="/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E4%B8%8E%E9%80%89%E6%8B%A9/" title="机器学习-模型评估与选择">机器学习-模型评估与选择</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2023-03-02T13:10:02.000Z" title="发表于 2023-03-02 21:10:02">2023-03-02</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0-%E8%AF%BE%E5%86%85%E7%9F%A5%E8%AF%86/">学习-课内知识</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><div class="content">模型评估与选择 误差 在分类任务中，通常把错分的样本数占样本总数的比例称为错误率（error rate）。比如m个样本有a个预测错了，错误率就是a/m；与错误率相对的有精度（accuracy），或者说正确率，数值上等于 1−错误率1-错误率1−错误率。 更一般地，通常会把模型输出和真实值之间的差异称为误差（error）。在训练集上的误差称为训练误差（training error）或者经验误差（empirical error）。而在新样本上的误差则称为泛化误差（generalization error）。我们希望模型的泛化误差尽可能小，但现实是，我们无法知道新样本是怎样的，所以只能尽可能地利用训练数据来最小化经验误差。 但是否经验误差小，泛化误差就一定小呢？这不是一定的，如果模型相比训练数据来说过于复杂，那就很有可能把训练数据本身的一些特点当作整个样本空间的特点，从而使得在训练数据上有很小的经验误差，但一旦面对新样本就会有很大误差，这种情况叫做过拟合（overfitting）。相对的是欠拟合（underfitting）。 欠拟合很容易避免，只要适当地增加模型复杂度（比方说增加神经网络的层 ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%BB%AA%E8%AE%BA/" title="机器学习-绪论"><img class="post-bg" src="/img/cover2/16-min.jpg" onerror='this.onerror=null,this.src="/img/404.webp"' alt="机器学习-绪论"></a></div><div class="recent-post-info"><a class="article-title" href="/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%BB%AA%E8%AE%BA/" title="机器学习-绪论">机器学习-绪论</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2023-03-01T13:10:02.000Z" title="发表于 2023-03-01 21:10:02">2023-03-01</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0-%E8%AF%BE%E5%86%85%E7%9F%A5%E8%AF%86/">学习-课内知识</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><div class="content">绪论 机器学习的定义 人可以通过经验学习，比方说“朝霞不出门，晚霞行千里”，就是通过经验得来的知识。获得知识后，即使在不同的地点，不同的时间，看到不同的霞，我们也能作出正确的判断。那么，机器是否也能学习并利用经验，从而对一些未出现过的情况，在不通过显式编程（人作出判断并告诉机器）的情况下也能作出正确的预测呢？答案是可以的，这就是机器学习。 对于机器来说，经验是通过数据传达的。机器学习的主要研究内容就是从数据中产生模型的算法，也即学习算法。Mitchell给出一个更为形式化的定义，假设我们用P来表示程序处理任务T时的性能，如果程序通过利用经验E提高了在任务T上的性能，则称该程序对E进行了学习。 在本书中，模型泛指所有从数据中学得的结果，在别的文献中，也有对模型和模式作出区分的，模型指学得的全局性结果（比如一棵决策树），模式指学得的局部性结果（比如一条规则）。 另一本经典教材的作者Mitchell给出了一个形式化的定义，假设： P：计算机程序在某任务类T上的性能。 T：计算机程序希望实现的任务类。 E：表示经验，即历史的数据集。 若该计算机程序通过利用经验E在任务T上获得了性能P的改善 ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/posts/How-To-Use-Hexo/" title="How-To-Use-Hexo Hexo建站小教程"><img class="post-bg" src="/img/cover1/2.jpg" onerror='this.onerror=null,this.src="/img/404.webp"' alt="How-To-Use-Hexo Hexo建站小教程"></a></div><div class="recent-post-info"><a class="article-title" href="/posts/How-To-Use-Hexo/" title="How-To-Use-Hexo Hexo建站小教程">How-To-Use-Hexo Hexo建站小教程</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2023-02-20T01:07:21.000Z" title="发表于 2023-02-20 09:07:21">2023-02-20</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AE%9E%E7%94%A8%E7%9F%A5%E8%AF%86/">实用知识</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E8%BD%AC%E8%BD%BD%E4%B8%8E%E6%B1%87%E6%80%BB/">转载与汇总</a><span class="article-meta-link">•</span><a class="article-meta__tags" href="/tags/Hexo/">Hexo</a></span></div><div class="content">How To Use Hexo：Hexo建站小教程 使用Hexo 安装Git Git是一个开源的分布式版本控制系统，可以有效、高速地处理从很小到非常大的项目版本管理，帮助我们把本地网页上传到Github。 win版本点击此处进入Git官网下载相应版本，默认安装即可。 参考资料：《如何在windows下安装GIT》 (By 俊雨廷休) 检验是否安装成功：cmd中输入并回车 1git --version 出现git版本即为成功。   Github 如果没有，点击此处进入Github官网点击 Sign Up 注册账户。 创建git仓库 登录Github创建一个仓库 如下图所示，输入自己的项目名字，后面一定要加.github.io后缀，README初始化也要勾上。名称一定要和你的Github名字完全一样，比如你github名字叫A，那么仓库名字一定要是A.github.io。 连接Github与本地 右键单击鼠标，点击 Git Bash Here输入以下命令： 12git config --global user.name &quot;Name&quot;git config --gl ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/posts/Covariant-Contravariant-and-Invariant/" title="协变 (Covariant)、逆变 (Contravariant) 与抗变 (Invariant)"><img class="post-bg" src="/img/cover3/26.jpg" onerror='this.onerror=null,this.src="/img/404.webp"' alt="协变 (Covariant)、逆变 (Contravariant) 与抗变 (Invariant)"></a></div><div class="recent-post-info"><a class="article-title" href="/posts/Covariant-Contravariant-and-Invariant/" title="协变 (Covariant)、逆变 (Contravariant) 与抗变 (Invariant)">协变 (Covariant)、逆变 (Contravariant) 与抗变 (Invariant)</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2023-01-26T09:00:06.000Z" title="发表于 2023-01-26 17:00:06">2023-01-26</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0-%E8%AF%BE%E5%A4%96%E6%8B%93%E5%B1%95/">学习-课外拓展</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/">面向对象</a></span></div><div class="content">协变 (Covariant)、逆变 (Contravariant) 与抗变 (Invariant) 定义 我们会记起里氏替换原则，对于任意类型关系而言，子类型可以胜任父类型的任何场景。   数组情况 以数组为例，我们有Animal以及继承自Animal 的 Cat和Dag。 协变：一个List&lt;Cat&gt;也是一个List&lt;Animal&gt; 逆变：一个List&lt;Animal&gt;也是一个List&lt;Cat&gt; 以上二者均不是则为不变 如果要避免类型错误，且数组支持对其元素的读、写操作，那么只有第3个选择是安全的。List&lt;Animal&gt;并不是总能当作List&lt;Cat&gt;，因为当一个客户读取数组并期望得到一个Cat，但List&lt;Animal&gt;中包含的可能是个Dog。所以逆变规则是不安全的。 反之，一个List&lt;Cat&gt;也不能被当作一个List&lt;Animal&gt;。因为总是可以把一个Dog放到List&lt;Animal&gt;中，也就是说，我们可能尝试将Dog写入这个被当做List&lt;Anim ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/posts/OS%E8%AF%BE%E8%AE%BE/" title="OS课设"><img class="post-bg" src="/img/cover2/24-min.jpg" onerror='this.onerror=null,this.src="/img/404.webp"' alt="OS课设"></a></div><div class="recent-post-info"><a class="article-title" href="/posts/OS%E8%AF%BE%E8%AE%BE/" title="OS课设">OS课设</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2023-01-09T08:33:36.000Z" title="发表于 2023-01-09 16:33:36">2023-01-09</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0-%E8%AF%BE%E5%86%85%E7%9F%A5%E8%AF%86/">学习-课内知识</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/">操作系统</a></span></div><div class="content">大水老师，老师人超级好，97 OS课设 环境配置 老师给了安装教程PPT，并不麻烦。 在apt install前，确认你的虚拟机网络可用。 关于虚拟机的网络配置，我参考了https://zhuanlan.zhihu.com/p/130984945，整个教程我也复制整理了一遍放在文末。 Linux下使用CLion进行Debug 首先打开项目：将以下两个Makefile进行Associte With File Type，定义为GNU MakeFile文件，记得定义第一行匹配模式。完成后： MakeFile.common中会报错，将如下冒号替换成空格： 然后打开具体的lab文件夹，会发现有报错，在Seetings中找到MakeFile，删掉Build target的all，选OK即可。 对于Configurations： 然后就可以打断点用debug模式运行了。   Lab1：Road Map Through Nachos 1234567891011121314151617181920212223242526272829303132333435363738394041424344 ...</div></div></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/"><i class="fas fa-chevron-left fa-fw"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/#content-inner">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/8/#content-inner">8</a><a class="extend next" rel="next" href="/page/3/#content-inner"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/favicon.webp" onerror='this.onerror=null,this.src="/img/friend_404.gif"' alt="avatar"></div><div class="author-info__name">洛雪</div><div class="author-info__description">我虽无意逐鹿，却知苍生苦楚</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">142</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">46</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">9</div></a></div><a id="card-info-btn" target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/ZWN2001"><i class="fab fa-github"></i><span>我的Github</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/ZWN2001" rel="external nofollow noreferrer" target="_blank" title="Github"><i class="fab fa-github"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">新域名：www.zwn2001.space，有效期：10年。https://www.zwn-blog.xyz已过期。访问时建议科学上网，否则博客内公式渲染会出现问题且速度慢。Ctrl+shift+r可强制刷新网站以避免浏览器缓存造成的更新不及时</div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/posts/%E5%90%B4%E6%81%A9%E8%BE%BEDL-Note/" title="吴恩达深度学习课程学习与笔记汇编"><img src="/img/cover3/6-min.jpg" onerror='this.onerror=null,this.src="/img/404.webp"' alt="吴恩达深度学习课程学习与笔记汇编"></a><div class="content"><a class="title" href="/posts/%E5%90%B4%E6%81%A9%E8%BE%BEDL-Note/" title="吴恩达深度学习课程学习与笔记汇编">吴恩达深度学习课程学习与笔记汇编</a><time datetime="2024-06-08T00:23:35.000Z" title="发表于 2024-06-08 08:23:35">2024-06-08</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/2024%E6%AF%95%E4%B8%9A%E7%94%9F%E7%BB%8F%E9%AA%8C%E5%88%86%E4%BA%AB%E4%BC%9A/" title="2024毕业生经验分享会"><img src="/img/cover3/21-min.jpg" onerror='this.onerror=null,this.src="/img/404.webp"' alt="2024毕业生经验分享会"></a><div class="content"><a class="title" href="/posts/2024%E6%AF%95%E4%B8%9A%E7%94%9F%E7%BB%8F%E9%AA%8C%E5%88%86%E4%BA%AB%E4%BC%9A/" title="2024毕业生经验分享会">2024毕业生经验分享会</a><time datetime="2024-05-09T05:52:03.000Z" title="发表于 2024-05-09 13:52:03">2024-05-09</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/2024BUAA%E8%BD%AF%E9%99%A2%E4%B8%93%E7%A1%95%E8%80%83%E7%A0%94tips/" title="2024BUAA软院专硕考研tips"><img src="/img/cover3/4-min.jpg" onerror='this.onerror=null,this.src="/img/404.webp"' alt="2024BUAA软院专硕考研tips"></a><div class="content"><a class="title" href="/posts/2024BUAA%E8%BD%AF%E9%99%A2%E4%B8%93%E7%A1%95%E8%80%83%E7%A0%94tips/" title="2024BUAA软院专硕考研tips">2024BUAA软院专硕考研tips</a><time datetime="2024-04-01T06:00:53.000Z" title="发表于 2024-04-01 14:00:53">2024-04-01</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/2024BUAA%E5%A4%8D%E8%AF%95%E4%B8%93%E4%B8%9A%E8%AF%BE%E6%8B%BE%E9%81%97/" title="BUAA复试专业课拾遗"><img src="/img/cover1/35.jpg" onerror='this.onerror=null,this.src="/img/404.webp"' alt="BUAA复试专业课拾遗"></a><div class="content"><a class="title" href="/posts/2024BUAA%E5%A4%8D%E8%AF%95%E4%B8%93%E4%B8%9A%E8%AF%BE%E6%8B%BE%E9%81%97/" title="BUAA复试专业课拾遗">BUAA复试专业课拾遗</a><time datetime="2024-04-01T06:00:52.000Z" title="发表于 2024-04-01 14:00:52">2024-04-01</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/24%E6%98%A5%E6%8B%9B%E9%9D%A2%E7%BB%8F/" title="24春招面经"><img src="/img/cover3/7-min.jpg" onerror='this.onerror=null,this.src="/img/404.webp"' alt="24春招面经"></a><div class="content"><a class="title" href="/posts/24%E6%98%A5%E6%8B%9B%E9%9D%A2%E7%BB%8F/" title="24春招面经">24春招面经</a><time datetime="2024-03-12T08:35:23.000Z" title="发表于 2024-03-12 16:35:23">2024-03-12</time></div></div></div></div><div class="card-widget card-categories"><div class="item-headline"><i class="fas fa-folder-open"></i> <span>分类</span></div><ul class="card-category-list" id="aside-cat-list"><li class="card-category-list-item"><a class="card-category-list-link" href="/categories/%E5%AD%A6%E4%B9%A0-%E8%AF%BE%E5%86%85%E7%9F%A5%E8%AF%86/"><span class="card-category-list-name">学习-课内知识</span><span class="card-category-list-count">56</span></a></li><li class="card-category-list-item"><a class="card-category-list-link" href="/categories/%E5%AD%A6%E4%B9%A0-%E8%AF%BE%E5%A4%96%E6%8B%93%E5%B1%95/"><span class="card-category-list-name">学习-课外拓展</span><span class="card-category-list-count">20</span></a></li><li class="card-category-list-item"><a class="card-category-list-link" href="/categories/%E5%AD%A6%E7%BA%BF%E5%9F%B9%E8%AE%AD/"><span class="card-category-list-name">学线培训</span><span class="card-category-list-count">14</span></a></li><li class="card-category-list-item"><a class="card-category-list-link" href="/categories/%E5%AE%9E%E7%94%A8%E7%9F%A5%E8%AF%86/"><span class="card-category-list-name">实用知识</span><span class="card-category-list-count">14</span></a></li><li class="card-category-list-item"><a class="card-category-list-link" href="/categories/%E6%9D%82%E8%AE%B0/"><span class="card-category-list-name">杂记</span><span class="card-category-list-count">11</span></a></li><li class="card-category-list-item"><a class="card-category-list-link" href="/categories/%E7%BC%96%E7%A8%8B%E7%9F%A5%E8%AF%86/"><span class="card-category-list-name">编程知识</span><span class="card-category-list-count">17</span></a></li><li class="card-category-list-item"><a class="card-category-list-link" href="/categories/%E8%AF%BE%E5%A4%96%E6%8B%93%E5%B1%95/"><span class="card-category-list-name">课外拓展</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item"><a class="card-category-list-link" href="/categories/%E8%AF%BE%E5%A4%96%E7%9F%A5%E8%AF%86/"><span class="card-category-list-name">课外知识</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item"><a class="card-category-list-link" href="/categories/%E9%A1%B9%E7%9B%AE%E6%80%9D%E8%B7%AF%E3%80%81%E7%AE%97%E6%B3%95/"><span class="card-category-list-name">项目思路、算法</span><span class="card-category-list-count">7</span></a></li></ul></div><div class="card-widget card-tags"><div class="item-headline"><i class="fas fa-tags"></i><span>标签</span></div><div class="card-tag-cloud"><a href="/tags/%E6%97%A5%E5%B8%B8/" style="font-size:1.18em;color:#b20a3d">日常</a><a href="/tags/%E8%80%83%E7%A0%94/" style="font-size:1.18em;color:#7b05c0">考研</a><a href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/" style="font-size:1.21em;color:#bca305">数据库系统设计</a><a href="/tags/%E6%9D%82%E8%AE%B0/" style="font-size:1.24em;color:#41632a">杂记</a><a href="/tags/%E5%B7%A5%E4%BD%9C/" style="font-size:1.15em;color:#0724b0">工作</a><a href="/tags/%E7%AE%97%E6%B3%95/" style="font-size:1.21em;color:#ad223b">算法</a><a href="/tags/%E8%B8%A9%E5%9D%91/" style="font-size:1.15em;color:#9b49a4">踩坑</a><a href="/tags/%E8%BD%AC%E8%BD%BD%E4%B8%8E%E6%B1%87%E6%80%BB/" style="font-size:1.45em;color:#4a4872">转载与汇总</a><a href="/tags/java%E5%B9%B6%E5%8F%91/" style="font-size:1.18em;color:#1549c6">java并发</a><a href="/tags/flutter/" style="font-size:1.39em;color:#39b359">flutter</a><a href="/tags/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/" style="font-size:1.27em;color:#224c75">面向对象</a><a href="/tags/git/" style="font-size:1.21em;color:#70311e">git</a><a href="/tags/CSharp/" style="font-size:1.15em;color:#027171">CSharp</a><a href="/tags/Hexo/" style="font-size:1.15em;color:#05c501">Hexo</a><a href="/tags/Linux/" style="font-size:1.15em;color:#119154">Linux</a><a href="/tags/Python/" style="font-size:1.3em;color:#9e55c7">Python</a><a href="/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/" style="font-size:1.33em;color:#c73d5f">操作系统</a><a href="/tags/SDU%E9%80%89%E8%AF%BE/" style="font-size:1.15em;color:#207c9d">SDU选课</a><a href="/tags/c/" style="font-size:1.15em;color:#b48ea2">c++</a><a href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F%E6%A6%82%E5%BF%B5/" style="font-size:1.33em;color:#a4a379">数据库系统概念</a><a href="/tags/%E5%AD%A6%E7%BA%BF%E5%9F%B9%E8%AE%AD/" style="font-size:1.18em;color:#57b36e">学线培训</a><a href="/tags/i%E5%B1%B1%E5%A4%A7/" style="font-size:1.15em;color:#c26e55">i山大</a><a href="/tags/%E7%A7%BB%E5%8A%A8/" style="font-size:1.36em;color:#5b0927">移动</a><a href="/tags/opencv/" style="font-size:1.18em;color:#29b908">opencv</a><a href="/tags/%E4%BC%97%E6%99%BA/" style="font-size:1.21em;color:#3a33b3">众智</a><a href="/tags/%E5%90%8E%E7%AB%AF/" style="font-size:1.24em;color:#9854ad">后端</a><a href="/tags/%E8%AE%A1%E7%BB%84%E8%AF%BE%E8%AE%BE/" style="font-size:1.15em;color:#abb12c">计组课设</a><a href="/tags/oj/" style="font-size:1.15em;color:#bbb237">oj</a><a href="/tags/%E8%AE%A1%E7%BD%91/" style="font-size:1.21em;color:#88bc77">计网</a><a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" style="font-size:1.15em;color:#6c1fa4">深度学习</a><a href="/tags/HSD/" style="font-size:1.15em;color:#270b74">HSD</a><a href="/tags/%E6%9E%B6%E6%9E%84/" style="font-size:1.15em;color:#833731">架构</a><a href="/tags/%E5%AE%A2%E5%88%B6%E5%8C%96%E9%94%AE%E7%9B%98/" style="font-size:1.15em;color:#0e44a1">客制化键盘</a><a href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" style="font-size:1.24em;color:#8b486a">数据结构</a><a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" style="font-size:1.42em;color:#5b6153">机器学习</a><a href="/tags/%E6%9C%8D%E5%8A%A1%E5%BC%80%E5%8F%91/" style="font-size:1.15em;color:#333e3f">服务开发</a><a href="/tags/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/" style="font-size:1.15em;color:#044ec5">正则表达式</a><a href="/tags/%E7%A6%BB%E6%95%A3/" style="font-size:1.21em;color:#a20a3f">离散</a><a href="/tags/%E6%AF%95%E8%AE%BE/" style="font-size:1.15em;color:#967432">毕设</a><a href="/tags/%E5%AD%A6%E4%B9%A0/" style="font-size:1.15em;color:#3081a6">学习</a><a href="/tags/%E5%AE%89%E5%8D%93/" style="font-size:1.21em;color:#6377b9">安卓</a><a href="/tags/%E5%AE%89%E5%8D%93%E5%8E%9F%E7%94%9F/" style="font-size:1.15em;color:#8ac847">安卓原生</a><a href="/tags/%E5%89%8D%E7%AB%AF/" style="font-size:1.15em;color:#4ea14f">前端</a><a href="/tags/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/" style="font-size:1.15em;color:#5a92b1">编译原理</a><a href="/tags/%E5%A4%A7%E8%8B%B1/" style="font-size:1.18em;color:#a37b7e">大英</a><a href="/tags/%E8%AE%BE%E8%AE%A1%E7%90%86%E5%BF%B5/" style="font-size:1.15em;color:#4ea845">设计理念</a></div></div><div class="card-widget card-archives"><div class="item-headline"><i class="fas fa-archive"></i><span>归档</span><a class="card-more-btn" href="/archives/" title="查看更多"> <i class="fas fa-angle-right"></i></a></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/06/"><span class="card-archive-list-date">六月 2024</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/05/"><span class="card-archive-list-date">五月 2024</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/04/"><span class="card-archive-list-date">四月 2024</span><span class="card-archive-list-count">2</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/03/"><span class="card-archive-list-date">三月 2024</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/01/"><span class="card-archive-list-date">一月 2024</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/08/"><span class="card-archive-list-date">八月 2023</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/07/"><span class="card-archive-list-date">七月 2023</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/06/"><span class="card-archive-list-date">六月 2023</span><span class="card-archive-list-count">4</span></a></li></ul></div><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>网站资讯</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">文章数目 :</div><div class="item-count">142</div></div><div class="webinfo-item"><div class="item-name">已运行时间 :</div><div class="item-count" id="runtimeshow" data-publishdate="2021-09-26T16:00:00.000Z"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">本站总字数 :</div><div class="item-count">1098.5k</div></div><div class="webinfo-item"><div class="item-name">最后更新时间 :</div><div class="item-count" id="last-push-date" data-lastpushdate="2024-07-03T09:57:19.626Z"><i class="fa-solid fa-spinner fa-spin"></i></div></div></div></div></div></div></main><footer id="footer" style="background:0 0"></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="translateLink" type="button" title="简繁转换">简</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span> 数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"></div></div><hr><div class="no-result" id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div><div class="js-pjax" id="rightMenu"><div class="rightMenu-group rightMenu-small"><a class="rightMenu-item" href="javascript:window.history.back();" rel="external nofollow noreferrer"><i class="fa fa-arrow-left"></i></a><a class="rightMenu-item" href="javascript:window.history.forward();" rel="external nofollow noreferrer"><i class="fa fa-arrow-right"></i></a><a class="rightMenu-item" href="javascript:window.location.reload();" rel="external nofollow noreferrer"><i class="fa fa-refresh"></i></a><a class="rightMenu-item" href="javascript:rmf.scrollToTop();" rel="external nofollow noreferrer"><i class="fa fa-arrow-up"></i></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-text"><a class="rightMenu-item" href="javascript:rmf.copySelect();" rel="external nofollow noreferrer"><i class="fa fa-copy"></i><span>复制</span></a><a class="rightMenu-item" href="javascript:window.open(&quot;https://www.google.com/search?q=&quot;+window.getSelection().toString());" rel="external nofollow noreferrer"><i class="iconfont icon-baidu"></i><span>搜索</span></a><a class="rightMenu-item" href="javascript:rmf.searchinThisPage();" rel="external nofollow noreferrer"><i class="fas fa-search"></i><span>站内搜索</span></a><a class="rightMenu-item" href="#post-comment" onclick="rmf.yinyong()"><i class="fa-solid fa-message"></i><span>引用文本评论</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-too"><a class="rightMenu-item" href="javascript:window.open(window.getSelection().toString());window.location.reload();" rel="external nofollow noreferrer"><i class="fa fa-link"></i><span>转到链接</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-paste"><a class="rightMenu-item" href="javascript:rmf.paste()" rel="external nofollow noreferrer"><i class="fa fa-copy"></i><span>粘贴</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-to"><a class="rightMenu-item" href="javascript:rmf.openWithNewTab()" rel="external nofollow noreferrer"><i class="fa fa-window-restore"></i><span>新窗口打开</span></a><a class="rightMenu-item" id="menu-too" href="javascript:rmf.open()" rel="external nofollow noreferrer"><i class="fa fa-link"></i><span>转到链接</span></a><a class="rightMenu-item" href="javascript:rmf.copyLink()" rel="external nofollow noreferrer"><i class="fa fa-copy"></i><span>复制链接</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-img"><a class="rightMenu-item" href="javascript:rmf.saveAs()" rel="external nofollow noreferrer"><i class="fa fa-download"></i><span>保存图片</span></a><a class="rightMenu-item" href="javascript:rmf.openWithNewTab()" rel="external nofollow noreferrer"><i class="fa fa-window-restore"></i><span>在新窗口打开</span></a><a class="rightMenu-item" href="javascript:rmf.click()" rel="external nofollow noreferrer"><i class="fa fa-arrows-alt"></i><span>全屏显示</span></a><a class="rightMenu-item" href="javascript:rmf.copyLink()" rel="external nofollow noreferrer"><i class="fa fa-copy"></i><span>复制图片链接</span></a></div><div class="rightMenu-group rightMenu-line"><a class="rightMenu-item" href="javascript:rmf.switchDarkMode();" rel="external nofollow noreferrer"><i class="fa fa-moon"></i><span>昼夜切换</span></a><a class="rightMenu-item" href="javascript:rmf.translate();" rel="external nofollow noreferrer"><i class="iconfont icon-fanti"></i><span>繁简转换</span></a><a class="rightMenu-item" href="javascript:rmf.switchReadMode();" rel="external nofollow noreferrer"><i class="fa fa-book"></i><span>阅读模式</span></a><a class="rightMenu-item" href="javascript:fullScreen();" rel="external nofollow noreferrer"><i class="fas fa-expand"></i><span>进入全屏</span></a></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://unpkg.com/@fancyapps/ui/dist/fancybox/fancybox.umd.js"></script><script src="https://unpkg.com/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script>function panguFn(){"object"==typeof pangu?pangu.autoSpacingPage():getScript("https://unpkg.com/pangu/dist/browser/pangu.min.js").then(()=>{pangu.autoSpacingPage()})}function panguInit(){GLOBAL_CONFIG_SITE.isPost&&panguFn()}document.addEventListener("DOMContentLoaded",panguInit)</script><div class="js-pjax"><script>window.typedJSFn={init:t=>{window.typed=new Typed("#subtitle",Object.assign({strings:t,startDelay:300,typeSpeed:150,loop:!0,backSpeed:50},null))},run:t=>{"function"==typeof Typed?t():getScript("https://unpkg.com/typed.js/dist/typed.umd.js").then(t)}}</script><script>function subtitleType(){typedJSFn.init(["吾等云骑，如云翳障空，卫蔽仙舟。","举头望明月，万般感怀皆在其中，此情此景，犹如天星照我，愿逐月华。","玩物丧志，不在玩物，在其本无志。","越过山丘，才发现无人等候","喋喋不休，再也换不回温柔"])}typedJSFn.run(subtitleType)</script></div><script type="text/javascript" src="https://cdn1.tianli0.top/npm/jquery@latest/dist/jquery.min.js"></script><script type="text/javascript" src="/js/rightmenu.js"></script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.7.1/jquery.min.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span> 数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"></div></div><hr><div class="no-result" id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div><script data-pjax>var parent,child;document.getElementById("recent-posts")&&"/"===location.pathname&&(parent=document.getElementById("recent-posts"),child='<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="https://zwn2001.space/categories/编程知识/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📚 洛雪の编程知识 (17)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://zwn2001.space/categories/实用知识/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">💡 洛雪の实用知识 (14)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://zwn2001.space/categories/学习-课外拓展/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">👩‍💻 洛雪の学习-课外拓展 (20)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://zwn2001.space/categories/学习-课内知识/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📒 洛雪の学习-课内知识 (56)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><a class="magnet_link_more"  href="https://zwn2001.space/categories" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>',console.log("已挂载magnet"),parent.insertAdjacentHTML("afterbegin",child))</script><style>#catalog_magnet{flex-wrap:wrap;display:flex;width:100%;justify-content:space-between;padding:10px 10px 0 10px;align-content:flex-start}.magnet_item{flex-basis:calc(50% - 5px);background:#f2f2f2;margin-bottom:10px;border-radius:8px;transition:all .2s ease-in-out}.magnet_item:hover{background:#b30070}.magnet_link_more{color:#555}.magnet_link{color:#000}.magnet_link:hover{color:#fff}@media screen and (max-width:600px){.magnet_item{flex-basis:100%}}.magnet_link_context{display:flex;padding:10px;font-size:16px;transition:all .2s ease-in-out}.magnet_link_context:hover{padding:10px 20px}</style><style></style></body></html>