<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover"><title>ZWN's blog</title><meta name="author" content="琉璃月"><meta name="copyright" content="琉璃月"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="我虽无意逐鹿，却知苍生苦楚"><meta property="og:type" content="website"><meta property="og:title" content="ZWN&#39;s blog"><meta property="og:url" content="https://zwn2001.space/page/2/index.html"><meta property="og:site_name" content="ZWN&#39;s blog"><meta property="og:description" content="我虽无意逐鹿，却知苍生苦楚"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://zwn2001.space/img/favicon.webp"><meta property="article:author" content="琉璃月"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://zwn2001.space/img/favicon.webp"><link rel="shortcut icon" href="/img/favicon.webp"><link rel="canonical" href="https://zwn2001.space/page/2/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://unpkg.com/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://unpkg.com/@fancyapps/ui/dist/fancybox/fancybox.css" media="print" onload='this.media="all"'><script>const GLOBAL_CONFIG={root:"/",algolia:void 0,localSearch:{path:"/search.xml",preload:!0,top_n_per_article:-1,unescape:!1,languages:{hits_empty:"找不到您查询的内容：${query}",hits_stats:"共找到 ${hits} 篇文章"}},translate:{defaultEncoding:2,translateDelay:0,msgToTraditionalChinese:"繁",msgToSimplifiedChinese:"简"},noticeOutdate:{limitDay:200,position:"top",messagePrev:"距离上次更新已经过去",messageNext:"天啦！注意内容可能过时。"},highlight:{plugin:"highlighjs",highlightCopy:!0,highlightLang:!0,highlightHeightLimit:300},copy:{success:"复制成功",error:"复制错误",noSupport:"浏览器不支持"},relativeDate:{homepage:!1,post:!1},runtime:"天",dateSuffix:{just:"刚刚",min:"分钟前",hour:"小时前",day:"天前",month:"个月前"},copyright:void 0,lightbox:"fancybox",Snackbar:void 0,source:{justifiedGallery:{js:"https://unpkg.com/flickr-justified-gallery/dist/fjGallery.min.js",css:"https://unpkg.com/flickr-justified-gallery/dist/fjGallery.css"}},isPhotoFigcaption:!0,islazyload:!1,isAnchor:!0,percent:{toc:!0,rightside:!0},autoDarkmode:!1}</script><script id="config-diff">var GLOBAL_CONFIG_SITE={title:"ZWN's blog",isPost:!1,isHome:!0,isHighlightShrink:!1,isToc:!1,postUpdate:"2025-02-12 20:51:46"}</script><noscript><style type="text/css">#nav{opacity:1}.justified-gallery img{opacity:1}#post-meta time,#recent-posts time{display:inline!important}</style></noscript><script>(e=>{e.saveToLocal={set:function(e,t,a){0!==a&&(a=864e5*a,t={value:t,expiry:(new Date).getTime()+a},localStorage.setItem(e,JSON.stringify(t)))},get:function(e){var t=localStorage.getItem(e);if(t){t=JSON.parse(t);if(!((new Date).getTime()>t.expiry))return t.value;localStorage.removeItem(e)}}},e.getScript=o=>new Promise((t,e)=>{const a=document.createElement("script");a.src=o,a.async=!0,a.onerror=e,a.onload=a.onreadystatechange=function(){var e=this.readyState;e&&"loaded"!==e&&"complete"!==e||(a.onload=a.onreadystatechange=null,t())},document.head.appendChild(a)}),e.getCSS=(o,n=!1)=>new Promise((t,e)=>{const a=document.createElement("link");a.rel="stylesheet",a.href=o,n&&(a.id=n),a.onerror=e,a.onload=a.onreadystatechange=function(){var e=this.readyState;e&&"loaded"!==e&&"complete"!==e||(a.onload=a.onreadystatechange=null,t())},document.head.appendChild(a)}),e.activateDarkMode=function(){document.documentElement.setAttribute("data-theme","dark"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#0d0d0d")},e.activateLightMode=function(){document.documentElement.setAttribute("data-theme","light"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","ffffff")};e=saveToLocal.get("theme"),"dark"===e?activateDarkMode():"light"===e&&activateLightMode(),e=saveToLocal.get("aside-status");void 0!==e&&("hide"===e?document.documentElement.classList.add("hide-aside"):document.documentElement.classList.remove("hide-aside"));/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)&&document.documentElement.classList.add("apple")})(window)</script><link rel="stylesheet" href="/css/transpancy.css"><link rel="stylesheet" href="/css/iconfont.css"><link rel="stylesheet" href="/css/rightmenu.css"><link rel="stylesheet" href="/css/loadimg.css"><link rel="stylesheet" href="/css/project.css"><link type="text/html" rel="stylesheet" href="/css/wide_screen.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-double-row-display@1.00/cardlistpost.min.css"><style>#recent-posts>.recent-post-item>.recent-post-info>.article-meta-wrap>.tags:before{content:"\A";white-space:pre}#recent-posts>.recent-post-item>.recent-post-info>.article-meta-wrap>.tags>.article-meta__separator{display:none}</style><meta name="generator" content="Hexo 5.4.0"></head><body><div id="loading-box" onclick="document.getElementById(&quot;loading-box&quot;).classList.add(&quot;loaded&quot;)"><div class="loading-bg"><img class="loading-img nolazyload" src="/img/favicon.webp"><div class="loading-image-dot"></div><div id="loading-percentage"></div></div></div><script>const loadingPercentage=document.getElementById("loading-percentage");loadingPercentage.style.color="black";let loadingPercentageTimer=setInterval(function(){var e=document.querySelector(".pace-progress");e&&(e=e.getAttribute("data-progress-text"))!==loadingPercentage.textContent&&"60%"===(loadingPercentage.textContent=e)&&clearInterval(loadingPercentageTimer)},100);const preloader={endLoading:()=>{document.body.style.overflow="auto",document.getElementById("loading-box").classList.add("loaded")},initLoading:()=>{document.body.style.overflow="",document.getElementById("loading-box").classList.remove("loaded")}};window.addEventListener("load",()=>{preloader.endLoading()})</script><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/favicon.webp" onerror='onerror=null,src="/img/friend_404.gif"' alt="avatar"></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">166</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">52</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">8</div></a></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="page" id="body-wrap"><header class="full_page" id="page-header" style="background-image:url(/img/bg.webp)"><nav id="nav"><span id="blog-info"><a href="/" title="ZWN's blog"><span class="site-name">ZWN's blog</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);" rel="external nofollow noreferrer"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);" rel="external nofollow noreferrer"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="site-info"><h1 id="site-title">ZWN's blog</h1><div id="site-subtitle"><span id="subtitle"></span></div><div id="site_social_icons"><a class="social-icon" href="https://github.com/ZWN2001" rel="external nofollow noreferrer" target="_blank" title="Github"><i class="fab fa-github"></i></a></div></div><div id="scroll-down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="post_cover left"><a href="/posts/Graduate-Works/Paper-Read/%E8%AF%BBpaper8-Copiloting-the-Copilots/" title="读paper8-Copiloting_the_Copilots"><img class="post-bg" src="/img/cover/36.jpg" onerror='this.onerror=null,this.src="/img/404.webp"' alt="读paper8-Copiloting_the_Copilots"></a></div><div class="recent-post-info"><a class="article-title" href="/posts/Graduate-Works/Paper-Read/%E8%AF%BBpaper8-Copiloting-the-Copilots/" title="读paper8-Copiloting_the_Copilots">读paper8-Copiloting_the_Copilots</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-09-18T10:29:57.000Z" title="发表于 2024-09-18 18:29:57">2024-09-18</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E7%A0%94%E7%A9%B6%E7%94%9F%E5%B7%A5%E4%BD%9C/">研究生工作</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E8%AE%BA%E6%96%87/">论文</a></span></div><div class="content">读paper8：Copiloting the Copilots Copiloting the Copilots: Fusing Large Language Models with Completion Engines for Automated Program Repair https://github.com/ise-uiuc/repilot INTRODUCTION 现有 LLM 在 APR 工具上的局限性的三个场景： 生成不可行的token：即91%概率会生成 asString() ，而不是代码中的 asEndTag() 相当于LLM从其学习的知识库中选择了概率最大的结果，但是不是针对该项目代码的修复（无导向性，无针对性 很难生成少见的token 比如 asEndTag() 这种更自定义的方法名，就很难生成 原因其实还是跟上一个场景类似，没有针对当前项目进行学习 突然想起一个办法，先让LLM分析所有代码，再去进行缺陷检测与修复，但是这个要怎么实现呢。。。。。 没有明确的类型考虑 对于自定义的实体类，显然我们的返回值是EndTag对象，但是LLM并不会学习到这一 ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/posts/Graduate-Works/Paper-Read/%E8%AF%BBpaper7-RAP-Gen-Retrieval-Augmented-Patch-Generation-with-CodeT5/" title="读paper7-RAP-Gen_Retrieval_Augmented_Patch_Generation_with_CodeT5"><img class="post-bg" src="/img/cover/1.jpg" onerror='this.onerror=null,this.src="/img/404.webp"' alt="读paper7-RAP-Gen_Retrieval_Augmented_Patch_Generation_with_CodeT5"></a></div><div class="recent-post-info"><a class="article-title" href="/posts/Graduate-Works/Paper-Read/%E8%AF%BBpaper7-RAP-Gen-Retrieval-Augmented-Patch-Generation-with-CodeT5/" title="读paper7-RAP-Gen_Retrieval_Augmented_Patch_Generation_with_CodeT5">读paper7-RAP-Gen_Retrieval_Augmented_Patch_Generation_with_CodeT5</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-09-17T02:02:32.000Z" title="发表于 2024-09-17 10:02:32">2024-09-17</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E7%A0%94%E7%A9%B6%E7%94%9F%E5%B7%A5%E4%BD%9C/">研究生工作</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E8%AE%BA%E6%96%87/">论文</a></span></div><div class="content">读paper7-RAP-Gen： Retrieval Augmented Patch Generation with CodeT5 INTRODUCTION 名为RAP-Gen的新型检索增强补丁生成框架，通过从补丁检索器中获取相关的修复模式来增强自动程序修复。 模型在性质上是半参数化的，旨在结合隐式（参数化）端到端程序修复学习和显式（非参数化）修复模式挖掘的双重优势。 与先前的修复模式挖掘工作的区别之一是，我们利用最相关的错误-修复对作为有关错误补丁的指导修复模式，而不是使用手工设计的启发式方法对修复模板进行聚类。 RAP-Gen采用了阶段式学习策略来连接补丁检索器和补丁生成器：补丁检索器首先搜索相关的错误修复模式，然后将其传递给CodeT5补丁生成器，根据源代码和检索的外部错误修复知识合成一个修复补丁候选列表。 对于检索器，我们提出了一种混合方法，通过基于原始源代码的稀疏（BM25 ）和密集（DPR）检索来考虑词法和语义匹配。我们使用CodeT5的编码器作为我们的密集DPR检索器，并提出使用对比学习目标对其进行训练，使用先前的错误-修复对作为修复补丁通常与其错误补丁共享大部分语义。 ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/posts/Graduate-Works/DL/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/" title="深度学习-注意力机制"><img class="post-bg" src="/img/cover/6.jpg" onerror='this.onerror=null,this.src="/img/404.webp"' alt="深度学习-注意力机制"></a></div><div class="recent-post-info"><a class="article-title" href="/posts/Graduate-Works/DL/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/" title="深度学习-注意力机制">深度学习-注意力机制</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-09-13T13:50:25.000Z" title="发表于 2024-09-13 21:50:25">2024-09-13</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0-%E8%AF%BE%E5%A4%96%E6%8B%93%E5%B1%95/">学习-课外拓展</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span></div><div class="content">注意力机制 注意力机制概述 自主性的与非自主性的注意力提示解释了人类的注意力的方式， 下面来看看如何通过这两种注意力提示， 用神经网络来设计注意力机制的框架， 首先，考虑一个相对简单的状况， 即只使用非自主性提示。 要想将选择偏向于感官输入， 则可以简单地使用参数化的全连接层， 甚至是非参数化的最大汇聚层或平均汇聚层。 因此，“是否包含自主性提示”将注意力机制与全连接层或汇聚层区别开来。 在注意力机制的背景下，自主性提示被称为查询（query）。 给定任何查询，注意力机制通过注意力汇聚（attention pooling） 将选择引导至感官输入（sensory inputs，例如中间特征表示）。 在注意力机制中，这些感官输入被称为值（value）。 更通俗的解释，每个值都与一个键（key）配对， 这可以想象为感官输入的非自主提示。 如下图所示，可以通过设计注意力汇聚的方式， 便于给定的查询（自主性提示）与键（非自主性提示）进行匹配， 这将引导得出最匹配的值（感官输入）。 此外，注意力机制的设计有许多替代方案。 例如可以设计一个不可微的注意力模型， 该模型可以使用强化学习方法 (Mni ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/posts/Graduate-Works/Course-Notes/%E7%A0%94%E4%B8%80%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97/" title="研一课程笔记-并行计算"><img class="post-bg" src="/img/cover/37.jpg" onerror='this.onerror=null,this.src="/img/404.webp"' alt="研一课程笔记-并行计算"></a></div><div class="recent-post-info"><a class="article-title" href="/posts/Graduate-Works/Course-Notes/%E7%A0%94%E4%B8%80%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97/" title="研一课程笔记-并行计算">研一课程笔记-并行计算</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-09-09T14:55:28.000Z" title="发表于 2024-09-09 22:55:28">2024-09-09</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0-%E8%AF%BE%E5%86%85%E7%9F%A5%E8%AF%86/">学习-课内知识</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90/">数值分析</a></span></div><div class="content">研一课程笔记-并行计算 一、多核体系结构概述 指令级并行 在多核时代到来之前，倾向于提升晶体管集成度，通过集成，可以将更多的原本片外的部件集成到片内中，从而开发出了诸如流水线、乱序执行、动态分支预测和缓存等，这些“低挂果”虽然硬件实现较为复杂，但生产之后的成本相对较低，开发人员无需考虑数据竞争、同步、通信等问题。 逻辑复杂度：例如超标量处理器中大部分部件都用于确保指令的分隔执行。 功耗问题：功耗和电容 CCC、电压V2V^2V2 和时钟频率 fff 相关，CCC 和集成度相关，VVV 如果降低，将导致 fff 变慢。 fmax⁡=c(V−Vthd)αVf_{\max}=c\frac{(V-V_{\mathrm{thd}})^\alpha}Vfmax​=cV(V−Vthd​)α​。其中 VthdV_{thd}Vthd​ 为阈值电压 如果降低阈值电压，则会导致处理器静态功耗指数级增长 数据级并行 由于之前的问题导致集成度无法再提高，频率无法再提升，产生了多核概念。 并行计算机分类： SISD，串行体系结构通用模型，但可以实现指令级并行 SIMD，多用于向量处理器结构 MISD， ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/posts/Graduate-Works/Course-Notes/%E7%A0%94%E4%B8%80%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%901-3/" title="研一课程笔记-数值分析1-3"><img class="post-bg" src="/img/cover/23.jpg" onerror='this.onerror=null,this.src="/img/404.webp"' alt="研一课程笔记-数值分析1-3"></a></div><div class="recent-post-info"><a class="article-title" href="/posts/Graduate-Works/Course-Notes/%E7%A0%94%E4%B8%80%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%901-3/" title="研一课程笔记-数值分析1-3">研一课程笔记-数值分析1-3</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-09-05T14:25:32.000Z" title="发表于 2024-09-05 22:25:32">2024-09-05</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0-%E8%AF%BE%E5%86%85%E7%9F%A5%E8%AF%86/">学习-课内知识</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90/">数值分析</a></span></div><div class="content">研一课程笔记-数值分析1-3 绪论与预备知识 概论 衡量数值算法的几个标准 衡量算法的优劣有两个标准，一是要有可靠的理论基础，包括收敛性、数值稳定性和算法精度等；二是要有较好的计算复杂度。 数值稳定性 数值稳定性即算法对舍入误差的敏感性。舍入误差对计算结果的精确性影响小的算法，具有较好的数值稳定性；反之，算法的数值稳定性差。 算法精度 数值算法的精度衡量了近似解对精确解的近似程度。算法的精度越高并不一定导致近似解的误差越小。精度的具体定义依赖于所考虑的问题类型。在偏微分方程的数值算法中我们一般考虑收敛精度，它指的是算法的收敛速率。 计算复杂度 计算复杂度指的是通过数值计算解决问题的困难程度。最常见的是时间复杂度和空间复杂度 收敛性 算法的收敛性一般指数值解逼近精确解的性质，而对于不同的问题，其定义也是有区别的。例如在迭代算法中，收敛性指的是近似解能够随着迭代过程趋向于精确解，它通常与迭代矩阵的谱半径相关。在偏微分方程数值算法中，收敛性指的是随网格尺寸等参数变化的数值解的收敛性质，它与算法的收敛精度密切相关。 误差理论 误差按照它们的来源可分为以下四种 ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/posts/Graduate-Works/Paper-Read/%E8%AF%BBpaper6-%E7%BC%BA%E9%99%B7%E6%A0%B7%E6%9C%AC%E7%94%9F%E6%88%90/" title="读paper6-缺陷样本生成"><img class="post-bg" src="/img/cover/8.jpg" onerror='this.onerror=null,this.src="/img/404.webp"' alt="读paper6-缺陷样本生成"></a></div><div class="recent-post-info"><a class="article-title" href="/posts/Graduate-Works/Paper-Read/%E8%AF%BBpaper6-%E7%BC%BA%E9%99%B7%E6%A0%B7%E6%9C%AC%E7%94%9F%E6%88%90/" title="读paper6-缺陷样本生成">读paper6-缺陷样本生成</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-09-05T05:20:47.000Z" title="发表于 2024-09-05 13:20:47">2024-09-05</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E7%A0%94%E7%A9%B6%E7%94%9F%E5%B7%A5%E4%BD%9C/">研究生工作</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E8%AE%BA%E6%96%87/">论文</a></span></div><div class="content">VGX: Large-Scale Sample Generation for Boosting Learning-Based Software Vulnerability Analyses VGX通过设计基于代码tokens之间的值流关系（value flow relationships）的绝对和相对位置编码的注意力机制，构建了一个基于Transformer的上下文化模型，并在大型代码语料库上对自定义的Transformer进行预训练，然后针对现有（task-specific 的）易受攻击代码位置数据集进行微调。然后，VGX利用从历史修复和人类对真实世界漏洞的知识中学习的编辑模式，在识别到的上下文中实现漏洞代码注入。 至于什么是值流，国内没有很规范的解释，国外对此有一定的应用，比如静态值流分析工具SVF ：https://blog.csdn.net/gitblog_00087/article/details/138841899 。指的应该是数据流 源码与数据集地址：https://zenodo.org/records/10443177 Background and motivati ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/posts/Graduate-Works/Paper-Read/%E8%AF%BBpaper5-%E5%9F%BA%E4%BA%8E%E5%9B%BE%E7%9A%84%E7%BC%BA%E9%99%B7%E6%A3%80%E6%B5%8B%E4%B8%8E%E4%BF%AE%E5%A4%8D%E4%B8%A4%E7%AF%87/" title="读paper5-基于图的缺陷检测与修复两篇"><img class="post-bg" src="/img/cover/48.jpg" onerror='this.onerror=null,this.src="/img/404.webp"' alt="读paper5-基于图的缺陷检测与修复两篇"></a></div><div class="recent-post-info"><a class="article-title" href="/posts/Graduate-Works/Paper-Read/%E8%AF%BBpaper5-%E5%9F%BA%E4%BA%8E%E5%9B%BE%E7%9A%84%E7%BC%BA%E9%99%B7%E6%A3%80%E6%B5%8B%E4%B8%8E%E4%BF%AE%E5%A4%8D%E4%B8%A4%E7%AF%87/" title="读paper5-基于图的缺陷检测与修复两篇">读paper5-基于图的缺陷检测与修复两篇</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-09-04T07:48:39.000Z" title="发表于 2024-09-04 15:48:39">2024-09-04</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E7%A0%94%E7%A9%B6%E7%94%9F%E5%B7%A5%E4%BD%9C/">研究生工作</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E8%AE%BA%E6%96%87/">论文</a></span></div><div class="content">读paper5-基于图的缺陷检测与修复两篇 CSGVD: A deep learning approach combining sequence and graph embedding for source code vulnerability detection 一种结合序列和图嵌入的深度学习方法用于源代码漏洞检测 利用原始源代码的控制流图，将函数级的漏洞检测视为一个图二分类任务。首先，我们提出了一个PE-BL模块，它继承并增强了预训练语言模型的知识。通过使用序列嵌入，它提取了代码在控制流图中的局部语义特征作为节点嵌入。其次，CSGVD使用具有残差连接的（with residual connectivity）图神经网络来提取图的结构化信息。最后，我们提出了一种均值双仿射注意力池化（M-BFA）方法，以更好地聚合节点信息作为图的特征表示。 符号定义如下： {(ci,yi)∣ci∈C,yi∈Y}i=1N\{(c_i,y_i)\mid c_i\in\mathbb{C},y_i\in\mathbb{Y}\}_{i=1}^N{(ci​,yi​)∣ci​∈C,yi​∈Y}i=1N​ ：数据 ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/posts/Graduate-Works/DL/cs224w-%E5%9B%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02/" title="cs224w-图机器学习2"><img class="post-bg" src="/img/cover/14.jpg" onerror='this.onerror=null,this.src="/img/404.webp"' alt="cs224w-图机器学习2"></a></div><div class="recent-post-info"><a class="article-title" href="/posts/Graduate-Works/DL/cs224w-%E5%9B%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02/" title="cs224w-图机器学习2">cs224w-图机器学习2</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-09-02T08:40:23.000Z" title="发表于 2024-09-02 16:40:23">2024-09-02</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0-%E8%AF%BE%E5%A4%96%E6%8B%93%E5%B1%95/">学习-课外拓展</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E5%9B%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">图机器学习</a></span></div><div class="content">cs224w-图机器学习2：GNN 图神经网络 前面几节内容主要介绍了节点嵌入的概念，也就是说我们可以将一个图中的节点映射到一个的 d 维向量上，而这种映射方式使得相似的节点对应的向量更接近，但主要的问题还是，我们如何学习出一个映射函数 f，而图嵌入的两个核心组件是编码器和相似度函数，图神经网络 GNN 提供了一种基于深度学习的节点嵌入方法。 深度学习基础 介绍了监督学习、损失函数、机器学习中的优化、梯度向量、随机梯度下降等基本概念，不过这些内容已经反复接触过了，因此也就不再专门整理记录 深度学习中的函数往往更为复杂，并且在反向传播进行参数更新的过程中需要用链式法则来求梯度，但总的来讲，不管是传统的监督机器学习还是深度学习，我们的优化目标都是： min⁡L(y,f(x))\min\mathcal{L}(y,f(x)) minL(y,f(x)) 图深度学习 问题的定义 我们把要研究的图记为 GGG，图中所有节点构成集合 VVV，AAA 是图的接邻矩阵 用 XXX 表示图节点的特征矩阵，每个节点具有 mmm 维的特征，节点的特征可以根据图的实际情况来选取 一种很 naive 的方法是将图 ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/posts/Graduate-Works/Paper-Read/%E8%AF%BBpaper4-%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%85%A5%E6%89%8B%E4%B8%8E%E8%AE%BA%E6%96%87%E9%9B%86/" title="读paper4-多智能体强化学习入手与论文集"><img class="post-bg" src="/img/cover/16.jpg" onerror='this.onerror=null,this.src="/img/404.webp"' alt="读paper4-多智能体强化学习入手与论文集"></a></div><div class="recent-post-info"><a class="article-title" href="/posts/Graduate-Works/Paper-Read/%E8%AF%BBpaper4-%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%85%A5%E6%89%8B%E4%B8%8E%E8%AE%BA%E6%96%87%E9%9B%86/" title="读paper4-多智能体强化学习入手与论文集">读paper4-多智能体强化学习入手与论文集</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-08-21T02:43:57.000Z" title="发表于 2024-08-21 10:43:57">2024-08-21</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E7%A0%94%E7%A9%B6%E7%94%9F%E5%B7%A5%E4%BD%9C/">研究生工作</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E8%AE%BA%E6%96%87/">论文</a></span></div><div class="content">多智能体强化学习入手与论文集 TODO List [x] 先把RL复习一下：马尔可夫与蒙特卡洛部分 [x] 2019.10的一篇nature：Grandmaster level in StarCraft II using multi-agent reinforcement learning。https://www.nature.com/articles/s41586-019-1724-z。https://mp.weixin.qq.com/s/R4RXxLan7H2sCbBrKqyH6w [x] 多智能体强化学习算法【一】【MAPPO、MADDPG、QMIX】 [ ] 新型多智能体 Transformer(MAT，Multi-Agent Transformer)架构，该架构可以有效地将协作 MARL 问题转化为序列模型问题，其任务是将智能体的观测序列映射到智能体的最优动作序列。https://arxiv.org/pdf/2205.14953.pdf [x] 多智能体强化学习大模型初探https://mp.weixin.qq.com/s/C_bNa42FdR5xLRcbSLXSCg [x ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/posts/Graduate-Works/DL/cs224w-%E5%9B%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A01/" title="cs224w-图机器学习1"><img class="post-bg" src="/img/cover/22.jpg" onerror='this.onerror=null,this.src="/img/404.webp"' alt="cs224w-图机器学习1"></a></div><div class="recent-post-info"><a class="article-title" href="/posts/Graduate-Works/DL/cs224w-%E5%9B%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A01/" title="cs224w-图机器学习1">cs224w-图机器学习1</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-08-14T01:41:41.000Z" title="发表于 2024-08-14 09:41:41">2024-08-14</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0-%E8%AF%BE%E5%A4%96%E6%8B%93%E5%B1%95/">学习-课外拓展</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E5%9B%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">图机器学习</a></span></div><div class="content">cs224w-图机器学习1 Introduction 选择图的原因：图是用于描述并分析有关联 / 互动的实体的一种普适语言。它不将实体视为一系列孤立的点，而认为其互相之间有关系。它是一种很好的描述领域知识的方式。 网络与图的分类 networks / natural graphs：自然表示为图 Social networks: Society is a collection of 7+ billion individuals Communication and transactions: Electronic devices, phone calls, financial transactions Biomedicine: Interactions between genes/proteins regulate life（大概是基因或蛋白质之间互动从而调节生理活动的过程） Brain connections: Our thoughts are hidden in the connections between billions of neurons graphs：作为一种表示方 ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/posts/Graduate-Works/Paper-Read/%E8%AF%BBpaper3-Katana-Dual-Slicing-Based-Context-for-Learning-Bug-Fixes/" title="读paper3-Katana_Dual_Slicing-Based_Context_for_Learning_Bug_Fixes"><img class="post-bg" src="/img/cover/44.jpg" onerror='this.onerror=null,this.src="/img/404.webp"' alt="读paper3-Katana_Dual_Slicing-Based_Context_for_Learning_Bug_Fixes"></a></div><div class="recent-post-info"><a class="article-title" href="/posts/Graduate-Works/Paper-Read/%E8%AF%BBpaper3-Katana-Dual-Slicing-Based-Context-for-Learning-Bug-Fixes/" title="读paper3-Katana_Dual_Slicing-Based_Context_for_Learning_Bug_Fixes">读paper3-Katana_Dual_Slicing-Based_Context_for_Learning_Bug_Fixes</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-08-11T12:30:40.000Z" title="发表于 2024-08-11 20:30:40">2024-08-11</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E7%A0%94%E7%A9%B6%E7%94%9F%E5%B7%A5%E4%BD%9C/">研究生工作</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E8%AE%BA%E6%96%87/">论文</a></span></div><div class="content">读paper3-Katana: Dual Slicing-Based Context for Learning Bug Fixes 提出了一种基于程序切片的方法，其不是任意地将代码作为上下文包含进来，而是分析对错误语句具有控制或数据依赖关系的语句。利用代码的上下文和修复版本的上下文来捕获相关的修复要素。这里修复版本的上下文并不是指错误代码区的代码前缀与后缀，而是指的是与错误代码直接关联的代码块，无论是控制流还是数据流。 思路上还是基于变形的AST+图神经网络，同时通过上下文的切分尽可能减少冗余信息，通过修复版本的上下文为神经网络的学习提供更多信息。 项目开源在https://github.com/saltlab/Katana 问题引入 当前最先进的基于学习的程序修复方法以各种方式利用上下文，并且其中许多方法使用基于序列和树/图的源代码表示来学习程序修复。这些方法使用包含buggy语句的包围类、包围函数、buggy子树或整个文件来捕获buggy语句的上下文。然而，所有这些方法都对处理buggy语句设置了一个界限限制。基于序列的方法使用最大标记数限制（例如，1,000个标记），在这个范围内 ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/posts/Graduate-Works/Paper-Read/%E8%AF%BBpaper2-%E5%9F%BA%E4%BA%8ELLM%E7%9A%84%E7%BC%BA%E9%99%B7%E4%BF%AE%E5%A4%8D/" title="读paper2-基于LLM的缺陷修复"><img class="post-bg" src="/img/cover/28.jpg" onerror='this.onerror=null,this.src="/img/404.webp"' alt="读paper2-基于LLM的缺陷修复"></a></div><div class="recent-post-info"><a class="article-title" href="/posts/Graduate-Works/Paper-Read/%E8%AF%BBpaper2-%E5%9F%BA%E4%BA%8ELLM%E7%9A%84%E7%BC%BA%E9%99%B7%E4%BF%AE%E5%A4%8D/" title="读paper2-基于LLM的缺陷修复">读paper2-基于LLM的缺陷修复</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-08-09T11:12:45.000Z" title="发表于 2024-08-09 19:12:45">2024-08-09</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E7%A0%94%E7%A9%B6%E7%94%9F%E5%B7%A5%E4%BD%9C/">研究生工作</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E8%AE%BA%E6%96%87/">论文</a></span></div><div class="content">读paper2-基于LLM的缺陷修复 A Deep Dive into Large Language Models for Automated Bug Localization and Repair 来自 Proceedings of the ACM on Software Engineering 。用作启发思路吧，水水的，一二区里没见这刊。反正成果也没开源，全靠几张图。。。 研究概述 现有的工作探索了将整个有错误的函数输入到LLMs中，并使用注释来指导LLMs生成修复好的函数的方法。然而，让LLMs生成整个函数是多余的，因为原有有错误的函数中并不是所有的代码都是错误的。有可能有错误的代码及其相应的修复代码共享一些非错误的前缀和后缀。例如，在图1中，蓝色和棕色的代码是有错误和修复函数共享的前缀和后缀代码。通常，只有少部分有错误的代码需要修改。在给定的例子中，只需要将 “getProperty” 替换为 “get” 就可以生成修复代码。要求LLMs生成这之外的其他代码可能会导致更多的错误，并降低整体的错误修复能力。 问题根源还是在于细粒度，所以该文提出了一种基于token的缺陷定位与修 ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/posts/Graduate-Works/DL/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-LogSumExp%E6%8A%80%E5%B7%A7/" title="深度学习-LogSumExp技巧"><img class="post-bg" src="/img/cover/58.jpg" onerror='this.onerror=null,this.src="/img/404.webp"' alt="深度学习-LogSumExp技巧"></a></div><div class="recent-post-info"><a class="article-title" href="/posts/Graduate-Works/DL/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-LogSumExp%E6%8A%80%E5%B7%A7/" title="深度学习-LogSumExp技巧">深度学习-LogSumExp技巧</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-07-27T04:15:17.000Z" title="发表于 2024-07-27 12:15:17">2024-07-27</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0-%E8%AF%BE%E5%A4%96%E6%8B%93%E5%B1%95/">学习-课外拓展</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span></div><div class="content">深度学习-LogSumExp技巧 引言 今天来学习下 LogSumExp(LSE)技巧，主要解决计算 Softmax 或 CrossEntropy时出现的上溢 (overflow) 或下溢 (underflow) 问题。 我们知道编程语言中的数值都有一个表示范围的，如果数值过大，超过最大的范围，就是上溢；如果过小，超过最小的范围，就是下溢。 什么是 LSE LSE 被定义为参数指数之和的对数： logSumExp⁡(x1…xn)=log⁡(∑i=1nexi)=log⁡(∑i=1nexi−beb)=log⁡(eb∑i=1nexi−b)=log⁡(∑i=1nexi−b)+log⁡(eb)=log⁡(∑i=1nexi−b)+b\begin{aligned}\operatorname{logSumExp}\left(x_{1} \ldots x_{n}\right) &amp;=\log \left(\sum_{i=1}^{n} e^{x_{i}}\right) \\ &amp;=\log \left(\sum_{i=1}^{n} e^{x_{i}-b} e^{b}\right) \\ & ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/posts/Other-Techs/jupyter%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/" title="jupyter踩坑记录"><img class="post-bg" src="/img/cover/41.jpg" onerror='this.onerror=null,this.src="/img/404.webp"' alt="jupyter踩坑记录"></a></div><div class="recent-post-info"><a class="article-title" href="/posts/Other-Techs/jupyter%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/" title="jupyter踩坑记录">jupyter踩坑记录</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-07-27T02:20:19.000Z" title="发表于 2024-07-27 10:20:19">2024-07-27</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%9D%82%E8%AE%B0/">杂记</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E8%B8%A9%E5%9D%91/">踩坑</a></span></div><div class="content">jupyter踩坑记录 VSCode安装完成后无法在命令行使用 无法将“jupyter”项识别为 cmdlet、函数、脚本文件或可运行程序的名称 ‘jupyter’ 不是内部或外部命令，也不是可运行的程序 首先要确认环境变量： D:\IDE-Extends\Python3\Lib\site-packages D:\IDE-Extends\Python3\Scripts D:\IDE-Extends\Python3 理论上第三个不需要，我只是保险起见 保险起见我直接把环境变量用户PATH与系统PATH都来了一份 其次：D:\IDE-Extends\Python3\Scripts，类似的，这个文件夹内，其实你发现根本没有 jupyter.exe 所以执行类似：jupyter nbconvert --to markdown '文件名.ipynb'命令会报错 一种可以在当前目录下复制 jupyter-notebook.exe 重命名为 jupyter.exe 另一种是直接使用 jupyter-notebook 替换命令中的 jupyter VSCode下ipynb转md https:/ ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/posts/Graduate-Works/DL/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E6%B1%87%E7%BC%964-3%EF%BC%9A%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B/" title="吴恩达深度学习笔记汇编4-3：序列模型"><img class="post-bg" src="/img/cover/58.jpg" onerror='this.onerror=null,this.src="/img/404.webp"' alt="吴恩达深度学习笔记汇编4-3：序列模型"></a></div><div class="recent-post-info"><a class="article-title" href="/posts/Graduate-Works/DL/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E6%B1%87%E7%BC%964-3%EF%BC%9A%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B/" title="吴恩达深度学习笔记汇编4-3：序列模型">吴恩达深度学习笔记汇编4-3：序列模型</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-07-16T10:01:03.000Z" title="发表于 2024-07-16 18:01:03">2024-07-16</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0-%E8%AF%BE%E5%A4%96%E6%8B%93%E5%B1%95/">学习-课外拓展</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span></div><div class="content">吴恩达深度学习笔记汇编4-3：序列模型(Sequence Models) 这部分知识是我在学习吴恩达的深度学习课程时对其笔记的汇总与编注。 内容上，原笔记是视频课程的字幕整合，我对原笔记一些无关紧要的内容进行了删减，以达到精炼的目的，并增加了一些个人见解、语义上的补充以及一部分中英对照和公式推导，以对吴老师的课程内容理解提供更充分的辅助，有一些使用了引用来加以区分，不过大部分并未进行标注（主要是没有观感很好的标注方法）。 我对原文有一些改动，主要是原文有一些地方翻译的不尽人意（这是因为视频课程中吴老师语句也并不会像课本一样做到非常条理清晰），所以我对那些词不达意、逻辑或语句结构混乱的地方进行了删改，以更清晰地表达出吴老师的原意。（这部分改动基本没有标注） 以及一些加粗，也是我自己认为相对重点的地方，带有一定主观性，见谅。 又，每节课程开始都会有简短的引言，不过看上去可能有些废话，但我认为也是必不可少的，所以用引用进行标注，可以选择性阅读 课程地址：【[双语字幕]吴恩达深度学习deeplearning.ai】 https://www.bilibili.com/video/BV1FT4y ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/posts/Graduate-Works/DL/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E6%B1%87%E7%BC%964-2%EF%BC%9A%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B/" title="吴恩达深度学习笔记汇编4-2：序列模型"><img class="post-bg" src="/img/cover/20.jpg" onerror='this.onerror=null,this.src="/img/404.webp"' alt="吴恩达深度学习笔记汇编4-2：序列模型"></a></div><div class="recent-post-info"><a class="article-title" href="/posts/Graduate-Works/DL/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E6%B1%87%E7%BC%964-2%EF%BC%9A%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B/" title="吴恩达深度学习笔记汇编4-2：序列模型">吴恩达深度学习笔记汇编4-2：序列模型</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-07-16T09:01:03.000Z" title="发表于 2024-07-16 17:01:03">2024-07-16</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0-%E8%AF%BE%E5%A4%96%E6%8B%93%E5%B1%95/">学习-课外拓展</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span></div><div class="content">吴恩达深度学习笔记汇编4-2：序列模型(Sequence Models) 这部分知识是我在学习吴恩达的深度学习课程时对其笔记的汇总与编注。 内容上，原笔记是视频课程的字幕整合，我对原笔记一些无关紧要的内容进行了删减，以达到精炼的目的，并增加了一些个人见解、语义上的补充以及一部分中英对照和公式推导，以对吴老师的课程内容理解提供更充分的辅助，有一些使用了引用来加以区分，不过大部分并未进行标注（主要是没有观感很好的标注方法）。 我对原文有一些改动，主要是原文有一些地方翻译的不尽人意（这是因为视频课程中吴老师语句也并不会像课本一样做到非常条理清晰），所以我对那些词不达意、逻辑或语句结构混乱的地方进行了删改，以更清晰地表达出吴老师的原意。（这部分改动基本没有标注） 以及一些加粗，也是我自己认为相对重点的地方，带有一定主观性，见谅。 又，每节课程开始都会有简短的引言，不过看上去可能有些废话，但我认为也是必不可少的，所以用引用进行标注，可以选择性阅读 课程地址：【[双语字幕]吴恩达深度学习deeplearning.ai】 https://www.bilibili.com/video/BV1FT4y ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/posts/Graduate-Works/DL/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E6%B1%87%E7%BC%964-1%EF%BC%9A%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B/" title="吴恩达深度学习笔记汇编4-1：序列模型"><img class="post-bg" src="/img/cover/20.jpg" onerror='this.onerror=null,this.src="/img/404.webp"' alt="吴恩达深度学习笔记汇编4-1：序列模型"></a></div><div class="recent-post-info"><a class="article-title" href="/posts/Graduate-Works/DL/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E6%B1%87%E7%BC%964-1%EF%BC%9A%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B/" title="吴恩达深度学习笔记汇编4-1：序列模型">吴恩达深度学习笔记汇编4-1：序列模型</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-07-16T02:01:03.000Z" title="发表于 2024-07-16 10:01:03">2024-07-16</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0-%E8%AF%BE%E5%A4%96%E6%8B%93%E5%B1%95/">学习-课外拓展</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span></div><div class="content">吴恩达深度学习笔记汇编4-1：序列模型(Sequence Models) 这部分知识是我在学习吴恩达的深度学习课程时对其笔记的汇总与编注。 内容上，原笔记是视频课程的字幕整合，我对原笔记一些无关紧要的内容进行了删减，以达到精炼的目的，并增加了一些个人见解、语义上的补充以及一部分中英对照和公式推导，以对吴老师的课程内容理解提供更充分的辅助，有一些使用了引用来加以区分，不过大部分并未进行标注（主要是没有观感很好的标注方法）。 我对原文有一些改动，主要是原文有一些地方翻译的不尽人意（这是因为视频课程中吴老师语句也并不会像课本一样做到非常条理清晰），所以我对那些词不达意、逻辑或语句结构混乱的地方进行了删改，以更清晰地表达出吴老师的原意。（这部分改动基本没有标注） 以及一些加粗，也是我自己认为相对重点的地方，带有一定主观性，见谅。 又，每节课程开始都会有简短的引言，不过看上去可能有些废话，但我认为也是必不可少的，所以用引用进行标注，可以选择性阅读 课程地址：【[双语字幕]吴恩达深度学习deeplearning.ai】 https://www.bilibili.com/video/BV1FT4y ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/posts/Graduate-Works/DL/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E6%B1%87%E7%BC%963-2%EF%BC%9A%E7%BB%93%E6%9E%84%E5%8C%96%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE/" title="吴恩达深度学习笔记汇编3-2：结构化机器学习项目"><img class="post-bg" src="/img/cover/54.jpg" onerror='this.onerror=null,this.src="/img/404.webp"' alt="吴恩达深度学习笔记汇编3-2：结构化机器学习项目"></a></div><div class="recent-post-info"><a class="article-title" href="/posts/Graduate-Works/DL/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E6%B1%87%E7%BC%963-2%EF%BC%9A%E7%BB%93%E6%9E%84%E5%8C%96%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE/" title="吴恩达深度学习笔记汇编3-2：结构化机器学习项目">吴恩达深度学习笔记汇编3-2：结构化机器学习项目</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-07-12T03:17:15.000Z" title="发表于 2024-07-12 11:17:15">2024-07-12</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0-%E8%AF%BE%E5%A4%96%E6%8B%93%E5%B1%95/">学习-课外拓展</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span></div><div class="content">吴恩达深度学习笔记汇编3-2：结构化机器学习项目 (Structuring Machine Learning Projects) 这部分知识是我在学习吴恩达的深度学习课程时对其笔记的汇总与编注。 这一部分内容并没有很多需要推导的数学知识或者很深奥的思想（除了最后几节），大部分都是经验性知识，更侧重于理解与思考，所以我对原文尽量没有改动，以免产生歧义。 当然，有一些加粗，是我自己认为相对重点的地方，带有一定主观性，见谅。 课程地址：【[双语字幕]吴恩达深度学习deeplearning.ai】 https://www.bilibili.com/video/BV1FT4y1E74V 笔记链接：https://github.com/fengdu78/deeplearning_ai_books 笔记在线阅读：http://www.ai-start.com/dl2017/ 机器学习策略（2）(ML Strategy (2)) 进行误差分析（Carrying out error analysis） 你好，欢迎回来，如果你希望让学习算法能够胜任人类能做的任务，但你的学习算法还没有达到人类的表现，那 ...</div></div></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/"><i class="fas fa-chevron-left fa-fw"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/#content-inner">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/10/#content-inner">10</a><a class="extend next" rel="next" href="/page/3/#content-inner"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/favicon.webp" onerror='this.onerror=null,this.src="/img/friend_404.gif"' alt="avatar"></div><div class="author-info__name">琉璃月</div><div class="author-info__description">我虽无意逐鹿，却知苍生苦楚</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">166</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">52</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">8</div></a></div><a id="card-info-btn" target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/ZWN2001"><i class="fab fa-github"></i><span>我的Github</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/ZWN2001" rel="external nofollow noreferrer" target="_blank" title="Github"><i class="fab fa-github"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">新域名：www.zwn2001.space，有效期：10年。https://www.zwn-blog.xyz已过期。访问时建议科学上网，否则博客内公式渲染会出现问题且速度慢。Ctrl+shift+r可强制刷新网站以避免浏览器缓存造成的更新不及时</div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/posts/Graduate-Works/Paper-Read/%E8%AF%BBpaper17-%E5%9F%BA%E4%BA%8ELLM%E7%9A%84%E7%BC%BA%E9%99%B7%E4%BF%AE%E5%A4%8D4%E4%B8%8E%E4%BF%AE%E5%A4%8D%E6%8F%90%E7%A4%BA%E8%AF%8D/" title="读paper17-基于LLM的缺陷修复4与修复提示词"><img src="/img/cover/1.jpg" onerror='this.onerror=null,this.src="/img/404.webp"' alt="读paper17-基于LLM的缺陷修复4与修复提示词"></a><div class="content"><a class="title" href="/posts/Graduate-Works/Paper-Read/%E8%AF%BBpaper17-%E5%9F%BA%E4%BA%8ELLM%E7%9A%84%E7%BC%BA%E9%99%B7%E4%BF%AE%E5%A4%8D4%E4%B8%8E%E4%BF%AE%E5%A4%8D%E6%8F%90%E7%A4%BA%E8%AF%8D/" title="读paper17-基于LLM的缺陷修复4与修复提示词">读paper17-基于LLM的缺陷修复4与修复提示词</a><time datetime="2025-02-03T08:19:48.000Z" title="发表于 2025-02-03 16:19:48">2025-02-03</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/Graduate-Works/Paper-Read/%E8%AF%BBpaper16-%E5%BE%AE%E8%B0%83LLM%E7%9A%84APR%E4%B8%8E%E6%AD%A3%E7%A1%AE%E6%80%A7%E9%AA%8C%E8%AF%81/" title="读paper16-微调LLM的APR与正确性验证"><img src="/img/cover/11.jpg" onerror='this.onerror=null,this.src="/img/404.webp"' alt="读paper16-微调LLM的APR与正确性验证"></a><div class="content"><a class="title" href="/posts/Graduate-Works/Paper-Read/%E8%AF%BBpaper16-%E5%BE%AE%E8%B0%83LLM%E7%9A%84APR%E4%B8%8E%E6%AD%A3%E7%A1%AE%E6%80%A7%E9%AA%8C%E8%AF%81/" title="读paper16-微调LLM的APR与正确性验证">读paper16-微调LLM的APR与正确性验证</a><time datetime="2025-01-03T08:23:09.000Z" title="发表于 2025-01-03 16:23:09">2025-01-03</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/Graduate-Works/Course-Notes/%E4%BD%BF%E7%94%A8%E4%B8%A2%E7%95%AA%E5%9B%BE%E9%80%BC%E8%BF%91%E4%BC%98%E5%8C%96%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8F%82%E6%95%B0/" title="使用丢番图逼近优化大语言模型的参数"><img src="/img/cover/47.jpg" onerror='this.onerror=null,this.src="/img/404.webp"' alt="使用丢番图逼近优化大语言模型的参数"></a><div class="content"><a class="title" href="/posts/Graduate-Works/Course-Notes/%E4%BD%BF%E7%94%A8%E4%B8%A2%E7%95%AA%E5%9B%BE%E9%80%BC%E8%BF%91%E4%BC%98%E5%8C%96%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8F%82%E6%95%B0/" title="使用丢番图逼近优化大语言模型的参数">使用丢番图逼近优化大语言模型的参数</a><time datetime="2024-12-18T07:56:34.000Z" title="发表于 2024-12-18 15:56:34">2024-12-18</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/Graduate-Works/Paper-Read/%E8%AF%BBpaper15-Multi-Agent/" title="读paper15-Multi-Agent"><img src="/img/cover/38.jpg" onerror='this.onerror=null,this.src="/img/404.webp"' alt="读paper15-Multi-Agent"></a><div class="content"><a class="title" href="/posts/Graduate-Works/Paper-Read/%E8%AF%BBpaper15-Multi-Agent/" title="读paper15-Multi-Agent">读paper15-Multi-Agent</a><time datetime="2024-12-11T10:47:35.000Z" title="发表于 2024-12-11 18:47:35">2024-12-11</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/Graduate-Works/Paper-Read/%E8%AF%BBpaper14-Multi-Agent-2/" title="读paper14-Multi-Agent-2"><img src="/img/cover/3.jpg" onerror='this.onerror=null,this.src="/img/404.webp"' alt="读paper14-Multi-Agent-2"></a><div class="content"><a class="title" href="/posts/Graduate-Works/Paper-Read/%E8%AF%BBpaper14-Multi-Agent-2/" title="读paper14-Multi-Agent-2">读paper14-Multi-Agent-2</a><time datetime="2024-12-10T04:37:04.000Z" title="发表于 2024-12-10 12:37:04">2024-12-10</time></div></div></div></div><div class="card-widget card-categories"><div class="item-headline"><i class="fas fa-folder-open"></i> <span>分类</span></div><ul class="card-category-list" id="aside-cat-list"><li class="card-category-list-item"><a class="card-category-list-link" href="/categories/%E5%AD%A6%E4%B9%A0-%E8%AF%BE%E5%86%85%E7%9F%A5%E8%AF%86/"><span class="card-category-list-name">学习-课内知识</span><span class="card-category-list-count">59</span></a></li><li class="card-category-list-item"><a class="card-category-list-link" href="/categories/%E5%AD%A6%E4%B9%A0-%E8%AF%BE%E5%A4%96%E6%8B%93%E5%B1%95/"><span class="card-category-list-name">学习-课外拓展</span><span class="card-category-list-count">38</span></a></li><li class="card-category-list-item"><a class="card-category-list-link" href="/categories/%E5%AD%A6%E7%BA%BF%E5%9F%B9%E8%AE%AD/"><span class="card-category-list-name">学线培训</span><span class="card-category-list-count">14</span></a></li><li class="card-category-list-item"><a class="card-category-list-link" href="/categories/%E5%AE%9E%E7%94%A8%E7%9F%A5%E8%AF%86/"><span class="card-category-list-name">实用知识</span><span class="card-category-list-count">10</span></a></li><li class="card-category-list-item"><a class="card-category-list-link" href="/categories/%E6%9D%82%E8%AE%B0/"><span class="card-category-list-name">杂记</span><span class="card-category-list-count">10</span></a></li><li class="card-category-list-item"><a class="card-category-list-link" href="/categories/%E7%A0%94%E7%A9%B6%E7%94%9F%E5%B7%A5%E4%BD%9C/"><span class="card-category-list-name">研究生工作</span><span class="card-category-list-count">18</span></a></li><li class="card-category-list-item"><a class="card-category-list-link" href="/categories/%E7%BC%96%E7%A8%8B%E7%9F%A5%E8%AF%86/"><span class="card-category-list-name">编程知识</span><span class="card-category-list-count">13</span></a></li><li class="card-category-list-item"><a class="card-category-list-link" href="/categories/%E9%A1%B9%E7%9B%AE%E6%80%9D%E8%B7%AF%E3%80%81%E7%AE%97%E6%B3%95/"><span class="card-category-list-name">项目思路、算法</span><span class="card-category-list-count">3</span></a></li></ul></div><div class="card-widget card-tags"><div class="item-headline"><i class="fas fa-tags"></i><span>标签</span></div><div class="card-tag-cloud"><a href="/tags/%E6%97%A5%E5%B8%B8/" style="font-size:1.15em;color:#498cb0">日常</a><a href="/tags/%E8%B8%A9%E5%9D%91/" style="font-size:1.18em;color:#a346a3">踩坑</a><a href="/tags/%E8%BD%AC%E8%BD%BD%E4%B8%8E%E6%B1%87%E6%80%BB/" style="font-size:1.45em;color:#8d61b0">转载与汇总</a><a href="/tags/Hexo/" style="font-size:1.15em;color:#859e5a">Hexo</a><a href="/tags/SDU%E9%80%89%E8%AF%BE/" style="font-size:1.15em;color:#8f3601">SDU选课</a><a href="/tags/%E6%9D%82%E8%AE%B0/" style="font-size:1.2em;color:#1b27c7">杂记</a><a href="/tags/HSD/" style="font-size:1.15em;color:#af1849">HSD</a><a href="/tags/%E5%AE%A2%E5%88%B6%E5%8C%96%E9%94%AE%E7%9B%98/" style="font-size:1.15em;color:#c102b9">客制化键盘</a><a href="/tags/%E5%89%8D%E7%AB%AF/" style="font-size:1.15em;color:#5da82c">前端</a><a href="/tags/%E7%AE%97%E6%B3%95/" style="font-size:1.2em;color:#740e3e">算法</a><a href="/tags/Python/" style="font-size:1.29em;color:#771e6e">Python</a><a href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/" style="font-size:1.2em;color:#aa0128">数据库系统设计</a><a href="/tags/Linux/" style="font-size:1.15em;color:#2bc8c5">Linux</a><a href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F%E6%A6%82%E5%BF%B5/" style="font-size:1.31em;color:#136176">数据库系统概念</a><a href="/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/" style="font-size:1.31em;color:#5da23f">操作系统</a><a href="/tags/%E4%BC%97%E6%99%BA/" style="font-size:1.2em;color:#5a6134">众智</a><a href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" style="font-size:1.23em;color:#371c51">数据结构</a><a href="/tags/%E7%A6%BB%E6%95%A3/" style="font-size:1.2em;color:#1b3b12">离散</a><a href="/tags/%E5%A4%A7%E8%8B%B1/" style="font-size:1.15em;color:#084306">大英</a><a href="/tags/%E8%AE%BE%E8%AE%A1%E7%90%86%E5%BF%B5/" style="font-size:1.15em;color:#6b44aa">设计理念</a><a href="/tags/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/" style="font-size:1.26em;color:#2a5115">面向对象</a><a href="/tags/%E5%90%8E%E7%AB%AF/" style="font-size:1.18em;color:#c22f9c">后端</a><a href="/tags/flutter/" style="font-size:1.31em;color:#719361">flutter</a><a href="/tags/%E5%AD%A6%E7%BA%BF%E5%9F%B9%E8%AE%AD/" style="font-size:1.18em;color:#23c3aa">学线培训</a><a href="/tags/%E5%AE%89%E5%8D%93/" style="font-size:1.2em;color:#842a90">安卓</a><a href="/tags/%E7%A7%BB%E5%8A%A8/" style="font-size:1.34em;color:#675b27">移动</a><a href="/tags/%E5%AE%89%E5%8D%93%E5%8E%9F%E7%94%9F/" style="font-size:1.15em;color:#972d2e">安卓原生</a><a href="/tags/java%E5%B9%B6%E5%8F%91/" style="font-size:1.18em;color:#a63662">java并发</a><a href="/tags/i%E5%B1%B1%E5%A4%A7/" style="font-size:1.15em;color:#246ab6">i山大</a><a href="/tags/oj/" style="font-size:1.15em;color:#445f71">oj</a><a href="/tags/%E5%AD%A6%E4%B9%A0/" style="font-size:1.2em;color:#5a10a2">学习</a><a href="/tags/%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90/" style="font-size:1.2em;color:#5e206a">数值分析</a><a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" style="font-size:1.42em;color:#ac1ba2">机器学习</a><a href="/tags/%E5%9B%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" style="font-size:1.18em;color:#97a0a6">图机器学习</a><a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" style="font-size:1.37em;color:#ba9f44">深度学习</a><a href="/tags/%E8%80%83%E7%A0%94/" style="font-size:1.2em;color:#403216">考研</a><a href="/tags/%E8%AE%BA%E6%96%87/" style="font-size:1.4em;color:#1f3dba">论文</a><a href="/tags/%E7%A0%94/" style="font-size:1.18em;color:#601b67">研</a><a href="/tags/%E8%AE%A1%E7%BB%84%E8%AF%BE%E8%AE%BE/" style="font-size:1.15em;color:#004cc0">计组课设</a><a href="/tags/%E8%AE%A1%E7%BD%91/" style="font-size:1.2em;color:#382797">计网</a><a href="/tags/git/" style="font-size:1.18em;color:#0a3ea0">git</a><a href="/tags/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/" style="font-size:1.15em;color:#9e6f23">正则表达式</a><a href="/tags/c/" style="font-size:1.15em;color:#069833">c++</a><a href="/tags/%E6%9E%B6%E6%9E%84/" style="font-size:1.15em;color:#5a4434">架构</a><a href="/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/" style="font-size:1.15em;color:#aa1119">强化学习</a><a href="/tags/Agent/" style="font-size:1.2em;color:#658533">Agent</a><a href="/tags/%E6%9C%8D%E5%8A%A1%E5%BC%80%E5%8F%91/" style="font-size:1.15em;color:#8a2559">服务开发</a><a href="/tags/%E6%AF%95%E8%AE%BE/" style="font-size:1.15em;color:#503605">毕设</a><a href="/tags/CSharp/" style="font-size:1.15em;color:#07bc82">CSharp</a><a href="/tags/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/" style="font-size:1.15em;color:#459578">编译原理</a><a href="/tags/opencv/" style="font-size:1.15em;color:#71436c">opencv</a><a href="/tags/LLM/" style="font-size:1.15em;color:#84bf4e">LLM</a></div></div><div class="card-widget card-archives"><div class="item-headline"><i class="fas fa-archive"></i><span>归档</span><a class="card-more-btn" href="/archives/" title="查看更多"> <i class="fas fa-angle-right"></i></a></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/02/"><span class="card-archive-list-date">二月 2025</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/01/"><span class="card-archive-list-date">一月 2025</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/12/"><span class="card-archive-list-date">十二月 2024</span><span class="card-archive-list-count">4</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/11/"><span class="card-archive-list-date">十一月 2024</span><span class="card-archive-list-count">3</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/10/"><span class="card-archive-list-date">十月 2024</span><span class="card-archive-list-count">7</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/09/"><span class="card-archive-list-date">九月 2024</span><span class="card-archive-list-count">9</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/08/"><span class="card-archive-list-date">八月 2024</span><span class="card-archive-list-count">4</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/07/"><span class="card-archive-list-date">七月 2024</span><span class="card-archive-list-count">10</span></a></li></ul></div><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>网站资讯</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">文章数目 :</div><div class="item-count">166</div></div><div class="webinfo-item"><div class="item-name">已运行时间 :</div><div class="item-count" id="runtimeshow" data-publishdate="2021-09-26T16:00:00.000Z"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">本站总字数 :</div><div class="item-count">1468.4k</div></div><div class="webinfo-item"><div class="item-name">最后更新时间 :</div><div class="item-count" id="last-push-date" data-lastpushdate="2025-02-12T12:51:26.609Z"><i class="fa-solid fa-spinner fa-spin"></i></div></div></div></div></div></div></main><footer id="footer" style="background:0 0"></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="translateLink" type="button" title="简繁转换">简</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span> 数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"></div></div><hr><div class="no-result" id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div><div class="js-pjax" id="rightMenu"><div class="rightMenu-group rightMenu-small"><a class="rightMenu-item" href="javascript:window.history.back();" rel="external nofollow noreferrer"><i class="fa fa-arrow-left"></i></a><a class="rightMenu-item" href="javascript:window.history.forward();" rel="external nofollow noreferrer"><i class="fa fa-arrow-right"></i></a><a class="rightMenu-item" href="javascript:window.location.reload();" rel="external nofollow noreferrer"><i class="fa fa-refresh"></i></a><a class="rightMenu-item" href="javascript:rmf.scrollToTop();" rel="external nofollow noreferrer"><i class="fa fa-arrow-up"></i></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-text"><a class="rightMenu-item" href="javascript:rmf.copySelect();" rel="external nofollow noreferrer"><i class="fa fa-copy"></i><span>复制</span></a><a class="rightMenu-item" href="javascript:window.open(&quot;https://www.google.com/search?q=&quot;+window.getSelection().toString());" rel="external nofollow noreferrer"><i class="iconfont icon-baidu"></i><span>搜索</span></a><a class="rightMenu-item" href="javascript:rmf.searchinThisPage();" rel="external nofollow noreferrer"><i class="fas fa-search"></i><span>站内搜索</span></a><a class="rightMenu-item" href="#post-comment" onclick="rmf.yinyong()"><i class="fa-solid fa-message"></i><span>引用文本评论</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-too"><a class="rightMenu-item" href="javascript:window.open(window.getSelection().toString());window.location.reload();" rel="external nofollow noreferrer"><i class="fa fa-link"></i><span>转到链接</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-paste"><a class="rightMenu-item" href="javascript:rmf.paste()" rel="external nofollow noreferrer"><i class="fa fa-copy"></i><span>粘贴</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-to"><a class="rightMenu-item" href="javascript:rmf.openWithNewTab()" rel="external nofollow noreferrer"><i class="fa fa-window-restore"></i><span>新窗口打开</span></a><a class="rightMenu-item" id="menu-too" href="javascript:rmf.open()" rel="external nofollow noreferrer"><i class="fa fa-link"></i><span>转到链接</span></a><a class="rightMenu-item" href="javascript:rmf.copyLink()" rel="external nofollow noreferrer"><i class="fa fa-copy"></i><span>复制链接</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-img"><a class="rightMenu-item" href="javascript:rmf.saveAs()" rel="external nofollow noreferrer"><i class="fa fa-download"></i><span>保存图片</span></a><a class="rightMenu-item" href="javascript:rmf.openWithNewTab()" rel="external nofollow noreferrer"><i class="fa fa-window-restore"></i><span>在新窗口打开</span></a><a class="rightMenu-item" href="javascript:rmf.click()" rel="external nofollow noreferrer"><i class="fa fa-arrows-alt"></i><span>全屏显示</span></a><a class="rightMenu-item" href="javascript:rmf.copyLink()" rel="external nofollow noreferrer"><i class="fa fa-copy"></i><span>复制图片链接</span></a></div><div class="rightMenu-group rightMenu-line"><a class="rightMenu-item" href="javascript:rmf.switchDarkMode();" rel="external nofollow noreferrer"><i class="fa fa-moon"></i><span>昼夜切换</span></a><a class="rightMenu-item" href="javascript:rmf.translate();" rel="external nofollow noreferrer"><i class="iconfont icon-fanti"></i><span>繁简转换</span></a><a class="rightMenu-item" href="javascript:rmf.switchReadMode();" rel="external nofollow noreferrer"><i class="fa fa-book"></i><span>阅读模式</span></a><a class="rightMenu-item" href="javascript:fullScreen();" rel="external nofollow noreferrer"><i class="fas fa-expand"></i><span>进入全屏</span></a></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://unpkg.com/@fancyapps/ui/dist/fancybox/fancybox.umd.js"></script><script>function panguFn(){"object"==typeof pangu?pangu.autoSpacingPage():getScript("https://unpkg.com/pangu/dist/browser/pangu.min.js").then(()=>{pangu.autoSpacingPage()})}function panguInit(){GLOBAL_CONFIG_SITE.isPost&&panguFn()}document.addEventListener("DOMContentLoaded",panguInit)</script><div class="js-pjax"><script>window.typedJSFn={init:t=>{window.typed=new Typed("#subtitle",Object.assign({strings:t,startDelay:300,typeSpeed:150,loop:!0,backSpeed:50},null))},run:t=>{"function"==typeof Typed?t():getScript("https://unpkg.com/typed.js/dist/typed.umd.js").then(t)}}</script><script>function subtitleType(){typedJSFn.init(["举头望明月，万般感怀皆在其中，此情此景，犹如天星照我，愿逐月华。","玩物丧志，不在玩物，在其本无志。","谁念西风独自凉......","我要这天 再遮不住我眼","我要这地 再埋不了我心","我要这铁棒醉舞魔","我有这变化乱迷浊","踏碎凌霄 放肆桀骜"])}typedJSFn.run(subtitleType)</script></div><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.7.1/jquery.min.js"></script><script type="text/javascript" src="/js/rightmenu.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span> 数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"></div></div><hr><div class="no-result" id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div><script data-pjax>var parent,child;document.getElementById("recent-posts")&&"/"===location.pathname&&(parent=document.getElementById("recent-posts"),child='<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="https://zwn2001.space/categories/编程知识/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📚 琉璃月の编程知识 (13)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://zwn2001.space/categories/实用知识/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">💡 琉璃月の实用知识 (10)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://zwn2001.space/categories/学习-课外拓展/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">👩‍💻 琉璃月の学习-课外拓展 (38)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://zwn2001.space/categories/学习-课内知识/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📒 琉璃月の学习-课内知识 (59)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><a class="magnet_link_more"  href="https://zwn2001.space/categories" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>',console.log("已挂载magnet"),parent.insertAdjacentHTML("afterbegin",child))</script><style>#catalog_magnet{flex-wrap:wrap;display:flex;width:100%;justify-content:space-between;padding:10px 10px 0 10px;align-content:flex-start}.magnet_item{flex-basis:calc(50% - 5px);background:#f2f2f2;margin-bottom:10px;border-radius:8px;transition:all .2s ease-in-out}.magnet_item:hover{background:#b30070}.magnet_link_more{color:#555}.magnet_link{color:#000}.magnet_link:hover{color:#fff}@media screen and (max-width:600px){.magnet_item{flex-basis:100%}}.magnet_link_context{display:flex;padding:10px;font-size:16px;transition:all .2s ease-in-out}.magnet_link_context:hover{padding:10px 20px}</style><style></style></body></html>