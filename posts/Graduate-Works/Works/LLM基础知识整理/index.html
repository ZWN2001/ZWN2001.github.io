<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover"><title>LLM基础知识整理 | ZWN's blog</title><meta name="author" content="琉璃月"><meta name="copyright" content="琉璃月"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="LLM基础知识整理 LLM-Base BERT BERT（Bidirectional Encoder Representations from Transformers）是一种基于Transformer架构的预训练语言模型，通过双向上下文建模显著提升了自然语言处理任务的性能。其核心原理如下： 1. 核心架构：Transformer编码器  BERT采用多层Transformer编码器堆叠而成，基础"><meta property="og:type" content="article"><meta property="og:title" content="LLM基础知识整理"><meta property="og:url" content="https://zwn2001.space/posts/Graduate-Works/Works/LLM%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/index.html"><meta property="og:site_name" content="ZWN&#39;s blog"><meta property="og:description" content="LLM基础知识整理 LLM-Base BERT BERT（Bidirectional Encoder Representations from Transformers）是一种基于Transformer架构的预训练语言模型，通过双向上下文建模显著提升了自然语言处理任务的性能。其核心原理如下： 1. 核心架构：Transformer编码器  BERT采用多层Transformer编码器堆叠而成，基础"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://zwn2001.space/img/cover/41.jpg"><meta property="article:published_time" content="2025-04-29T09:40:59.000Z"><meta property="article:modified_time" content="2025-05-12T16:33:52.928Z"><meta property="article:author" content="琉璃月"><meta property="article:tag" content="LLM"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://zwn2001.space/img/cover/41.jpg"><link rel="shortcut icon" href="/img/favicon.webp"><link rel="canonical" href="https://zwn2001.space/posts/Graduate-Works/Works/LLM%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://unpkg.com/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://unpkg.com/@fancyapps/ui/dist/fancybox/fancybox.css" media="print" onload='this.media="all"'><script>const GLOBAL_CONFIG={root:"/",algolia:void 0,localSearch:{path:"/search.xml",preload:!0,top_n_per_article:-1,unescape:!1,languages:{hits_empty:"找不到您查询的内容：${query}",hits_stats:"共找到 ${hits} 篇文章"}},translate:{defaultEncoding:2,translateDelay:0,msgToTraditionalChinese:"繁",msgToSimplifiedChinese:"简"},noticeOutdate:{limitDay:200,position:"top",messagePrev:"距离上次更新已经过去",messageNext:"天啦！注意内容可能过时。"},highlight:{plugin:"highlighjs",highlightCopy:!0,highlightLang:!0,highlightHeightLimit:300},copy:{success:"复制成功",error:"复制错误",noSupport:"浏览器不支持"},relativeDate:{homepage:!1,post:!1},runtime:"天",dateSuffix:{just:"刚刚",min:"分钟前",hour:"小时前",day:"天前",month:"个月前"},copyright:void 0,lightbox:"fancybox",Snackbar:void 0,source:{justifiedGallery:{js:"https://unpkg.com/flickr-justified-gallery/dist/fjGallery.min.js",css:"https://unpkg.com/flickr-justified-gallery/dist/fjGallery.css"}},isPhotoFigcaption:!0,islazyload:!1,isAnchor:!0,percent:{toc:!0,rightside:!0},autoDarkmode:!1}</script><script id="config-diff">var GLOBAL_CONFIG_SITE={title:"LLM基础知识整理",isPost:!0,isHome:!1,isHighlightShrink:!1,isToc:!0,postUpdate:"2025-05-13 00:33:52"}</script><noscript><style type="text/css">#nav{opacity:1}.justified-gallery img{opacity:1}#post-meta time,#recent-posts time{display:inline!important}</style></noscript><script>(e=>{e.saveToLocal={set:function(e,t,a){0!==a&&(a=864e5*a,t={value:t,expiry:(new Date).getTime()+a},localStorage.setItem(e,JSON.stringify(t)))},get:function(e){var t=localStorage.getItem(e);if(t){t=JSON.parse(t);if(!((new Date).getTime()>t.expiry))return t.value;localStorage.removeItem(e)}}},e.getScript=o=>new Promise((t,e)=>{const a=document.createElement("script");a.src=o,a.async=!0,a.onerror=e,a.onload=a.onreadystatechange=function(){var e=this.readyState;e&&"loaded"!==e&&"complete"!==e||(a.onload=a.onreadystatechange=null,t())},document.head.appendChild(a)}),e.getCSS=(o,n=!1)=>new Promise((t,e)=>{const a=document.createElement("link");a.rel="stylesheet",a.href=o,n&&(a.id=n),a.onerror=e,a.onload=a.onreadystatechange=function(){var e=this.readyState;e&&"loaded"!==e&&"complete"!==e||(a.onload=a.onreadystatechange=null,t())},document.head.appendChild(a)}),e.activateDarkMode=function(){document.documentElement.setAttribute("data-theme","dark"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#0d0d0d")},e.activateLightMode=function(){document.documentElement.setAttribute("data-theme","light"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","ffffff")};e=saveToLocal.get("theme"),"dark"===e?activateDarkMode():"light"===e&&activateLightMode(),e=saveToLocal.get("aside-status");void 0!==e&&("hide"===e?document.documentElement.classList.add("hide-aside"):document.documentElement.classList.remove("hide-aside"));/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)&&document.documentElement.classList.add("apple")})(window)</script><link rel="stylesheet" href="/css/transpancy.css"><link rel="stylesheet" href="/css/iconfont.css"><link rel="stylesheet" href="/css/rightmenu.css"><link rel="stylesheet" href="/css/loadimg.css"><link rel="stylesheet" href="/css/project.css"><link type="text/html" rel="stylesheet" href="/css/wide_screen.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-double-row-display@1.00/cardlistpost.min.css"><style>#recent-posts>.recent-post-item>.recent-post-info>.article-meta-wrap>.tags:before{content:"\A";white-space:pre}#recent-posts>.recent-post-item>.recent-post-info>.article-meta-wrap>.tags>.article-meta__separator{display:none}</style><meta name="generator" content="Hexo 5.4.0"></head><body><div id="loading-box" onclick="document.getElementById(&quot;loading-box&quot;).classList.add(&quot;loaded&quot;)"><div class="loading-bg"><img class="loading-img nolazyload" src="/img/favicon.webp"><div class="loading-image-dot"></div><div id="loading-percentage"></div></div></div><script>const loadingPercentage=document.getElementById("loading-percentage");loadingPercentage.style.color="black";let loadingPercentageTimer=setInterval(function(){var e=document.querySelector(".pace-progress");e&&(e=e.getAttribute("data-progress-text"))!==loadingPercentage.textContent&&"60%"===(loadingPercentage.textContent=e)&&clearInterval(loadingPercentageTimer)},100);const preloader={endLoading:()=>{document.body.style.overflow="auto",document.getElementById("loading-box").classList.add("loaded")},initLoading:()=>{document.body.style.overflow="",document.getElementById("loading-box").classList.remove("loaded")}};window.addEventListener("load",()=>{preloader.endLoading()})</script><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/favicon.webp" onerror='onerror=null,src="/img/friend_404.gif"' alt="avatar"></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">171</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">52</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">8</div></a></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image:url(/img/cover/41.jpg)"><nav id="nav"><span id="blog-info"><a href="/" title="ZWN's blog"><span class="site-name">ZWN's blog</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);" rel="external nofollow noreferrer"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);" rel="external nofollow noreferrer"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">LLM基础知识整理</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-04-29T09:40:59.000Z" title="发表于 2025-04-29 17:40:59">2025-04-29</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-05-12T16:33:52.928Z" title="更新于 2025-05-13 00:33:52">2025-05-13</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%AD%A6%E4%B9%A0-%E8%AF%BE%E5%A4%96%E6%8B%93%E5%B1%95/">学习-课外拓展</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">36k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>117分钟</span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1>LLM基础知识整理</h1><h2 id="LLM-Base">LLM-Base</h2><h3 id="BERT">BERT</h3><p>BERT（Bidirectional Encoder Representations from Transformers）是一种基于Transformer架构的预训练语言模型，通过双向上下文建模显著提升了自然语言处理任务的性能。其核心原理如下：</p><h4 id="1-核心架构：Transformer编码器"><strong>1. 核心架构：Transformer编码器</strong></h4><ul><li>BERT采用<strong>多层Transformer编码器</strong>堆叠而成，基础模型包含12层，大模型包含24层。</li><li>每层编码器由<strong>多头自注意力机制</strong>和<strong>前馈神经网络</strong>组成，支持并行计算和长距离依赖捕捉。</li><li><strong>自注意力机制</strong>允许模型动态权衡不同位置词的重要性，生成上下文相关的词表示。</li></ul><h4 id="2-预训练任务"><strong>2. 预训练任务</strong></h4><p>BERT通过两个无监督任务学习通用语言表示：</p><h5 id="2-1-掩码语言模型（Masked-Language-Model-MLM）"><strong>2.1 掩码语言模型（Masked Language Model, MLM）</strong></h5><ul><li><strong>方法</strong>：随机遮盖输入中15%的词（如替换为<code>[MASK]</code>），模型基于上下文预测被遮盖的词。</li><li><strong>遮盖策略</strong>：<ul><li>80%替换为<code>[MASK]</code>。</li><li>10%替换为随机词。</li><li>10%保留原词。</li></ul></li><li><strong>目的</strong>：迫使模型融合双向上下文信息，避免对遮盖标记过度依赖。</li></ul><h5 id="2-2-下一句预测（Next-Sentence-Prediction-NSP）"><strong>2.2 下一句预测（Next Sentence Prediction, NSP）</strong></h5><ul><li><strong>方法</strong>：输入两个句子（A和B），50%情况下B是A的真实下一句，50%为随机句子，模型判断二者是否连续。</li><li><strong>目的</strong>：学习句子间关系，提升对段落级任务（如问答、推理）的理解。</li></ul><h4 id="3-输入表示"><strong>3. 输入表示</strong></h4><p>BERT的输入为<strong>词、位置、段落嵌入</strong>的加和：</p><ul><li><strong>词嵌入（Token Embeddings）</strong>：将词映射为向量，包含<code>[CLS]</code>（分类标记）和<code>[SEP]</code>（分隔标记）。</li><li><strong>位置嵌入（Position Embeddings）</strong>：可学习的向量，表示词的位置。</li><li><strong>段落嵌入（Segment Embeddings）</strong>：区分句子A和B（如NSP任务）。</li></ul><h4 id="5-关键优势与局限"><strong>5. 关键优势与局限</strong></h4><ul><li><strong>优势</strong>：<ul><li><strong>双向上下文建模</strong>：突破传统单向模型的限制。</li><li><strong>通用性强</strong>：通过预训练+微调范式适配多种任务。</li></ul></li><li><strong>局限</strong>：<ul><li>模型参数量大，训练资源消耗高。</li></ul></li></ul><h3 id="三种嵌入">三种嵌入</h3><p>BERT的输入表示通过将词嵌入（Token Embeddings）、位置嵌入（Position Embeddings）和段落嵌入（Segment Embeddings）三者结合，形成最终的输入向量。以下是具体展开：</p><h4 id="1-词嵌入（Token-Embeddings）"><strong>1. 词嵌入（Token Embeddings）</strong></h4><h5 id="作用"><strong>作用</strong></h5><ul><li>将离散的词语（或子词）映射为连续向量，捕捉语义信息。</li><li>处理特殊标记（如<code>[CLS]</code>、<code>[SEP]</code>、<code>[MASK]</code>）。</li></ul><h5 id="实现细节"><strong>实现细节</strong></h5><ol><li><strong>分词方式</strong>：<ul><li>使用<strong>WordPiece分词</strong>，将单词拆分为子词（subword），例如：<ul><li><code>&quot;unbelievable&quot;</code> → <code>[&quot;un&quot;, &quot;##belie&quot;, &quot;##vable&quot;]</code>。</li></ul></li><li>优点：减少词汇表大小（通常3万左右），解决OOV问题。</li></ul></li><li><strong>特殊标记</strong>：<ul><li><code>[CLS]</code>：位于输入开头，用于分类任务的聚合表示。</li><li><code>[SEP]</code>：分隔两个句子（如问答对、句子对任务）。</li><li><code>[MASK]</code>：在预训练任务（MLM）中表示被遮盖的词。</li><li><code>[PAD]</code>：填充标记，统一输入长度。</li></ul></li><li><strong>词嵌入矩阵</strong>：<ul><li>词表大小：约3万（不同版本略有差异）。</li><li>向量维度：通常与模型隐藏层维度一致（如BERT-base为768维）。</li></ul></li></ol><h4 id="2-位置嵌入（Position-Embeddings）"><strong>2. 位置嵌入（Position Embeddings）</strong></h4><h5 id="作用-2"><strong>作用</strong></h5><ul><li>为模型提供词语的<strong>位置信息</strong>（Transformer本身不包含顺序信息）。</li><li>解决序列中词与词之间的相对或绝对位置关系。</li></ul><h5 id="实现细节-2"><strong>实现细节</strong></h5><ol><li><strong>绝对位置编码</strong>：<ul><li>BERT采用<strong>可学习的位置向量</strong>（非固定的正弦/余弦函数）。</li><li>每个位置（0到最大序列长度-1）对应一个唯一的向量。</li><li>例如：BERT支持的最大序列长度为512，因此位置嵌入矩阵形状为<code>[512, 768]</code>（BERT-base）。</li></ul></li><li><strong>与词嵌入的结合</strong>：<ul><li>每个词的最终输入 = 词嵌入 + 位置嵌入 + 段落嵌入。</li><li>位置嵌入直接与词嵌入相加，而非拼接，减少计算量。</li></ul></li><li><strong>相对位置的局限性</strong>：<ul><li>BERT的位置嵌入是绝对位置编码，无法直接建模相对距离（后续模型如Transformer-XL改进这一点）。</li></ul></li></ol><h4 id="3-段落嵌入（Segment-Embeddings）"><strong>3. 段落嵌入（Segment Embeddings）</strong></h4><h5 id="作用-3"><strong>作用</strong></h5><ul><li>区分输入中的不同句子或段落（如句子对任务中的句子A和句子B）。</li><li>帮助模型理解句子间关系（如NSP任务）。</li></ul><h5 id="实现细节-3"><strong>实现细节</strong></h5><ol><li><strong>段落标识</strong>：<ul><li>输入中的每个词被标记为属于句子A（<code>Segment 0</code>）或句子B（<code>Segment 1</code>）。</li><li>例如：<ul><li>单句输入：所有词标记为<code>Segment 0</code>。</li><li>句子对输入：<code>[CLS] A [SEP] B [SEP]</code> → A部分为<code>Segment 0</code>，B部分为<code>Segment 1</code>。</li></ul></li></ul></li><li><strong>段嵌入向量</strong>：<ul><li>每个段落标识（0或1）对应一个可学习的向量。</li><li>向量维度与词嵌入相同（如768维）。</li></ul></li><li><strong>应用场景</strong>：<ul><li><strong>NSP任务</strong>：判断句子B是否是句子A的下一句。</li><li><strong>问答任务</strong>：区分问题和上下文段落。</li></ul></li></ol><h4 id="4-输入整合流程"><strong>4. 输入整合流程</strong></h4><h5 id="步骤示例（输入句子对：“How-are-you-”-和-“I’m-fine-”）"><strong>步骤示例（输入句子对：“How are you?” 和 “I’m fine.”）</strong></h5><ol><li><p><strong>分词与添加特殊标记</strong>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[CLS] How are you? [SEP] I&#x27;m fine. [SEP]</span><br></pre></td></tr></table></figure></li><li><p><strong>映射为词嵌入</strong>：</p><ul><li>每个词（包括<code>[CLS]</code>和<code>[SEP]</code>）转换为768维向量。</li></ul></li><li><p><strong>添加位置嵌入</strong>：</p><ul><li>位置0对应<code>[CLS]</code>，位置1对应&quot;How&quot;，依此类推，直到序列结束。</li></ul></li><li><p><strong>添加段落嵌入</strong>：</p><ul><li>第一句（<code>[CLS] How are you? [SEP]</code>）标记为<code>Segment 0</code>。</li><li>第二句（<code>I'm fine. [SEP]</code>）标记为<code>Segment 1</code>。</li></ul></li><li><p><strong>最终输入</strong>：</p><ul><li>每个词的输入向量 = 词嵌入 + 位置嵌入 + 段落嵌入。</li><li>输入矩阵形状：<code>[序列长度, 隐藏层维度]</code>（如<code>[12, 768]</code>）。</li></ul></li></ol><h3 id="Transformer">Transformer</h3><p>阅读 <a target="_blank" rel="noopener external nofollow noreferrer" href="https://blog.csdn.net/v_JULY_v/article/details/127411638">v_JULY_v的博客</a>，从第三部分开始看</p><h4 id="为什么需要Transformer？"><strong>为什么需要Transformer？</strong></h4><ul><li><strong>传统模型的局限性</strong>：RNN（循环神经网络）难以并行计算且难以捕捉长距离依赖，CNN（卷积神经网络）的局部感受野限制全局语义理解。</li><li><strong>注意力机制的优势</strong>：可直接建模任意距离的词语关系，但早期注意力仍需依赖RNN/CNN框架。</li><li><strong>Transformer的突破</strong>：<strong>完全抛弃循环和卷积结构</strong>，仅用注意力机制构建模型，实现高效并行和全局建模。</li></ul><h4 id="核心结构：编码器-解码器架构"><strong>核心结构：编码器-解码器架构</strong></h4><h5 id="1-编码器（Encoder）"><strong>1. 编码器（Encoder）</strong></h5><ul><li><strong>输入处理</strong>：词向量 + 位置编码（解决无时序信息的缺陷）</li><li><strong>核心模块</strong>：N个相同层堆叠（通常N=6），每层包含：<ul><li><strong>多头自注意力（Multi-Head Self-Attention）</strong>：并行计算多个注意力头，捕捉不同维度的语义关联</li><li><strong>前馈神经网络（Feed Forward）</strong>：对每个位置独立进行非线性变换</li><li><strong>残差连接 + Layer Normalization</strong>：缓解梯度消失，稳定训练</li></ul></li></ul><h5 id="2-解码器（Decoder）"><strong>2. 解码器（Decoder）</strong></h5><ul><li><strong>额外功能</strong>：在自注意力层中引入<strong>掩码机制</strong>（防止未来信息泄露）</li><li><strong>交叉注意力层</strong>：连接编码器输出与解码器输入，建立跨序列关联</li></ul><h4 id="关键技术细节"><strong>关键技术细节</strong></h4><ol><li><strong>位置编码（Positional Encoding）</strong><ul><li>使用正弦函数或可学习向量，为无位置信息的模型注入序列顺序</li></ul></li><li><strong>多头注意力（Multi-Head Attention）</strong><ul><li>将Q/K/V投影到多个子空间，独立计算后拼接，增强模型表达能力</li></ul></li><li><strong>层归一化与残差连接</strong><ul><li>每个子层后接残差连接（输入+输出）和层归一化，加速收敛</li></ul></li></ol><h4 id="优势与局限"><strong>优势与局限</strong></h4><ul><li><strong>优势</strong>：<ul><li>并行计算效率远超RNN</li><li>长距离依赖建模能力极强</li><li>架构统一，适合多种任务</li></ul></li><li><strong>局限</strong>：<ul><li>计算复杂度随序列长度平方增长（适合短文本，长文本需优化如稀疏注意力）</li><li>缺乏对局部结构的显式建模（后续工作通过卷积混合改进）</li></ul></li></ul><h3 id="为什么与Encoder中的Q、K、V全部来自于上一层单元的输出不同，Decoder只有Q来自于上一个Decoder单元的输出，K与V都来自于Encoder最后一层的输出">为什么与Encoder中的Q、K、V全部来自于上一层单元的输出不同，Decoder只有Q来自于上一个Decoder单元的输出，K与V都来自于Encoder最后一层的输出</h3><p>在Transformer模型中，Decoder的Q、K、V来源与Encoder不同的设计，主要基于以下核心原因：</p><h3 id="1-Encoder与Decoder的职责差异"><strong>1. Encoder与Decoder的职责差异</strong></h3><ul><li><p><strong>Encoder</strong>的任务是<strong>全面理解输入序列</strong>，通过多层自注意力机制逐步融合全局信息，生成高层次的语义表示。因此，其每一层的Q、K、V均来自同一输入序列的上一层输出，确保每个位置都能动态关注整个输入序列的上下文。</p></li><li><p><strong>Decoder</strong>的任务是<strong>自回归生成输出序列</strong>（如翻译、文本生成），需满足两个关键约束：</p><ol><li><strong>自回归性</strong>：生成当前词时，只能依赖已生成的词（防止信息泄露）。</li><li><strong>输入依赖</strong>：生成的词需与输入序列的语义对齐（如翻译时需参考源语言）。</li></ol></li></ul><h3 id="2-Decoder的结构与注意力机制"><strong>2. Decoder的结构与注意力机制</strong></h3><p>Decoder的每一层包含两种注意力机制：</p><h4 id="1-掩码自注意力（Masked-Self-Attention）"><strong>(1) 掩码自注意力（Masked Self-Attention）</strong></h4><ul><li><strong>Q、K、V均来自Decoder的上一层输出</strong>：<ul><li>通过掩码机制（Masking），确保生成第(t)个词时，仅能关注前(t-1)个词，避免未来信息泄露。</li><li>作用：捕捉已生成输出序列的内部依赖关系（如语法连贯性）。</li></ul></li></ul><h4 id="2-交叉注意力（Encoder-Decoder-Attention）"><strong>(2) 交叉注意力（Encoder-Decoder Attention）</strong></h4><ul><li><strong>Q来自Decoder的上一层输出，K、V来自Encoder的最终输出</strong>：<ul><li><strong>Q</strong>：代表当前生成位置（如目标语言的第(t)个词）的查询需求。</li><li><strong>K、V</strong>：携带输入序列的完整语义信息（如源语言句子的编码结果）。</li><li>作用：根据当前生成状态（Q），动态检索输入序列（K、V）中最相关的信息，指导下一个词的生成。</li></ul></li></ul><img src="f06b895e8a5379ac6ba95534a0b80b0d.png" style="zoom:50%"><h3 id="3-为何交叉注意力中K、V必须来自Encoder？"><strong>3. 为何交叉注意力中K、V必须来自Encoder？</strong></h3><h4 id="1-输入与输出的语义对齐"><strong>(1) 输入与输出的语义对齐</strong></h4><ul><li><strong>Encoder的最终输出</strong>是对输入序列的全局表示（如源语言句子的语义），Decoder需要通过交叉注意力将输出序列的生成与输入序列的关键信息对齐。<ul><li><strong>示例</strong>：在翻译“我爱AI”为“I love AI”时，生成“love”时需关注源句中的“爱”。</li></ul></li></ul><h4 id="2-避免信息泄露与职责分离"><strong>(2) 避免信息泄露与职责分离</strong></h4><ul><li>如果K、V来自Decoder自身输出（即Decoder的上一层输出）：<ul><li><strong>信息泄露</strong>：即便使用了自回归掩码（mask），Decoder的隐藏状态可能包含未来时间步的信息，因为Decoder的生成是基于历史上下文累积的，而上层的隐藏状态可能隐含了未来生成的词的信息。这种信息泄露会破坏生成任务的因果性假设。</li><li>职责分离：Transformer模型中的Encoder和Decoder各司其职：<ul><li><strong>Encoder</strong>：静态地编码输入序列，生成输入的全局语义表示（固定不变）。</li><li><strong>Decoder</strong>：动态生成输出序列，逐步生成每个词，同时通过交叉注意力从Encoder的输出中获取输入相关的信息。</li></ul></li></ul></li></ul><h4 id="3-计算效率与参数复用"><strong>(3) 计算效率与参数复用</strong></h4><ul><li>Encoder的最终输出只需计算一次，Decoder的每一层均可复用该结果作为K、V，避免重复编码输入序列，显著提升计算效率。</li></ul><h3 id="FFN">FFN</h3><p>摘自 <a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.zhihu.com/question/622085869">知乎</a></p><p>FFN本质上就是一个两层的<a target="_blank" rel="noopener external nofollow noreferrer" href="https://so.csdn.net/so/search?q=MLP&amp;spm=1001.2101.3001.7020">MLP</a>。这个MLP的数学本质是：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>FFN</mtext><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo>⋅</mo><msub><mi>W</mi><mn>1</mn></msub><mo stretchy="false">)</mo><msub><mi>W</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\text{FFN}(x) = f(x \cdot W_1) W_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord text"><span class="mord">FFN</span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.10764em">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.13889em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.13889em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span></span></p><p>其中两层<a target="_blank" rel="noopener external nofollow noreferrer" href="https://so.csdn.net/so/search?q=%E6%84%9F%E7%9F%A5%E6%9C%BA&amp;spm=1001.2101.3001.7020">感知机</a>中，第一层会将输入的向量升维，第二层将向量重新降维。这样子就可以学习到更加抽象的特征。</p><p>FFN 设计的初衷，其实就是为模型引入非线性变换。那接着问，attention 中也有 softmax，也是非线性，那 FFN 还是必须的么？ 大多数人开始产生自我怀疑，开始从别的角度回答 FFN 的作用。就比如用Transformers 原始论文中的解释： FNN 可以看作用 1x1 的卷积核来进行特征的升维和降维。</p><p>其实这么追问是个陷阱，用来了解一下候选人对 Transformers 细节的把握情况。这个陷阱其实会引出另外一个问题：attention 是线性运算的还是非线性运算的？</p><p>全局来看，对于x来说是非线性运算。因为仔细看一下 Attention 的计算公式，其中确实有一个针对 q 和 k 的 softmax 的非线性运算。</p><p><strong>但是对于 value 来说，并没有任何的非线性变换。所以每一次 Attention 的计算相当于是对 value 代表的向量进行了加权平均，虽然权重是非线性的权重。这就是 FFN 必须要存在的原因，或者说更本质的原因是因为 FFN 提供了最简单的非线性变换</strong>。</p><p>线性变换无法处理一些非线性的特征，恰如当年马文明斯基给神经网络判的死刑，只需要加个非线性变换的激活函数就能起死回生。</p><p>Attention, FFN, ResNet 缺一不可但却可能是各司其职，我个人的观点（并不一定准确）是， Attention 的功能是做信息的提取和聚合，Resnet 提供信息带宽，而真正学到的知识或者信息都存储在 FFN 中。在图像领域中，也有一种说法，那就是 Attention 其实是 token mixer, FNN 其实是 channel mixer.</p><p>《 Attention is Not All You Need: Pure Attention Loses Rank Doubly Exponentially with Depth》这篇论文，提出了 Transformers 架构存在 token uniformity 的归纳偏置(inductive bias，有时候也叫归纳偏好)问题。如果去掉 FFN 或者 Resnet，则问题更加严重。</p><p>这里解释一下这两个名词，所谓归纳偏置，可以通俗的理解为模型的“个性”，就是满足训练集合的解法有无数种，但是不同的模型架构会让模型更偏向于某些解法。比如我们常用的一些正则化方法，其实就是让模型的归纳偏置倾向于选择一些简单的解法。任何模型都有归纳偏置，尤其是碰到未见过的样本的时候，模型的归纳偏置就更容易体现出来。 Transformers 的一个归纳偏执是什么呢？就是 token uniformity，有时候也叫 information diffusion，或者 anisotropic (各向异性)，也就是说 训练完后的 token 会共享很多相似信息。</p><p>看下图大概就知道了，我们期望表示 token 的向量，相似的要相近，不相似的要远，而且最好是均匀的分布在整个空间中，比如下图所示。但是 Transformers 会存在 各向异性的问题，也就是所有的 token 都挤到一个很窄的锥形区域了。</p><p><img src="v2-cf13e536d0a8b7b3424577a24def3e4e_720w.webp" alt=""></p><p>回到论文，论文将 FFN 和 ResNet 去掉之后做了一些消融实验，证明了 FFN 和 ResNet 是 Transformers 中的必备组件，这两个可以大大的缓解 token uniformity 或者 各向异性的问题。</p><h4 id="FFN的记忆功能">FFN的记忆功能</h4><p>这一节讲的两篇论文都非常有意思，建议大家看一看原始论文。</p><p>《Transformer Feed-Forward Layers Are Key-Value Memories》这篇文章做了很多实验和统计，得出了以下结论：</p><ol><li>FFN 是一个 Key-Value 记忆网络，第一层线性变换是 Key Memory，第二层线性变换是 Value Memory。</li><li>FFN 学到的记忆有一定的可解释性，比如低层的 Key 记住了一些通用 pattern (比如以某某结尾)，而高层的 Key 则记住了一些语义上的 Pattern （比如句子的分类）。</li><li>Value Memory 根据 Key Memory 记住的 Pattern，来预测输出词的分布。</li><li><a target="_blank" rel="noopener external nofollow noreferrer" href="https://zhida.zhihu.com/search?content_id=669772418&amp;content_type=Answer&amp;match_order=1&amp;q=skip+connection&amp;zhida_source=entity">skip connection</a> 将每层 FFN 的结果进行细化。</li></ol><p>2015年，《<a target="_blank" rel="noopener external nofollow noreferrer" href="https://zhida.zhihu.com/search?content_id=669772418&amp;content_type=Answer&amp;match_order=1&amp;q=End-To-End+Memory+Networks&amp;zhida_source=entity">End-To-End Memory Networks</a> 》这篇论文提出了 <a target="_blank" rel="noopener external nofollow noreferrer" href="https://zhida.zhihu.com/search?content_id=669772418&amp;content_type=Answer&amp;match_order=1&amp;q=Key-Value+Memory&amp;zhida_source=entity">Key-Value Memory</a> 的结构，对于一个输入 xxx, 其网络结构为</p><p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>MemoryNet(x)</mtext><mo>=</mo><mtext>softmax</mtext><mo stretchy="false">(</mo><mi>x</mi><mo>⋅</mo><msup><mi>K</mi><mi mathvariant="normal">⊤</mi></msup><mo stretchy="false">)</mo><mi>V</mi></mrow><annotation encoding="application/x-tex">\text{MemoryNet(x)} = \text{softmax}(x \cdot K^\top) V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord text"><span class="mord">MemoryNet(x)</span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord text"><span class="mord">softmax</span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1.099108em;vertical-align:-.25em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.07153em">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.849108em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">⊤</span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord mathnormal" style="margin-right:.22222em">V</span></span></span></span></p><p>FFN 的公式为，</p><p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>FFN</mtext><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo>⋅</mo><msub><mi>W</mi><mn>1</mn></msub><mo stretchy="false">)</mo><msub><mi>W</mi><mn>2</mn></msub><mo>=</mo><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo>⋅</mo><msup><mi>K</mi><mi mathvariant="normal">⊤</mi></msup><mo stretchy="false">)</mo><mi>V</mi></mrow><annotation encoding="application/x-tex">\text{FFN}(x) = f(x \cdot W_1) W_2 = f(x \cdot K^\top) V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord text"><span class="mord">FFN</span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.10764em">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.13889em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.13889em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.10764em">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1.099108em;vertical-align:-.25em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.07153em">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.849108em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">⊤</span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord mathnormal" style="margin-right:.22222em">V</span></span></span></span></p><p>这里 fff 是 ReLU 激活函数，可以看出两个结构的唯一区别就是一个是才用 softmax 进行归一化，另一个则采用 ReLU 进行筛选。本质上都差不多。</p><p><img src="v2-bcb3513bf17f0d7c5251adbce9c7ff08_720w.webp" alt=""></p><p>通过一些实验也确实证明了上面结论，也就是 FFN 确实将一些 pattern 或者知识记忆和存储起来了。</p><p>这就很有意思，从这个角度来说，Attention 是对短期的信息进行提取，而 FFN 则对整个训练样本进行信息提取和记忆。<strong>这也就能解释为什么一个有限的窗口甚至对语料进行了暴力截断，模型也能记住语料库中的信息。</strong></p><h4 id="FFN-是一种混合专家模型">FFN 是一种混合专家模型</h4><p>MoEfication: Transformer Feed-forward Layers are Mixtures of Experts</p><p>这是刘知远团队的论文，其实一直以来，神经网络就存在稀疏激活的现象，也就是在推理的时候，其实只有极小一部分参数参与了计算。这篇论文则通过 MoE 的思想来将 FFN 层拆分成了多个专家，并且新增了一个路由模块来确定推理的时候来挂哪个专家的门诊：）</p><p>这么做完之后，在提升推理速度的同时，效果依然能保持原来的95%以上。</p><h3 id="残差链接-ResNet残差网络">残差链接/ResNet残差网络</h3><h4 id="一、残差连接是什么？"><strong>一、残差连接是什么？</strong></h4><ul><li><strong>核心思想</strong>：允许输入信号直接“跳过”某些网络层，与这些层的输出相加，形成<code>输出 = 输入 + 层变换(输入)</code>的结构。</li><li><strong>数学表达</strong>：输出=x+F(x)。其中，x 是输入，F(x) 是某一层（或几层）的变换（如卷积、注意力等）。</li></ul><h4 id="二、为什么需要残差连接？"><strong>二、为什么需要残差连接？</strong></h4><ol><li><p><strong>缓解梯度消失/爆炸</strong>：</p><ul><li>深层网络中，反向传播时梯度需经过多层连乘，易衰减（消失）或膨胀（爆炸）。</li><li>残差连接提供“捷径”，梯度可直接通过加法从深层传回浅层，减少对连乘路径的依赖。</li></ul></li><li><p><strong>解决网络退化问题</strong>：</p><p>实验发现：单纯增加网络深度（如超过20层的CNN）会导致训练误差上升（非过拟合，而是模型难以优化）。</p></li></ol><h4 id="三、在Transformer中的应用"><strong>三、在Transformer中的应用</strong></h4><p>Transformer的每个子层（如自注意力层、前馈网络）均采用残差连接，具体流程如下：</p><ol><li><strong>输入处理</strong>：输入 x 进入子层（如多头注意力）。</li><li><strong>残差叠加</strong>：子层输出 F(x) 与原始输入 x 相加 → x+F(x)。</li><li><strong>层归一化</strong>：对叠加后的结果做归一化 → LayerNorm(x+F(x))。</li></ol><h4 id="四、残差连接-vs-普通连接"><strong>四、残差连接 vs 普通连接</strong></h4><table><thead><tr><th style="text-align:left"><strong>普通连接</strong></th><th style="text-align:left"><strong>残差连接</strong></th></tr></thead><tbody><tr><td style="text-align:left">输出 = 层变换(输入)</td><td style="text-align:left">输出 = 输入 + 层变换(输入)</td></tr><tr><td style="text-align:left">梯度依赖链式求导</td><td style="text-align:left">梯度可通过加法捷径回传</td></tr><tr><td style="text-align:left">深层易出现梯度消失</td><td style="text-align:left">缓解梯度消失，支持超深层网络</td></tr><tr><td style="text-align:left">需谨慎设计初始化/归一化</td><td style="text-align:left">训练更稳定，收敛更快</td></tr></tbody></table><h3 id="为什么Transformer的长距离依赖建模能力强">为什么Transformer的长距离依赖建模能力强</h3><p>在自然语言处理（NLP）中，长距离依赖（Long-Range Dependencies）指的是在文本中相隔较远的两个或多个元素之间的<a target="_blank" rel="noopener external nofollow noreferrer" href="https://so.csdn.net/so/search?q=%E4%BE%9D%E8%B5%96%E5%85%B3%E7%B3%BB&amp;spm=1001.2101.3001.7020">依赖关系</a>。这些依赖关系可以是语法上的，也可以是语义上的。例如，在句子中，一个从句的开始部分和结束部分可能相隔很远，但它们之间存在语法上的依赖关系；或者在长篇文章中，主题的引入和后面的详细阐述之间可能存在语义上的依赖。</p><p>在传统的循环神经网络（RNN）和长短期记忆网络（LSTM）中，捕捉长距离依赖是一个挑战，因为随着序列长度的增加，信息可能会逐渐丢失，导致模型难以捕捉到这些远距离的依赖关系。</p><p>Transformer模型通过自注意力机制（Self-Attention Mechanism）有效地解决了这个问题。自注意力机制允许模型在处理序列的每个元素时，考虑序列中所有其他元素的信息，无论它们相隔多远。这意味着每个元素的表示都可以直接包含整个序列的上下文信息，从而有效地捕捉长距离依赖。</p><p><strong>自注意力机制的关键在于它计算每个元素对序列中所有其他元素的注意力分数，然后根据这些分数对其他元素的表示进行加权求和，生成每个元素的最终表示。这个过程不受序列长度的限制，因此可以有效地处理长文本中的长距离依赖问题</strong></p><p>摘自： <a target="_blank" rel="noopener external nofollow noreferrer" href="https://blog.csdn.net/weixin_50512050/article/details/142590692">CSDN</a></p><ul><li><strong>传统模型的问题</strong>：<ul><li><strong>RNN</strong>：依赖链式时序传递，长距离信息需经过多步传播，易受梯度消失/爆炸影响。</li><li><strong>CNN</strong>：局部感受野需多层堆叠才能扩大，且多次卷积可能稀释远端信息。</li></ul></li><li><strong>Transformer的突破</strong>：<ul><li><strong>自注意力</strong>允许序列中的任意两个位置直接计算关联权重，无论距离多远（如第1个词和第1000个词一步交互）。</li><li><strong>权重计算公式</strong>：​​<br>每个位置的词通过查询（Query）与所有位置的键（Key）直接匹配，无距离限制。</li></ul></li></ul><h2 id="位置编码">位置编码</h2><p>阅读：<a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.zhihu.com/tardis/zm/art/675243992?source_id=1003">https://www.zhihu.com/tardis/zm/art/675243992?source_id=1003</a></p><p>在Transformer模型中，位置编码用于为序列中的每个位置注入位置信息，弥补自注意力机制本身不具备的位置感知能力。位置编码主要分为<strong>绝对位置编码</strong>和<strong>相对位置编码</strong>两大类，它们在建模位置信息的方式和应用场景上有显著差异。</p><h3 id="一、绝对位置编码（Absolute-Position-Encoding）"><strong>一、绝对位置编码（Absolute Position Encoding）</strong></h3><p><strong>核心思想</strong>：为序列中的每个绝对位置（如第1个词、第2个词等）分配一个独立的编码向量，直接与词嵌入相加。<br><strong>特点</strong>：</p><ul><li><strong>位置独立性</strong>：每个位置的编码是固定的，与序列长度无关。</li><li><strong>显式表示</strong>：直接编码绝对位置信息，如位置0、位置1等。</li></ul><h4 id="典型结构"><strong>典型结构</strong></h4><ol><li><p><strong>Sinusoidal位置编码（原始Transformer）</strong></p><ul><li>使用正弦和余弦函数的组合生成固定编码：<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>P</mi><msub><mi>E</mi><mrow><mo stretchy="false">(</mo><mi>p</mi><mi>o</mi><mi>s</mi><mo separator="true">,</mo><mn>2</mn><mi>i</mi><mo stretchy="false">)</mo></mrow></msub><mo>=</mo><mi>sin</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><mfrac><mrow><mi>p</mi><mi>o</mi><mi>s</mi></mrow><mrow><mn>1000</mn><msup><mn>0</mn><mrow><mn>2</mn><mi>i</mi><mi mathvariant="normal">/</mi><mi>d</mi></mrow></msup></mrow></mfrac><mo fence="true">)</mo></mrow><mo separator="true">,</mo><mspace width="1em"><mi>P</mi><msub><mi>E</mi><mrow><mo stretchy="false">(</mo><mi>p</mi><mi>o</mi><mi>s</mi><mo separator="true">,</mo><mn>2</mn><mi>i</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msub><mo>=</mo><mi>cos</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><mfrac><mrow><mi>p</mi><mi>o</mi><mi>s</mi></mrow><mrow><mn>1000</mn><msup><mn>0</mn><mrow><mn>2</mn><mi>i</mi><mi mathvariant="normal">/</mi><mi>d</mi></mrow></msup></mrow></mfrac><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">PE_{(pos, 2i)} = \sin\left(\frac{pos}{10000^{2i/d}}\right), \quad PE_{(pos, 2i+1)} = \cos\left(\frac{pos}{10000^{2i/d}}\right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.03853em;vertical-align:-.3551999999999999em"></span><span class="mord mathnormal" style="margin-right:.13889em">P</span><span class="mord"><span class="mord mathnormal" style="margin-right:.05764em">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.34480000000000005em"><span style="top:-2.5198em;margin-left:-.05764em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">os</span><span class="mpunct mtight">,</span><span class="mord mtight">2</span><span class="mord mathnormal mtight">i</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.3551999999999999em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.8539999999999999em;vertical-align:-.704em"></span><span class="mop">sin</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner"><span class="mopen delimcenter" style="top:0"><span class="delimsizing size2">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1075599999999999em"><span style="top:-2.2960000000000003em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1000</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.814em"><span style="top:-2.989em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mord mathnormal mtight">i</span><span class="mord mtight">/</span><span class="mord mathnormal mtight">d</span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal">p</span><span class="mord mathnormal">os</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.704em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0"><span class="delimsizing size2">)</span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:1em"></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathnormal" style="margin-right:.13889em">P</span><span class="mord"><span class="mord mathnormal" style="margin-right:.05764em">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.34480000000000005em"><span style="top:-2.5198em;margin-left:-.05764em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">os</span><span class="mpunct mtight">,</span><span class="mord mtight">2</span><span class="mord mathnormal mtight">i</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.3551999999999999em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.8539999999999999em;vertical-align:-.704em"></span><span class="mop">cos</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner"><span class="mopen delimcenter" style="top:0"><span class="delimsizing size2">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1075599999999999em"><span style="top:-2.2960000000000003em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1000</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.814em"><span style="top:-2.989em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mord mathnormal mtight">i</span><span class="mord mtight">/</span><span class="mord mathnormal mtight">d</span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal">p</span><span class="mord mathnormal">os</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.704em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0"><span class="delimsizing size2">)</span></span></span></span></span></span></span></p></li><li><strong>优点</strong>：可处理任意长度序列，无需训练。</li><li><strong>缺点</strong>：固定编码可能无法适应不同任务的数据分布。</li></ul></li><li><p><strong>可学习的位置编码（如BERT）</strong></p><ul><li>随机初始化一个位置嵌入矩阵，通过训练学习位置向量。</li><li><strong>优点</strong>：灵活适应任务需求。</li><li><strong>缺点</strong>：需要足够数据训练，对长序列泛化能力有限。</li></ul></li></ol><h3 id="二、相对位置编码（Relative-Position-Encoding）"><strong>二、相对位置编码（Relative Position Encoding）</strong></h3><p><strong>核心思想</strong>：建模词与词之间的相对距离（如“两个词相隔k个位置”），而非绝对位置。</p><p><strong>特点</strong>：</p><ul><li><strong>位置关系性</strong>：关注词对之间的相对偏移（如+1、-2等）。</li><li><strong>动态适应</strong>：对长序列更友好，能捕捉局部依赖。</li></ul><h4 id="典型结构-2"><strong>典型结构</strong></h4><ol><li><p><strong>经典相对位置编码（Transformer-XL）</strong></p><ul><li>在计算注意力分数时，引入相对位置偏置：<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>A</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>j</mi></mrow></msub><mo>=</mo><mtext>Softmax</mtext><mrow><mo fence="true">(</mo><mfrac><mrow><msub><mi>Q</mi><mi>i</mi></msub><msubsup><mi>K</mi><mi>j</mi><mi>T</mi></msubsup><mo>+</mo><msub><mi>b</mi><mrow><mi>i</mi><mo>−</mo><mi>j</mi></mrow></msub></mrow><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt></mfrac><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">A_{i,j} = \text{Softmax}\left( \frac{Q_i K_j^T + b_{i-j}}{\sqrt{d_k}} \right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.969438em;vertical-align:-.286108em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:3.0000299999999998em;vertical-align:-1.25003em"></span><span class="mord text"><span class="mord">Softmax</span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner"><span class="mopen delimcenter" style="top:0"><span class="delimsizing size4">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.626103em"><span style="top:-2.25278em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.85722em"><span class="svg-align" style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord" style="padding-left:.833em"><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.33610799999999996em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span><span style="top:-2.81722em"><span class="pstrut" style="height:3em"></span><span class="hide-tail" style="min-width:.853em;height:1.08em"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.18278000000000005em"><span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.7847720000000002em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:.07153em">K</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8413309999999999em"><span style="top:-2.441336em;margin-left:-.07153em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span></span></span><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.13889em">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.394772em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.93em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0"><span class="delimsizing size4">)</span></span></span></span></span></span></span></p></li><li>其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>b</mi><mrow><mi>i</mi><mo>−</mo><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">b_{i-j}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.980548em;vertical-align:-.286108em"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span></span></span></span> 是可学习的相对位置偏置，仅依赖相对距离 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mo>−</mo><mi>j</mi></mrow><annotation encoding="application/x-tex">i-j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.74285em;vertical-align:-.08333em"></span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.85396em;vertical-align:-.19444em"></span><span class="mord mathnormal" style="margin-right:.05724em">j</span></span></span></span>。</li></ul></li><li><p><strong>RoPE（Rotary Position Embedding，旋转位置编码）</strong></p><ul><li>通过复数域的旋转操作，将绝对位置编码融入相对位置计算，兼容两种信息（如LLaMA、ChatGLM采用）。</li></ul></li><li><p><strong>ALiBi（Attention with Linear Biases）</strong></p><ul><li>在注意力分数中直接添加一个与相对距离成线性关系的偏置项：<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>A</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>j</mi></mrow></msub><mo>=</mo><mtext>Softmax</mtext><mrow><mo fence="true">(</mo><msub><mi>Q</mi><mi>i</mi></msub><msubsup><mi>K</mi><mi>j</mi><mi>T</mi></msubsup><mo>−</mo><mi>m</mi><mo>⋅</mo><mi mathvariant="normal">∣</mi><mi>i</mi><mo>−</mo><mi>j</mi><mi mathvariant="normal">∣</mi><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">A_{i,j} = \text{Softmax}\left( Q_i K_j^T - m \cdot |i-j| \right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.969438em;vertical-align:-.286108em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.274439em;vertical-align:-.383108em"></span><span class="mord text"><span class="mord">Softmax</span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner"><span class="mopen delimcenter" style="top:0"><span class="delimsizing size1">(</span></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:.07153em">K</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.891331em"><span style="top:-2.4530000000000003em;margin-left:-.07153em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span></span></span><span style="top:-3.1130000000000004em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.13889em">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.383108em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord mathnormal">m</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord">∣</span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord mathnormal" style="margin-right:.05724em">j</span><span class="mord">∣</span><span class="mclose delimcenter" style="top:0"><span class="delimsizing size1">)</span></span></span></span></span></span></span></p></li><li><strong>优点</strong>：无需显式位置嵌入，适合超长序列（如Transformer-XL的改进版）。</li></ul></li></ol><h3 id="三、绝对-vs-相对位置编码的异同"><strong>三、绝对 vs. 相对位置编码的异同</strong></h3><table><thead><tr><th><strong>特性</strong></th><th><strong>绝对位置编码</strong></th><th><strong>相对位置编码</strong></th></tr></thead><tbody><tr><td><strong>建模对象</strong></td><td>单个位置的绝对坐标</td><td>词对之间的相对距离</td></tr><tr><td><strong>泛化能力</strong></td><td>对训练数据中的位置分布敏感</td><td>更易泛化到未见过的序列长度</td></tr><tr><td><strong>长序列处理</strong></td><td>可能因位置嵌入矩阵过大而受限</td><td>天然支持长序列（如ALiBi、RoPE）</td></tr><tr><td><strong>实现复杂度</strong></td><td>简单（直接相加或拼接）</td><td>复杂（需修改注意力计算逻辑）</td></tr><tr><td><strong>典型应用</strong></td><td>短文本（BERT、GPT）</td><td>长文本（Transformer-XL、LLaMA）</td></tr></tbody></table><h4 id="核心差异"><strong>核心差异</strong></h4><ul><li><strong>绝对位置编码</strong>：直接告诉模型“当前词在第几个位置”。</li><li><strong>相对位置编码</strong>：告诉模型“两个词之间相隔多远”，更关注局部关系。</li></ul><h3 id="相对位置编码与位置编码外推">相对位置编码与位置编码外推</h3><p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://blog.csdn.net/v_JULY_v/article/details/135072211">https://blog.csdn.net/v_JULY_v/article/details/135072211</a></p><p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://blog.csdn.net/v_JULY_v/article/details/134085503">https://blog.csdn.net/v_JULY_v/article/details/134085503</a></p><p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://kexue.fm/archives/9675">https://kexue.fm/archives/9675</a></p><p>也可以参考阅读：</p><p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.zhihu.com/tardis/zm/art/675243992?source_id=1003">https://www.zhihu.com/tardis/zm/art/675243992?source_id=1003</a></p><p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://zhuanlan.zhihu.com/p/670149880">https://zhuanlan.zhihu.com/p/670149880</a></p><p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://zhuanlan.zhihu.com/p/632780188">https://zhuanlan.zhihu.com/p/632780188</a></p><h2 id="注意力">注意力</h2><p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://zh.d2l.ai/chapter_attention-mechanisms/index.html">https://zh.d2l.ai/chapter_attention-mechanisms/index.html</a></p><h3 id="注意力与自注意力的区别">注意力与自注意力的区别</h3><p>简单来说，自注意力是一种特殊的注意力机制。</p><p>传统的Attention机制在一般任务的Encoder-Decoder model中，输入Source和输出Target内容是不一样的，比如对于英-中机器翻译来说，Source是英文句子，Target是对应的翻译出的中文句子，Attention机制发生在Target的元素Query和Source中的所有元素之间。简单的讲就是Attention机制中的权重的计算需要Target来参与的，即在Encoder-Decoder model中Attention权值的计算不仅需要Encoder中的隐状态而且还需要Decoder 中的隐状态。</p><p>而Self Attention顾名思义，指的不是Target和Source之间的Attention机制，而是Source内部元素之间或者Target内部元素之间发生的Attention机制，也可以理解为Target=Source这种特殊情况下的注意力计算机制。例如在Transformer中在计算权重参数时将文字向量转成对应的KQV，只需要在Source处进行对应的矩阵操作，用不到Target中的信息。</p><p>作者：知乎用户7icl58<br>链接：<a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.zhihu.com/question/397509972/answer/1893323493">https://www.zhihu.com/question/397509972/answer/1893323493</a><br>来源：知乎。著作权归作者所有。</p><p>从本质上理解，Attention是从大量信息中有筛选出少量重要信息，并聚焦到这些重要信息上，忽略大多不重要的信息。权重越大越聚焦于其对应的Value值上，即权重代表了信息的重要性，而Value是其对应的信息。</p><p>至于Attention机制的具体计算过程，如果对目前大多数方法进行抽象的话，可以将其归纳为两个过程：<strong>第一个过程是根据Query和Key计算权重系数</strong>，<strong>第二个过程根据权重系数对Value进行加权求和</strong>。而第一个过程又可以细分为两个阶段：第一个阶段根据Query和Key计算两者的相似性或者相关性；第二个阶段对第一阶段的原始分值进行归一化处理；</p><p>自注意力机制是注意力机制的变体，其减少了对外部信息的依赖，更擅长捕捉数据或特征的内部相关性。自注意力机制在文本中的应用，主要是通过计算单词间的互相影响，来解决长距离依赖问题。其思想和attention类似，但是self-attention是Transformer用来将其他相关单词的“理解”转换成我们正在处理的单词的一种思路。</p><p>自注意力机制的计算过程：</p><p>1.将输入单词转化成嵌入向量；</p><p>2.根据嵌入向量得到q，k，v三个向量；</p><p>3.为每个向量计算一个score：score =q . k ；</p><p>4.为了梯度的稳定，<a target="_blank" rel="noopener external nofollow noreferrer" href="https://zhida.zhihu.com/search?content_id=147043687&amp;content_type=Article&amp;match_order=1&amp;q=Transformer&amp;zhida_source=entity">Transformer</a>使用了score归一化，即除以 dk ；</p><p>5.对score施以softmax激活函数；</p><p>6.softmax点乘Value值v，得到加权的每个输入向量的评分v；</p><p>7.相加之后得到最终的输出结果z ：z= ∑ v。</p><p>来自：<a target="_blank" rel="noopener external nofollow noreferrer" href="https://zhuanlan.zhihu.com/p/265108616">知乎</a></p><p>自注意力机制（Self-Attention）和注意力机制（Attention Mechanism）的核心区别在于<strong>输入来源和应用目标</strong>，具体差异可以从以下几个角度分析：</p><hr><h4 id="1-输入来源不同">1. <strong>输入来源不同</strong></h4><ul><li><p><strong>注意力机制</strong>（跨注意力）：</p><ul><li>处理<strong>两个不同序列</strong>之间的关系。例如，在机器翻译中：<ul><li><strong>查询（Query）</strong>：来自解码器的当前状态（目标序列）。</li><li><strong>键（Key）和值（Value）</strong>：来自编码器的输出（源序列）。</li></ul></li><li><strong>目标</strong>：动态对齐不同序列的信息（如源语言与目标语言）。</li></ul></li><li><p><strong>自注意力机制</strong>：</p><ul><li>处理<strong>同一序列内部</strong>的关系。<ul><li><strong>查询、键、值</strong>均来自同一输入序列（例如源句子的各个词）。</li></ul></li><li><strong>目标</strong>：捕捉序列内部的上下文依赖（如词与词之间的关联）。</li></ul></li></ul><hr><h4 id="2-应用场景不同">2. <strong>应用场景不同</strong></h4><ul><li><p><strong>注意力机制</strong>：</p><ul><li>常用于<strong>编码器-解码器架构</strong>，解决长距离信息丢失问题。</li><li>例：Seq2Seq模型（如RNN+Attention）中，解码器生成目标词时关注编码器的相关部分。</li></ul></li><li><p><strong>自注意力机制</strong>：</p><ul><li>用于<strong>单序列的上下文建模</strong>，替代RNN/CNN捕捉长距离依赖。</li><li>例：Transformer的编码器中，每个词通过自注意力与整个输入序列交互。</li></ul></li></ul><hr><h4 id="3-计算方式与结构特点">3. <strong>计算方式与结构特点</strong></h4><ul><li><p><strong>注意力机制</strong>：</p><ul><li>计算<strong>跨序列相关性</strong>，权重反映两个序列元素间的重要性。</li><li>通常没有多头设计，直接计算单组注意力权重。</li></ul></li><li><p><strong>自注意力机制</strong>：</p><ul><li>计算<strong>序列内部的相关性</strong>，权重反映同一序列中元素的重要性。</li><li>常结合<strong>多头注意力</strong>（Multi-Head Attention），将输入投影到多个子空间，并行捕捉不同维度的关系。</li><li>在Transformer中，自注意力通过缩放点积（Scaled Dot-Product）高效计算。</li></ul></li></ul><hr><h4 id="4-功能与优势对比">4. <strong>功能与优势对比</strong></h4><table><thead><tr><th><strong>维度</strong></th><th><strong>注意力机制</strong></th><th><strong>自注意力机制</strong></th></tr></thead><tbody><tr><td><strong>输入关系</strong></td><td>跨序列（如源-目标）</td><td>同序列内部</td></tr><tr><td><strong>依赖捕捉</strong></td><td>局部或全局跨序列对齐</td><td>全局序列内长距离依赖</td></tr><tr><td><strong>并行性</strong></td><td>依赖编码器/解码器的结构（如RNN）</td><td>完全并行计算（无递归结构）</td></tr><tr><td><strong>典型应用</strong></td><td>Seq2Seq任务（如翻译、摘要）</td><td>Transformer、BERT、GPT等模型</td></tr></tbody></table><hr><h4 id="总结"><strong>总结</strong></h4><ul><li><strong>注意力机制</strong>是<strong>跨序列的信息筛选工具</strong>，解决两个序列间的动态对齐问题。</li><li><strong>自注意力机制</strong>是<strong>序列内部的上下文建模工具</strong>，通过全局交互增强表征能力。两者共同成为Transformer等现代模型的核心组件。</li></ul><h3 id="通过向量计算自注意力">通过向量计算自注意力</h3><p>摘自 <a target="_blank" rel="noopener external nofollow noreferrer" href="https://blog.csdn.net/v_JULY_v/article/details/127411638">CSDN v_JULY_v</a></p><h4 id="第一步：生成查询向量、键向量和值向量"><strong>第一步：生成查询向量、键向量和值向量</strong></h4><ul><li><strong>Query（Q）</strong>：发起查询，决定“关注什么”。</li><li><strong>Key（K）</strong>：提供索引，确定“哪里重要”。</li><li><strong>Value（V）</strong>：携带内容，提供“提取什么”。</li></ul><p>通过向量方式计算自注意力的第一步，就是从每个编码器的输入向量(即每个单词的词向量)生成三个向量：查询向量query-vec、键向量key-vec、值向量value-vec</p><ol><li><em>查询向量、键向量、值向量这三个向量的维度在论文中设置的是<strong>64</strong>，在维度上比词嵌入向量更低，因为词嵌入和编码器的输入/输出向量的维度是512，但也不是必须比编码器输入输出的维数小，这样做主要是为了让后续多头注意力的计算更稳定</em></li><li><em>在下文你会看到，transformer通过多头注意力机制multi headed attention，对每个512维的输入向量都设置了8个头，不同的头关注每个输入向量不同的部分，而<strong>每个头的维度则是：512/8 = 64</strong>，且再多说一句，也可以设置为2个头，不一定非得设置为8个头</em></li></ol><p>至于这三个向量的生成方法是把输入的向量分别乘以三个不同的权重矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mi>Q</mi></msup></mrow><annotation encoding="application/x-tex">W^{Q}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8413309999999999em;vertical-align:0"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8413309999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">Q</span></span></span></span></span></span></span></span></span></span></span></span>、<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mi>K</mi></msup></mrow><annotation encoding="application/x-tex">W^{K}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8413309999999999em;vertical-align:0"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8413309999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.07153em">K</span></span></span></span></span></span></span></span></span></span></span></span>、<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mi>V</mi></msup></mrow><annotation encoding="application/x-tex">W^{V}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8413309999999999em;vertical-align:0"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8413309999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.22222em">V</span></span></span></span></span></span></span></span></span></span></span></span>，得到Q、K、V，而这些权重矩阵是在模型训练阶段中训练出来的</p><blockquote><ol><li><strong>对于权重矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mi>Q</mi></msup></mrow><annotation encoding="application/x-tex">W^{Q}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8413309999999999em;vertical-align:0"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8413309999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">Q</span></span></span></span></span></span></span></span></span></span></span></span>/<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mi>K</mi></msup></mrow><annotation encoding="application/x-tex">W^{K}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8413309999999999em;vertical-align:0"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8413309999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.07153em">K</span></span></span></span></span></span></span></span></span></span></span></span>/<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mi>V</mi></msup></mrow><annotation encoding="application/x-tex">W^{V}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8413309999999999em;vertical-align:0"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8413309999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.22222em">V</span></span></span></span></span></span></span></span></span></span></span></span>如何训练出来的</strong>，还是标准老套路：<strong>先随机初始化，然后在损失函数中表示出来，最后通过反向传播不断优化学习得出，最终目标是最小化模型的预测误差</strong><a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.julyedu.com/questions/interview-detail?kp_id=26&amp;cate=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0&amp;quesId=2921">https://www.julyedu.com/questions/interview-detail?kp_id=26&amp;cate=深度学习&amp;quesId=2921</a> “参考文献17”)</li><li>当然，值得注意的是，这些权重矩阵是模型参数的一部分，除了自注意力层，模型参数还包括：_嵌入层(词嵌入矩阵、位置编码)、层归一化参数(比如缩放参数)、MLP全连接层权重(包含升维 降维 偏置因子)、输出层(线性变换的投影矩阵)_等一系列参数 。而整个模型的损失函数会基于最终的输出(比如预测的下一个词的概率分布)与真实标签之间的差异来计算损失，然后通过反向传播算法将梯度传递回各个参数</li></ol></blockquote><p>为形象起见，还是举例来说明，在我们有了权重矩阵后，对于单词<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>X</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">X_{1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.83333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.07847em">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.07847em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span>、<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>X</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">X_{2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.83333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.07847em">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.07847em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span>分别而言（假定X1是Thinking，X2是Machines)：</p><img src="/d305fa446b6542d29ae8e7ac0d15f45c.png" style="zoom:30%"><ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>X</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">X_{1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.83333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.07847em">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.07847em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span>与<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mi>Q</mi></msup></mrow><annotation encoding="application/x-tex">W^{Q}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8413309999999999em;vertical-align:0"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8413309999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">Q</span></span></span></span></span></span></span></span></span></span></span></span>权重矩阵相乘得到与这个单词相关的查询向量<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">q_{1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span>、<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>X</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">X_{1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.83333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.07847em">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.07847em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span>与<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mi>K</mi></msup></mrow><annotation encoding="application/x-tex">W^{K}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8413309999999999em;vertical-align:0"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8413309999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.07153em">K</span></span></span></span></span></span></span></span></span></span></span></span>权重矩阵相乘得到与这个单词相关的键向量<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>k</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">k_{1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.84444em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03148em">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.03148em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span>、<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>X</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">X_{1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.83333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.07847em">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.07847em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span>与<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mi>V</mi></msup></mrow><annotation encoding="application/x-tex">W^{V}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8413309999999999em;vertical-align:0"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8413309999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.22222em">V</span></span></span></span></span></span></span></span></span></span></span></span>权重矩阵相乘得到与这个单词相关的值向量<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">v_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.58056em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span></li><li>对于单词<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>X</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">X_{2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.83333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.07847em">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.07847em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span>而言，依上类推：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>X</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">X_{2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.83333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.07847em">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.07847em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span>分别与<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mi>Q</mi></msup></mrow><annotation encoding="application/x-tex">W^{Q}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8413309999999999em;vertical-align:0"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8413309999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">Q</span></span></span></span></span></span></span></span></span></span></span></span>、<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mi>K</mi></msup></mrow><annotation encoding="application/x-tex">W^{K}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8413309999999999em;vertical-align:0"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8413309999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.07153em">K</span></span></span></span></span></span></span></span></span></span></span></span>、<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mi>V</mi></msup></mrow><annotation encoding="application/x-tex">W^{V}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8413309999999999em;vertical-align:0"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8413309999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.22222em">V</span></span></span></span></span></span></span></span></span></span></span></span>相乘得到该单词的查询向量<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">q_{2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span>、键向量<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>k</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">k_{2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.84444em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03148em">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.03148em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span>、值向量<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">v_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.58056em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span></li></ul><p>最终使得输入序列的每个单词各自创建一个查询向量、一个键向量和一个值向量</p><p>可能有的读者有疑问了，设置这三个向量的用意何在或有何深意，实际上</p><ul><li>查询向量Query是当前单词的表示形式，用于对所有其他单词(key)进行评分，我们只需要关注当前正在处理的token的query</li><li>键向量Key可以看做是序列中所有单词的标签，是在我们找相关单词时候的对照物</li><li>值向量Value是单词的实际表示，一旦我们对每个单词的相关度打分之后，我们就要对value进行相加表示当前正在处理单词的value</li></ul><h4 id="第二步：计算得分"><strong>第二步：计算得分</strong></h4><p>接下来，我们需要针对这个例子中的第一个单词“Thinking”（pos#1）计算attention分值，即计算每个词对“Thinking”的打分，这个分决定着编码“Thinking”时(某个固定位置时)，应该对其他位置上的单词<strong>各自</strong>给予多少关注度</p><p>这个得分通过“Thinking”所对应的查询向量query和所有词的键向量key，依次乘积得出来。所以如果我们是处理位置最靠前的词的attention分值的话</p><ul><li><p>第一个分数是q1和k1的点积(根据点积结果可以判断<strong>q1和k1这个向量的相似性</strong>)</p></li><li><p>第二个分数是q1和k2的点积(根据点积结果可以判断q1<strong>和k2这个向量的相似性</strong>)</p><img src="46bdeb03108248b7beb5af9ab11408fc.png" style="zoom:33%"></li></ul><h4 id="第三、四步：分数除以8然后softmax">第三、四步：分数除以8然后softmax</h4><p>第三步和第四步分别是：</p><ul><li>将分数除以8（8是论文中使用的键向量的维数64的平方根，这会让梯度更稳定，也可以使用其它值）</li><li>然后通过softmax传递结果，softmax的作用是使所有单词的分数归一化，得到的分数都是正值且它们的和为1</li></ul><img src="3a458138fa0143f09ff1cc4a173f604b.png" style="zoom:33%"><p>这个softmax分数决定了在编码当下位置（“Thinking”）时，包括当下位置单词（“Thinking”）在内每个单词的所获得的关注度。显然，正在当下位置上的<strong>Thinking</strong>获得最高的softmax分数(毕竟自己跟自己最相似嘛，所以编码thinking时对Thinking、Machines的注意力分数分配是：0.88 0.12)。</p><h4 id="第五、六步：值向量乘以softmax分数后对加权值向量求和">第五、六步：值向量乘以softmax分数后对加权值向量求和</h4><p>第五步是将softmax分值乘以每个值向量，这样操作的意义在于留下我们想要关注的单词的value，并把其他不相关的单词丢掉(例如，让它们乘以0.001这样的小数)</p><p>第六步是对加权值向量求和，产生“<strong>Thinking</strong>”的self-attention的输出结果</p><img src="718958702e554e1281ff41a0986060db.png" style="zoom:33%"><p>接下来，针对每个单词都进行上述六个步骤的自注意力得分计算，相当于</p><ol><li><p>先是“Thinking”对应的query(q1)与各个不同的key(k1、k2)计算相似度，然后除以8继而softmax，最后softmax值乘以值向量v1、v2并加权求和<br>即：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mn>1</mn></msub><mo>=</mo><mi>s</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">[</mo><mo stretchy="false">(</mo><msub><mi>q</mi><mn>1</mn></msub><msub><mi>k</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mi mathvariant="normal">/</mi><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt><mo stretchy="false">]</mo><mo>×</mo><msub><mi>v</mi><mn>1</mn></msub><mo>+</mo><mi>s</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">[</mo><mo stretchy="false">(</mo><msub><mi>q</mi><mn>1</mn></msub><msub><mi>k</mi><mn>2</mn></msub><mo stretchy="false">)</mo><mi mathvariant="normal">/</mi><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt><mo stretchy="false">]</mo><mo>×</mo><msub><mi>v</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">z_1 = softmax [(q_1k_1)/\sqrt{d_k}] \times v_1 + softmax [(q_1k_2)/\sqrt{d_k}] \times v_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.58056em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.04398em">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.04398em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.1072199999999999em;vertical-align:-.25em"></span><span class="mord mathnormal">so</span><span class="mord mathnormal" style="margin-right:.10764em">f</span><span class="mord mathnormal">t</span><span class="mord mathnormal">ma</span><span class="mord mathnormal">x</span><span class="mopen">[(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03148em">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.03148em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord">/</span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.85722em"><span class="svg-align" style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord" style="padding-left:.833em"><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.33610799999999996em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span><span style="top:-2.81722em"><span class="pstrut" style="height:3em"></span><span class="hide-tail" style="min-width:.853em;height:1.08em"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.18278000000000005em"><span></span></span></span></span></span><span class="mclose">]</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.73333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1.1072199999999999em;vertical-align:-.25em"></span><span class="mord mathnormal">so</span><span class="mord mathnormal" style="margin-right:.10764em">f</span><span class="mord mathnormal">t</span><span class="mord mathnormal">ma</span><span class="mord mathnormal">x</span><span class="mopen">[(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03148em">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.03148em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord">/</span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.85722em"><span class="svg-align" style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord" style="padding-left:.833em"><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.33610799999999996em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span><span style="top:-2.81722em"><span class="pstrut" style="height:3em"></span><span class="hide-tail" style="min-width:.853em;height:1.08em"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.18278000000000005em"><span></span></span></span></span></span><span class="mclose">]</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.58056em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span>，注：下图里的b1相当于z1</p><img src="9713048732378c51c8158e000cc8dd2d.png" style="zoom:33%"></li><li><p>再是“Machines”对应的query(q2)与各个不同的key(k1、k2)计算相似度，然后也除以8继而softmax，最后softmax值乘以值向量v1、v2并加权求和<br>即：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mn>2</mn></msub><mo>=</mo><mi>s</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">[</mo><mo stretchy="false">(</mo><msub><mi>q</mi><mn>2</mn></msub><msub><mi>k</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mi mathvariant="normal">/</mi><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt><mo stretchy="false">]</mo><mo>×</mo><msub><mi>v</mi><mn>1</mn></msub><mo>+</mo><mi>s</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">[</mo><mo stretchy="false">(</mo><msub><mi>q</mi><mn>2</mn></msub><msub><mi>k</mi><mn>2</mn></msub><mo stretchy="false">)</mo><mi mathvariant="normal">/</mi><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt><mo stretchy="false">]</mo><mo>×</mo><msub><mi>v</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">z_2 = softmax [(q_2k_1)/\sqrt{d_k}] \times v_1 + softmax [(q_2k_2)/\sqrt{d_k}] \times v_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.58056em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.04398em">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.04398em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.1072199999999999em;vertical-align:-.25em"></span><span class="mord mathnormal">so</span><span class="mord mathnormal" style="margin-right:.10764em">f</span><span class="mord mathnormal">t</span><span class="mord mathnormal">ma</span><span class="mord mathnormal">x</span><span class="mopen">[(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03148em">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.03148em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord">/</span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.85722em"><span class="svg-align" style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord" style="padding-left:.833em"><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.33610799999999996em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span><span style="top:-2.81722em"><span class="pstrut" style="height:3em"></span><span class="hide-tail" style="min-width:.853em;height:1.08em"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.18278000000000005em"><span></span></span></span></span></span><span class="mclose">]</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.73333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1.1072199999999999em;vertical-align:-.25em"></span><span class="mord mathnormal">so</span><span class="mord mathnormal" style="margin-right:.10764em">f</span><span class="mord mathnormal">t</span><span class="mord mathnormal">ma</span><span class="mord mathnormal">x</span><span class="mopen">[(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03148em">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.03148em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord">/</span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.85722em"><span class="svg-align" style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord" style="padding-left:.833em"><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.33610799999999996em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span><span style="top:-2.81722em"><span class="pstrut" style="height:3em"></span><span class="hide-tail" style="min-width:.853em;height:1.08em"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.18278000000000005em"><span></span></span></span></span></span><span class="mclose">]</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.58056em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span>，注：下图里的b2相当于z2</p><img src="c8ac2534b217fd9b8fbdd296732191ab.png" style="zoom:33%"></li></ol><blockquote><p>为更加一目了然，且如果不考虑缩放、softmax等因素，那么这一系列的计算过程可以简化为(注意，如果是GPT那种单向的结构，则只有其中带下划线的计算部分)</p><ol><li>q1<strong>k1 v1</strong>、q1k2 v2、q1k3 v3、q1k4 v4</li><li>q2<strong>k1 v1</strong>、q2<strong>k2 v2</strong>、q2k3 v3、q2k4 v4</li><li>q3<strong>k1 v1</strong>、q3<strong>k2 v2</strong>、q3<strong>k3 v3</strong>、q3k4 v4</li><li>q4<strong>k1 v1</strong>、q4<strong>k2 v2</strong>、q4<strong>k3 v3</strong>、q4<strong>k4 v4</strong></li></ol></blockquote><p>最终每个词的输出向量<img src="https://latex.csdn.net/eq?z_i" alt="z_i">都包含了其他词的信息，每个词都不再是孤立的了，而且词与词的相关程度可以通过softmax输出的权重进行分析</p><p><img src="cb33a1823d4f2adcdae42d0a5ed1855f.png" alt=""></p><p>如此，所有单词的自注意力计算就完成了，得到的向量就可以传给前馈神经网络。然而实际中，这些计算是以矩阵形式完成的，以便算得更快。这部分可以阅读原博客对应部分</p><h3 id="为什么用KV-Cache">为什么用KV Cache</h3><p>KV Cache（键值缓存）是一种在自回归模型（如Transformer）生成序列时广泛使用的优化技术，主要用于<strong>大幅提升推理效率</strong>，尤其是在生成长文本时。以下是其核心原因和优势：</p><h4 id="1-避免重复计算，降低计算复杂度"><strong>1. 避免重复计算，降低计算复杂度</strong></h4><ul><li><p><strong>问题背景</strong>：在自回归生成中（如GPT生成文本），每个新token的生成都依赖于之前所有token的注意力计算结果。若不缓存，每次生成时需重新计算所有历史token的键（Key）和值（Value），时间复杂度为<em>O(n²)</em>。</p></li><li><p><strong>KV Cache的作用</strong>：缓存历史token的Key和Value向量，每次生成新token时只需计算当前token的K和V，并与缓存拼接。整体时间复杂度降至<em>O(n)</em>。</p><p><strong>公式对比</strong>：</p><ul><li>无缓存：第<code>t</code>步计算量为 <code>t</code> 次（序列长度从1到t）。</li><li>有缓存：第<code>t</code>步仅计算当前token，总计算量为 <code>1+2+...+n ≈ n²/2</code> → 优化为 <code>n</code>。</li></ul></li></ul><h4 id="2-减少内存访问开销"><strong>2. 减少内存访问开销</strong></h4><ul><li><strong>硬件瓶颈</strong>：GPU/TPU的内存带宽有限，频繁读写大张量会拖慢速度。</li><li><strong>KV Cache优化</strong>：通过缓存历史K和V，避免重复从显存中加载参数和中间结果，减少内存访问次数，提升计算效率。</li></ul><h4 id="3-支持更长的生成序列"><strong>3. 支持更长的生成序列</strong></h4><ul><li><strong>长文本场景</strong>：在对话、故事生成等任务中，序列长度可能达到数千token。若每次重新计算所有历史token的K和V，显存和计算资源会快速耗尽。</li><li><strong>KV Cache的权衡</strong>：以空间换时间，显存中仅需存储历史K和V（通常占模型总参数的10%~30%），即可支持生成超长文本。</li></ul><h4 id="KV-Cache的代价"><strong>KV Cache的代价</strong></h4><ul><li><strong>显存占用增加</strong>：缓存历史K和V需要额外显存，尤其是大模型和长序列场景（例如，Llama-3 70B生成4096 token需约5GB显存）。</li><li><strong>工程优化</strong>：需合理管理缓存（如滑动窗口、压缩），避免显存溢出。</li></ul><h2 id="超参数">超参数</h2><p>在大语言模型中，温度系数（Temperature）、Top-K 和 Top-P 都是用于控制生成文本随机性和多样性的重要参数，但它们的实现方式和作用机制有所不同。以下是三者的具体区别和典型应用场景：</p><h3 id="一、温度系数（Temperature）"><strong>一、温度系数（Temperature）</strong></h3><h4 id="作用机制">作用机制</h4><ul><li><p>通过调整 softmax 前的 logits 值改变概率分布的平滑程度。</p></li><li><p>公式：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>P</mi><mtext>new</mtext></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>z</mi><mi>i</mi></msub><mi mathvariant="normal">/</mi><mi>T</mi><mo stretchy="false">)</mo></mrow><mrow><munder><mo>∑</mo><mi>j</mi></munder><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>z</mi><mi>j</mi></msub><mi mathvariant="normal">/</mi><mi>T</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">P_{\text{new}}(x) = \frac{\exp(z_i / T)}{\sum_j \exp(z_j / T)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.151392em"><span style="top:-2.5500000000000003em;margin-left:-.13889em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">new</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:2.5488180000000003em;vertical-align:-1.1218180000000002em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-.0000050000000000050004em">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.16195399999999993em"><span style="top:-2.40029em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.43581800000000004em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mop">exp</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.04398em">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:-.04398em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mord">/</span><span class="mord mathnormal" style="margin-right:.13889em">T</span><span class="mclose">)</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mop">exp</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.04398em">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:-.04398em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mord">/</span><span class="mord mathnormal" style="margin-right:.13889em">T</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.1218180000000002em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><p>其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi></mrow><annotation encoding="application/x-tex">T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.13889em">T</span></span></span></span> 是温度值，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">z_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.58056em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.04398em">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:-.04398em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 是原始 logits。</p></li></ul><h4 id="效果">效果</h4><ul><li>高温：<br>概率分布更平缓，低概率词被提升，生成结果更多样化、更具创造性，但可能不连贯。<br>例如：生成诗歌或创意故事时使用。</li><li>低温：<br>概率分布更尖锐，高概率词被强化，生成结果更保守、确定性更强。<br>例如：生成技术文档或需要高准确性的场景。</li></ul><h3 id="二、Top-K-采样"><strong>二、Top-K 采样</strong></h3><h4 id="作用机制-2">作用机制</h4><ul><li>从概率最高的前 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.07153em">K</span></span></span></span> 个候选词中重新分配概率并采样。</li><li>固定选择数量，无论概率高低，只保留前 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.07153em">K</span></span></span></span> 个词。</li></ul><h4 id="效果-2">效果</h4><ul><li><strong>K 值大</strong>：候选词范围广，生成结果多样性高，但可能包含低质量词。</li><li><strong>K 值小</strong>：生成结果更安全，但可能重复或缺乏新意。</li></ul><h3 id="三、Top-P（Nucleus-Sampling）"><strong>三、Top-P（Nucleus Sampling）</strong></h3><h4 id="作用机制-3">作用机制</h4><ul><li>从累积概率超过阈值 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.13889em">P</span></span></span></span> 的最小候选词集合中采样。</li><li>动态选择词的数量，可能每次生成的候选词数量不同。</li></ul><h4 id="效果-3">效果</h4><ul><li><strong>P 值大（如 0.95）</strong>：候选词多，结果多样化。</li><li><strong>P 值小（如 0.5）</strong>：候选词少，结果更确定。</li></ul><h2 id="幻觉">幻觉</h2><p>大模型的“幻觉”（Hallucination）指的是生成内容看似合理但缺乏事实依据、存在错误或虚构信息的问题。这是由于模型在训练过程中过度依赖统计规律，而非真正的逻辑推理或事实验证。以下是解决大模型幻觉问题的系统性方法，分为预防、生成时干预和后处理三个阶段：</p><h3 id="一、预防阶段：优化模型训练与架构"><strong>一、预防阶段：优化模型训练与架构</strong></h3><ol><li><p><strong>提升数据质量与多样性</strong></p><ul><li><strong>数据清洗</strong>：过滤训练数据中的噪声、错误或冲突信息，减少模型学习错误知识的概率。</li><li><strong>引入高质量知识库</strong>：结合结构化知识（如维基百科、专业数据库）与非结构化文本，增强模型对事实的依赖。</li><li><strong>领域平衡</strong>：避免特定领域数据过载导致模型偏向生成不相关的内容。</li></ul></li><li><p><strong>改进模型架构</strong></p><ul><li><strong>知识蒸馏（Knowledge Distillation）</strong>：用大模型训练小模型，通过简化结构和减少过参数化降低幻觉风险。</li><li><strong>混合专家模型（MoE）</strong>：通过分治策略，让不同专家模块处理不同任务，减少通用生成中的不确定性。</li><li><strong>显式知识嵌入</strong>：在模型中集成可解释的知识图谱模块，强制生成结果与已知事实对齐。</li></ul></li><li><p><strong>训练目标优化</strong></p><ul><li><strong>事实性损失函数</strong>：在训练中引入基于事实正确性的惩罚项（如对比学习），鼓励模型生成可信内容。</li><li><strong>多任务学习</strong>：联合训练生成任务与事实验证任务（如问答、文本蕴含），增强模型自我验证能力。</li></ul></li></ol><h3 id="二、生成时干预：控制输出可靠性"><strong>二、生成时干预：控制输出可靠性</strong></h3><ol><li><p><strong>检索增强生成（RAG, Retrieval-Augmented Generation）</strong></p><ul><li>在生成过程中动态检索外部知识库（如搜索引擎、数据库），将检索结果作为生成依据，避免依赖内部记忆。</li><li>示例：ChatGPT 的 Bing 搜索插件通过实时检索补充事实信息。</li></ul></li><li><p><strong>提示工程（Prompt Engineering）</strong></p><ul><li><strong>明确约束</strong>：在输入中限定生成范围（如“仅基于2023年后的信息回答”）。</li><li><strong>链式推理（Chain-of-Thought）</strong>：要求模型分步解释逻辑，暴露潜在错误。</li><li><strong>自我质疑提示</strong>：例如“请先验证以下陈述是否正确：……”。</li></ul></li><li><p><strong>解码策略优化</strong></p><ul><li><strong>基于知识采样的解码</strong>：对候选输出的每个token进行事实概率评估（如引入知识库匹配度打分）。</li><li><strong>不确定性校准</strong>：通过蒙特卡洛采样检测模型对生成内容的置信度，过滤低置信度结果。</li></ul></li></ol><h3 id="三、后处理：验证与修正"><strong>三、后处理：验证与修正</strong></h3><ol><li><p><strong>事实性验证工具</strong></p><ul><li>使用独立的事实核查模型（如DeFacto、FEVER）或API（如Google Fact Check Tools）对生成内容进行二次验证。</li><li>针对特定领域训练验证模型（如医疗、法律），提升针对性。</li></ul></li><li><p><strong>人工反馈与强化学习（RLHF）</strong></p><ul><li>收集用户对幻觉的标注数据，通过强化学习调整模型生成偏好。</li><li>构建闭环系统：用户标记错误→模型微调→迭代优化。</li></ul></li><li><p><strong>可解释性分析</strong></p><ul><li>可视化模型注意力权重，定位生成错误的知识来源。</li><li>使用对抗样本测试模型的鲁棒性，发现潜在幻觉模式。</li></ul></li></ol><h3 id="四、长期解决方案"><strong>四、长期解决方案</strong></h3><ol><li><strong>动态知识更新</strong><ul><li>构建实时更新的知识库（如增量学习或外部知识接口），避免模型知识过时。</li></ul></li><li><strong>因果推理能力增强</strong><ul><li>通过引入符号逻辑模块或因果图模型，提升模型对因果关系的理解。</li></ul></li><li><strong>多模态输入验证</strong><ul><li>结合文本、图像、视频等多模态信息交叉验证生成内容的真实性。</li></ul></li></ol><h2 id="微调">微调</h2><p>可以直接阅读：<a target="_blank" rel="noopener external nofollow noreferrer" href="https://blog.csdn.net/v_JULY_v/article/details/132116949">https://blog.csdn.net/v_JULY_v/article/details/132116949</a></p><h3 id="LoRA">LoRA</h3><p>摘自：<a target="_blank" rel="noopener external nofollow noreferrer" href="https://blog.csdn.net/v_JULY_v/article/details/132116949">https://blog.csdn.net/v_JULY_v/article/details/132116949</a></p><p>简言之，LoRA的核心思想是用一种低秩的方式来调整这些参数矩阵。在数学上，低秩意味着一个矩阵可以用两个较小的矩阵相乘来近似，可知</p><img src="8d9d1c8a0d3544908727575a3b3f5b67.png" style="zoom:20%"><h4 id="进行LoRA训练的一般步骤">进行LoRA训练的一般步骤</h4><p>那如何进行LoRA训练呢</p><ol><li><p><strong>选择目标层</strong>：首先，在预训练神经网络模型中选择要应用LoRA的目标层。这些层通常是与特定任务相关的，如自注意力机制中的查询Q和键K矩阵<br>值得注意的是，原则上，我们可以将LoRA应用于神经网络中权矩阵的任何子集，以减少可训练参数的数量</p><p>在Transformer体系结构中，自关注模块(Wq、Wk、Wv、Wo)中有四个权重矩阵，MLP模块中有两个权重矩阵</p><ul><li>我们将Wq(或Wk，Wv)作为维度<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub><mo>×</mo><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub></mrow><annotation encoding="application/x-tex">d_{model} \times d_{model}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.84444em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.33610799999999996em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:.01968em">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.84444em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.33610799999999996em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:.01968em">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span>的单个矩阵，尽管输出维度通常被切分为注意力头</li><li><em>不过，为了简单和参数效率，我们将研究限制为仅适应下游任务的注意力权重，并冻结MLP模块(因此它们不接受下游任务的训练)</em></li></ul></li><li><p>初始化映射矩阵和逆映射矩阵：为目标层创建两个较小的矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal">A</span></span></span></span>和<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.05017em">B</span></span></span></span>，然后进行变换</p><ul><li><p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal">A</span></span></span></span>是映射矩阵(一般用随机高斯分布初始化，当然实际代码实现时，比如微软的deepspeed chat在用到LoRA时，一开始通过0矩阵占位，然后调用搭配ReLU激活函数的kaiming均匀分布初始化，虽与LoRA原始定义所用的高斯分布初始化不同，但此两种初始化方式都可以工作)，维度上是降维</p></li><li><p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.05017em">B</span></span></span></span>是逆映射矩阵(用0矩阵初始化)，维度上是升维</p></li></ul><p>之后做参数变换：将目标层的原始参数矩阵W通过映射矩阵A和逆映射矩阵B进行变换，计算公式为：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo>=</mo><mi>W</mi><mo>+</mo><mi>A</mi><mo>∗</mo><mi>B</mi></mrow><annotation encoding="application/x-tex">W&#x27; = W + A * B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.751892em;vertical-align:0"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.751892em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.76666em;vertical-align:-.08333em"></span><span class="mord mathnormal" style="margin-right:.13889em">W</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.05017em">B</span></span></span></span>，这里W’是变换后的参数矩阵</p><p>其中，矩阵的大小由LoRA的秩(rank)和alpha值确定，即实际实现时，会对<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mi>B</mi></mrow><annotation encoding="application/x-tex">AB</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal">A</span><span class="mord mathnormal" style="margin-right:.05017em">B</span></span></span></span>的结果通过<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mi>α</mi><mi>r</mi></mfrac></mrow><annotation encoding="application/x-tex">\frac{\alpha }{r}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.040392em;vertical-align:-.345em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.695392em"><span style="top:-2.6550000000000002em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.02778em">r</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.0037em">α</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>进行缩放</p><img src="a9dab9c45ef193e0527c55dc757aaf06.png" style="zoom:37%"></li><li><p><strong>微调模型</strong>：使用新的参数矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></mrow><annotation encoding="application/x-tex">W&#x27;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.751892em;vertical-align:0"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.751892em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span>替换目标层的原始参数矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi></mrow><annotation encoding="application/x-tex">W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.13889em">W</span></span></span></span>，然后在特定任务的训练数据上对模型进行微调</p></li><li><p><strong>梯度更新</strong>：在微调过程中，计算损失函数关于映射矩阵A和逆映射矩阵B的梯度，并使用优化算法(如Adam、SGD等)对A和B进行更新。注意，在更新过程中，原始参数矩阵W保持不变，说白了，<strong>训练的时候固定原始PLM的参数，只训练降维矩阵A与升维矩阵B</strong></p></li><li><p><strong>重复更新</strong>：在训练的每个批次中，重复步骤3-5，直到达到预定的训练轮次(epoch)或满足收敛条件</p></li></ol><p>且当需要切换到另一个下游任务时，可以通过减去B A然后添加不同的B’ A’来恢复W，这是一个内存开销很小的快速操作</p><p>总之，LoRA的详细步骤包括选择目标层、初始化映射矩阵和逆映射矩阵、进行参数变换和模型微调。在微调过程中，模型会通过更新映射矩阵U和逆映射矩阵V来学习特定任务的知识，从而提高模型在该任务上的性能</p><h3 id="QLoRA">QLoRA</h3><p>摘自：<a target="_blank" rel="noopener external nofollow noreferrer" href="https://blog.csdn.net/v_JULY_v/article/details/132116949">https://blog.csdn.net/v_JULY_v/article/details/132116949</a></p><p>QLoRA于今23年5月份通过此篇论文《<a target="_blank" rel="noopener external nofollow noreferrer" href="https://arxiv.org/pdf/2305.14314">QLORA: Efficient Finetuning of Quantized LLMs</a>》被提出，本质是对LoRA的改进，相比LoRA进一步降低显存消耗，话怎讲？</p><ul><li>因为LoRa为LLM的每一层添加了少量的可训练参数(适配器)，并冻结了所有原始参数。这样对于微调，只需要更新适配器权重，这可以显著减少内存占用</li><li>而QLoRa更进一步，引入了4位量化、双量化和利用nVidia统一内存进行分页(细节下文详解)<br>所有这些步骤都大大减少了微调所需的内存，同时性能几乎与标准微调相当</li></ul><p>下图总结了不同的微调方法及其内存需求，其中的QLoRA通过将模型量化到4位精度并使用分页优化器管理内存峰值来改进LoRA</p><img src="6979cbc0fa1f425955e4dd55520ebf02.png" style="zoom:30%"><p>可能论文中的这个图还不够一目了然，那可以对比下图</p><img src="17cebb80cbab901d5db1dd9d6ed21de7.png" style="zoom:43%"><h3 id="Prompt-Tuning">Prompt Tuning</h3><p>Prompt Tuning（提示调优）是近年来自然语言处理（NLP）领域兴起的一种高效迁移学习技术，旨在通过调整输入提示（Prompt）而非整个模型参数，使预训练语言模型（如BERT、GPT等）适配下游任务。其核心思想是<strong>利用预训练模型已有的知识，通过设计或优化提示词来“激发”模型完成任务</strong>，而非传统的全参数微调。</p><h4 id="1-核心原理"><strong>1. 核心原理</strong></h4><ul><li><p><strong>传统微调 vs. Prompt Tuning</strong>：</p><ul><li><strong>传统微调</strong>：针对下游任务调整整个模型的参数，需要大量标注数据和计算资源。</li><li><strong>Prompt Tuning</strong>：仅调整输入中的提示部分（如添加可学习的“软提示”向量），或优化少量参数，保留预训练模型的大部分参数不变。</li></ul></li><li><p><strong>Prompt的作用</strong>：</p><ul><li>将下游任务重新建模为预训练任务的形式。例如：<ul><li>情感分类任务 → 设计提示：“这句话的情感是[MASK]。”，模型预测[MASK]处的词（如“正面”/“负面”）。</li><li>文本生成任务 → 输入“请续写下文：{文本}[MASK]”。</li></ul></li></ul></li></ul><h4 id="2-主要方法"><strong>2. 主要方法</strong></h4><h5 id="1-硬提示（Hard-Prompts）"><strong>(1) 硬提示（Hard Prompts）</strong></h5><ul><li><strong>人工设计</strong>可读的文本模板，依赖领域知识。</li><li>示例：在问答任务中使用模板：“问题：{Q} 答案：[MASK]”。</li><li>缺点：设计耗时，且效果不稳定。</li></ul><h5 id="2-软提示（Soft-Prompts）"><strong>(2) 软提示（Soft Prompts）</strong></h5><ul><li><strong>可学习的连续向量</strong>：在输入层添加一组可训练的向量（如前缀或后缀），通过梯度下降优化。</li><li>代表方法：<ul><li><strong>Prefix Tuning</strong>：在输入前添加可训练的前缀向量。</li><li><strong>P-Tuning</strong>：将离散提示替换为可优化的连续向量。</li><li><strong>Prompt Tuning</strong>（狭义）：仅优化提示向量，冻结模型参数。</li></ul></li></ul><h5 id="3-混合方法"><strong>(3) 混合方法</strong></h5><ul><li>结合硬提示和软提示，例如<strong>P-Tuning v2</strong>，支持更深层次的提示优化。</li></ul><h4 id="3-优势"><strong>3. 优势</strong></h4><ol><li><strong>参数高效</strong>：仅调整少量参数（如0.1%~1%的模型参数量），适合资源受限场景。</li><li><strong>数据高效</strong>：在小样本（Few-shot）甚至零样本（Zero-shot）场景下表现优异。</li><li><strong>多任务适配</strong>：不同任务可设计不同提示，共享同一预训练模型。</li><li><strong>避免灾难性遗忘</strong>：冻结模型参数，保留预训练知识。</li></ol><h2 id="DPO、PPO">DPO、PPO</h2><p>参考：<a target="_blank" rel="noopener external nofollow noreferrer" href="https://blog.csdn.net/baoyan2015/article/details/135287298">https://blog.csdn.net/baoyan2015/article/details/135287298</a></p><h3 id="简单阐述">简单阐述</h3><h4 id="PPO（Proximal-Policy-Optimization）">PPO（Proximal Policy Optimization）</h4><h5 id="工作原理">工作原理</h5><ol><li><strong>目标函数</strong>：PPO旨在通过最大化特定的目标函数来改进策略。这个目标函数通常包括一个期望回报的项，以及可能的正则化项（如熵）来鼓励探索。</li><li><strong>概率比率剪切</strong>：PPO使用了一种称为概率比率剪切的技术，这涉及到计算新策略和旧策略对动作概率的比率。如果这个比率偏离1太远，PPO会通过剪切这个比率来限制更新的幅度，从而避免过大的策略变动。</li><li><strong>目标函数的优化</strong>：PPO对目标函数进行优化，通常使用随机梯度上升方法。这个过程涉及到在策略网络参数上应用梯度更新，以增加高回报动作的概率，同时减少低回报动作的概率。</li><li><strong>多次迭代更新</strong>：PPO算法通常在一次策略更新中使用多个迭代，这意味着它会重复利用同一批数据多次，以进行有效的学习。</li></ol><h5 id="实现步骤">实现步骤</h5><ol><li><strong>收集数据</strong>：首先，使用当前策略在环境中执行多个动作，收集状态、动作和回报的数据。</li><li><strong>计算优势函数</strong>：然后，计算每个时间步的优势函数，这通常涉及到对回报的估计和基线（比如状态价值函数）的使用。</li><li><strong>优化策略</strong>：接着，通过优化目标函数来更新策略参数。这个过程包括计算目标函数的梯度，并使用梯度上升来更新参数。</li><li><strong>重复迭代</strong>：重复上述过程多次，直到策略收敛或达到预定的迭代次数。</li></ol><p>加载4个模型，2个推理，2个训练</p><p><img src="https://i-blog.csdnimg.cn/blog_migrate/d41ce1354710e8ba58497590429e4f17.png" alt=""></p><ul><li><p><strong>Actor Model：演员模型</strong>，想要训练的目标语言模型</p></li><li><p><strong>Critic Model：评论家模型</strong>，它的作用是预估总收益</p></li><li><p><strong>Reward Model：奖励模型</strong>，它的作用是计算即时收益</p></li><li><p><strong>Reference Model：参考模型</strong>，它的作用是在RLHF阶段给语言模型增加一些“约束”，防止语言模型训歪（朝不受控制的方向更新，效果可能越来越差）</p></li></ul><p>其中:</p><ul><li><p><strong>Actor/Critic Model</strong>在RLHF阶段是<strong>需要训练</strong>的；<strong>而Reward/Reference Model</strong>是<strong>参数冻结</strong>的。</p></li><li><p>Critic/Reward/Reference Model共同组成了一个“奖励-loss”计算体系，我们综合它们的结果计算loss，用于更新Actor和Critic Model</p></li></ul><h5 id="reward-model和critic-network的区别">reward model和critic network的区别</h5><p>reward model和critic network只是看上去有点像，但在RLHF流程中起到的作用是不一样：</p><ul><li><p>reward model评估整个response质量，给出整体奖励信号，无法直接映射到每个token的贡献。</p></li><li><p>critic model估计价值函数，预测未来可能获得的累积奖励，为策略更新提供稳定的advantage信号</p></li><li><p>reward扮演的是环境的角色，而critic属于llm这个智能体的一部分，就好比在考试中，你自己检查卷子和老师给你打分的区别</p></li></ul><img src="image-20250510223415933.png" style="zoom:67%"> <img src="image-20250510223456416.png" style="zoom:67%"> <img src="image-20250510223522404.png" style="zoom:67%"> <img src="image-20250510223543133.png" style="zoom:67%"><h4 id="DPO-Direct-Preference-Optimization">DPO (Direct Preference Optimization)</h4><p>PPO 优化需要同时加载 4 个 LLMs，并且还要同时训练其中的两个，<strong>优化难度</strong>和<strong>训练开销</strong>可想而知，<strong>DPO</strong> 则是对 PPO 做出改进，<strong>直接利用人类偏好数据去训练 LLM</strong>，免去了 RL 的过程，不需要额外训练 reward model 和 critic model，但又和 RLHF 使用相同的目标函数，理论上优化得到的模型也是一样的，同时还可以使得模型更容易训练；此外，DPO 只需要使用偏序关系表示的人类偏好数据，在标注数据时我们只需要比较两个回答哪个好而不用给出具体的打分，也<strong>节省了标注成本</strong></p><p>DPO是一种相对较新的方法，它直接优化用户或专家的偏好，而非传统的累积奖励。在DPO中，通过对比不同的决策序列或策略，并根据用户或专家的偏好来优化模型，使得最终的策略能够更好地符合预期的行为。DPO通常用于那些难以明确定义奖励函数的场景，或者在用户偏好需要直接编码到决策过程中的应用中。</p><p>DPO的实现需要构建一个偏好模型，该模型能够从用户或专家的反馈中学习。在实际应用中，可能需要设计一种机制来收集用户的偏好数据，例如通过对比查询或者排名反馈。然后使用这些数据来训练一个或多个模型，这些模型能够预测给定决策序列的偏好得分，并据此来优化策略。</p><p>只需要加载2个模型，其中一个推理，另外一个训练，直接在偏好数据上进行训练。</p><p>原理公式解析可以查看：<a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.zhihu.com/tardis/zm/art/717010380?source_id=1003">https://www.zhihu.com/tardis/zm/art/717010380?source_id=1003</a></p><h3 id="RL中的改进过程">RL中的改进过程</h3><p>参考自：<a target="_blank" rel="noopener external nofollow noreferrer" href="https://hrl.boyuai.com/">https://hrl.boyuai.com/</a></p><h4 id="Actor-Critic-算法">Actor-Critic 算法</h4><p>之前讲解了基于值函数的方法（DQN）和基于策略的方法（REINFORCE），其中基于值函数的方法只学习一个价值函数，而基于策略的方法只学习一个策略函数。那么，一个很自然的问题是，有没有什么方法既学习价值函数，又学习策略函数呢？答案就是 Actor-Critic。Actor-Critic 是囊括一系列算法的整体架构，目前很多高效的前沿算法都属于 Actor-Critic 算法，本章接下来将会介绍一种最简单的 Actor-Critic 算法。需要明确的是，Actor-Critic 算法本质上是基于策略的算法，因为这一系列算法的目标都是优化一个带参数的策略，只是会额外学习价值函数，从而帮助策略函数更好地学习。</p><p>我们将 Actor-Critic 分为两个部分：Actor（策略网络）和 Critic（价值网络）。</p><ul><li>Actor 要做的是与环境交互，并在 Critic 价值函数的指导下用策略梯度学习一个更好的策略。</li><li>Critic 要做的是通过 Actor 与环境交互收集的数据学习一个价值函数，这个价值函数会用于判断在当前状态什么动作是好的，什么动作不是好的，进而帮助 Actor 进行策略更新。</li></ul><p>Actor 的更新采用策略梯度的原则，那 Critic 如何更新呢？我们可以采取时序差分残差的学习方式，对于单个数据定义价值函数的损失函数，与 DQN 中一样，我们采取类似于目标网络的方法，选择时序差分目标，产生梯度来更新价值函数，然后使用梯度下降方法来更新 Critic 价值网络参数即可。</p><h4 id="TRPO">TRPO</h4><p>之前介绍的基于策略的方法包括策略梯度算法和 Actor-Critic 算法。这些方法虽然简单、直观，但在实际应用过程中会遇到训练不稳定的情况。回顾一下基于策略的方法：参数化智能体的策略，并设计衡量策略好坏的目标函数，通过梯度上升的方法来最大化这个目标函数，使得策略最优。但是这种算法有一个明显的缺点：当策略网络是深度模型时，沿着策略梯度更新参数，很有可能由于步长太长，策略突然显著变差，进而影响训练效果。</p><p>针对以上问题，我们考虑在更新时找到一块<strong>信任区域</strong>（trust region），在这个区域上更新策略时能够得到某种策略性能的安全性保证，这就是<strong>信任区域策略优化</strong>（trust region policy optimization，TRPO）算法的主要思想</p><h4 id="PPO">PPO</h4><p>第 11 章介绍的 TRPO 算法在很多场景上的应用都很成功，但是我们也发现它的计算过程非常复杂，每一步更新的运算量非常大。于是，TRPO 算法的改进版——PPO 算法在 2017 年被提出，PPO 基于 TRPO 的思想，但是其算法实现更加简单。</p><p>PPO-惩罚（PPO-Penalty）用拉格朗日乘数法直接将 KL 散度的限制放进了目标函数中，这就变成了一个无约束的优化问题，在迭代的过程中不断更新 KL 散度前的系数。</p><p>PPO 的另一种形式 PPO-截断（PPO-Clip）更加直接，它在目标函数中进行限制，以保证新的参数和旧的参数的差距不会太大</p><h2 id="Agent">Agent</h2><p><strong>最直观的公式：Agent = LLM+Planning+Feedback+Tool use</strong></p><p>可以参考：</p><p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.cnblogs.com/huaweiyun/p/18289995">https://www.cnblogs.com/huaweiyun/p/18289995</a></p><p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://blog.csdn.net/v_JULY_v/article/details/135868163">https://blog.csdn.net/v_JULY_v/article/details/135868163</a></p><h2 id="RAG">RAG</h2><h3 id="优化">优化</h3><p>摘自<a target="_blank" rel="noopener external nofollow noreferrer" href="https://zhuanlan.zhihu.com/p/27319956001">知乎</a></p><ol><li>文档种类繁多 在商业环境中，常见的文档格式包括doc、ppt、excel、pdf等，其中pdf还分为扫描版和文字版。处理doc类文档相对简单，因为它们主要包含文字信息，信息密度较高，尽管也存在图文混排的情况。Excel文档由于结构化数据的特性，处理起来也相对容易，尤其是经过程序填充合并单元格后，每行信息均保持完整。然而，ppt和pdf文档的处理则颇具挑战，它们常包含大量的图表、流程图和展示图片，导致抽取出的文字信息呈现出碎片化和不完整的特点。</li><li>切分方式的局限性 若未采用定制化的切分方式，文本往往按照固定长度进行分割，并设置一定的重叠。这种方法导致每段文本的语义信息实际上不够完整，同时忽略了文本中已有的标题等关键信息。这导致需要被向量化的文本段落主题语义不明确，与自然形成的段落存在显著差距，从而给检索过程带来巨大困难。</li><li>内部知识的特殊性 大模型或句向量在训练时通常使用通用语料，这导致它们在识别特定行业的内部知识时存在缺陷。这些模型难以理解企业内部的专业术语和缩写所代表的具体含义，极大地影响了生成向量的精准度和模型的输出效果。</li><li>用户提问的随意性 实际上，大部分用户在提问时，所写的query较为模糊和笼统，其实际意图并未完全体现在query中。这使得检索出的文本段落无法完全命中用户想要的内容，导致大模型根据这些文本段落无法输出合适的答案。例如，用户简单提问“请给我推荐一个酒店”，由于缺乏具体信息，模型难以提供满足用户需求的精准答案。</li></ol><p>对于以上问题，一般可以采取多种方式进行解决，最终应用还是能够较好的满足用户的需求。</p><h4 id="1-对文档内容进行重新处理，以更准确地提取和表示信息。"><strong>1.</strong> 对文档内容进行重新处理，以更准确地提取和表示信息。</h4><p>针对各种类型的文档，分别进行了很多定制化的措施，用于完整的提取文档内容。这部分基本上脏活累活，</p><ul><li><p>Doc类文档还是比较好处理的，直接解析其实就能得到文本到底是什么元素，比如标题、表格、段落等等。这部分直接将文本段及其对应的属性存储下来，用于后续切分的依据。</p></li><li><p>PDF类文档的难点在于，如何完整恢复图片、表格、标题、段落等内容，形成一个文字版的文档。</p></li><li><p>PPT的难点在于，如何对PPT中大量的流程图，架构图进行提取。因为这些图多以形状元素在PPT中呈现，如果光提取文字，大量潜藏的信息就完全丢失了。于是这里只能先将PPT转换成PDF形式，然后用上述处理PDF的方式来进行解析。</p></li><li><p>当然，这里还没有解决出图片信息如何还原的问题。大量的文档使用了图文混排的形式，例如上述的PPT文件，转换成PDF后，仅仅是能够识别出这一块是一幅图片，对于图片，直接转换成向量，不利于后续的检索。所以我们只能通过一个较为昂贵的方案，即部署了一个多模态模型，通过prompt来对文档中的图片进行关键信息提取，形成一段摘要描述，作为文档图片的索引。</p></li></ul><h4 id="2-实施语义切分，以保持文本段落的完整性和语义连贯性。"><strong>2.</strong> 实施语义切分，以保持文本段落的完整性和语义连贯性。</h4><p>对文档内容进行重新处理后，语义切分工作其实就比较好做了。我们现在能够拿到的有每一段文本，每一张图片，每一张表格，文本对应的属性，图片对应的描述。</p><p>对于每个文档，实际上元素的组织形式是树状形式。例如一个文档包含多个标题，每个标题又包括多个小标题，每个小标题包括一段文本等等。我们只需要根据元素之间的关系，通过遍历这颗文档树，就能取到各个较为完整的语义段落，以及其对应的标题。</p><p>有些完整语义段落可能较长，于是我们对每一个语义段落，再通过大模型进行摘要。这样文档就形成了一个结构化的表达形式：</p><table><thead><tr><th>id</th><th>text</th><th>summary</th><th>source</th><th>type</th><th>image_source</th></tr></thead><tbody><tr><td>1</td><td>文本原始段落</td><td>文本摘要</td><td>来源文件</td><td>文本元素类别（主要用于区分图片和文本）</td><td>图片存储位置（在回答中返回这个位置，前端进行渲染）</td></tr></tbody></table><h4 id="3-使用RAG-Fusion技术来增加相关文本块的召回率。"><strong>3.</strong> 使用RAG Fusion技术来增加相关文本块的召回率。</h4><p>RAG Fusion技术就是，当接收用户query时，让大模型生成5-10个相似的query，然后每个query去匹配5-10个文本块，接着对所有返回的文本块再做个倒序融合排序，如果有需求就再加个精排，最后取Top K个文本块拼接至prompt。</p><p><img src="https://picx.zhimg.com/v2-f2b172dcecc78359b4fdd01aef1c65a5_1440w.jpg" alt="img"></p><p>实际使用时候，这个方法的主要好处，是增加了相关文本块的召回率，同时对用户的query自动进行了文本纠错、分解长句等功能。但是还是无法从根本上解决理解用户意图的问题。</p><h4 id="4-引入追问机制，通过多轮对话来明确用户的问题。"><strong>4.</strong> 引入追问机制，通过多轮对话来明确用户的问题。</h4><p>这里是通过Prompt就可以实现的功能，只要在Prompt中加入“如果无法从背景知识回答用户的问题，则根据背景知识内容，对用户进行追问，问题限制在3个以内”。这个机制并没有什么技术含量，主要依靠大模型的能力。不过大大改善了用户体验，用户在多轮引导中逐步明确了自己的问题，从而能够得到合适的答案。</p><h4 id="5-微调Embedding句向量模型，以更好地适应垂直领域的知识。"><strong>5.</strong> 微调Embedding句向量模型，以更好地适应垂直领域的知识。</h4><p>这部分主要是为了解决垂直领域特殊词汇，在通用句向量中会权重过大的问题。比如有个通用句向量模型，它在训练中很少见到“SAAS”这个词，无论是文本段和用户query，只要提到了这个词，整个句向量都会被带偏。举个例子：</p><p>假如一个用户问的是：我是一个SAAS用户，我希望订购一个云存储服务。由于SAAS的权重很高，使得检索匹配时候，模型完全忽略了后面的那句话，才是真实的用户需求。返回的内容可能是SAAS的介绍、SAAS的使用手册等等。</p><p>这里的微调方法使用的数据，是让大模型对语义分割的每一段，形成问答对。用这些问答对构建了数据集进行句向量的训练，使得句向量能够尽量理解垂直领域的场景。</p><h3 id="使用分层索引检索">使用分层索引检索</h3><p>由 LLM 生成摘要并对摘要进行检索可以使得检索过程更为高效。上节使用 LLM 提高信息密度的方法类似于无损压缩，而使用 LLM 生成摘要更像有损压缩。在大型数据库的情况下，一种有效的方法是<strong>创建两个索引 — 一个由摘要组成，另一个由文档块组成</strong> ，并分两步进行搜索，首先通过摘要过滤掉相关文档，然后在此相关组内进行搜索。</p><img src="v2-83cff3a603170c369ca76611d81fb204_1440w.jpg" alt="img" style="zoom:83%"><h3 id="RAG-Fusion">RAG Fusion</h3><p>参考：<a target="_blank" rel="noopener external nofollow noreferrer" href="https://blog.csdn.net/weixin_42608414/article/details/138487248">https://blog.csdn.net/weixin_42608414/article/details/138487248</a></p><p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://blog.csdn.net/m0_56255097/article/details/141417641">https://blog.csdn.net/m0_56255097/article/details/141417641</a></p><p>Multi Query的基本思想是当用户输入查询语句(自然语言)时，我们让大模型(LLM)基于用户的问题再生成多个<a target="_blank" rel="noopener external nofollow noreferrer" href="https://so.csdn.net/so/search?q=%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5&amp;spm=1001.2101.3001.7020">查询语句</a>，这些生成的查询语句是对用户查询语句的补充，它们是从不同的视角来补充用户的查询语句，然后每条查询语句都会从向量数据库中检索到一批相关文档，最后所有的相关文档都会被喂给LLM，这样LLM就会生成比较完整和全面的答案。这样就可以避免因为查询语句的差异而导致结果不正确。如下图所示：</p><p><img src="cb7435fcf623646602d6444b18cc94a9.png" alt=""></p><p>今天我们来介绍RAG 融合(rag fusion)，它的主要思想是在Multi Query的基础上，对其检索结果进行重新排序(即reranking)后输出Top K个最相关文档，最后将这top k个文档喂给LLM并生成最终的答案(answer)。如下图所示：</p><p><img src="077debf1cdd0c75bac01b62ff5e815c7.png" alt=""></p><h4 id="RRF-算法原理"><strong>RRF 算法原理</strong></h4><p>RRF 是一种用于组合多个来源排名的聚合方法，特别是在 RAG 系统中应用时，不同的检索模型会生成不同的文档排名，RRF 将这些排名融合为一个统一的结果。</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>R</mi><mi>R</mi><mi>F</mi><mi>s</mi><mi>c</mi><mi>o</mi><mi>r</mi><mi>e</mi><mo stretchy="false">(</mo><mi>d</mi><mo>∈</mo><mi>D</mi><mo stretchy="false">)</mo><mo>=</mo><munder><mo>∑</mo><mrow><mi>r</mi><mo>∈</mo><mi>R</mi></mrow></munder><mfrac><mn>1</mn><mrow><mi>k</mi><mo>+</mo><mi>r</mi><mo stretchy="false">(</mo><mi>d</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">RRFscore(d\in D)=\sum_{r\in R}\frac1{k+r(d)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.13889em">RRF</span><span class="mord mathnormal">score</span><span class="mopen">(</span><span class="mord mathnormal">d</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.02778em">D</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:2.6431459999999998em;vertical-align:-1.321706em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.050005em"><span style="top:-1.8556639999999998em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.02778em">r</span><span class="mrel mtight">∈</span><span class="mord mathnormal mtight" style="margin-right:.00773em">R</span></span></span></span><span style="top:-3.0500049999999996em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.321706em"><span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03148em">k</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord mathnormal" style="margin-right:.02778em">r</span><span class="mopen">(</span><span class="mord mathnormal">d</span><span class="mclose">)</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.936em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><p>其中：</p><ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi></mrow><annotation encoding="application/x-tex">d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord mathnormal">d</span></span></span></span> 是文档</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi></mrow><annotation encoding="application/x-tex">R</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.00773em">R</span></span></span></span> 是检索器的集合</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.03148em">k</span></span></span></span> 是常数</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi><mo stretchy="false">(</mo><mi>d</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">r(d)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.02778em">r</span><span class="mopen">(</span><span class="mord mathnormal">d</span><span class="mclose">)</span></span></span></span> 是文档 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi></mrow><annotation encoding="application/x-tex">d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord mathnormal">d</span></span></span></span> 在ranker <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.02778em">r</span></span></span></span> 中的等级</li></ul><h5 id="RRF的工作流程"><strong>RRF的工作流程</strong></h5><ol><li><p><strong>用户查询</strong>：用户输入一个查询。</p></li><li><p><strong>多重检索器</strong>：查询被发送到多个检索器，这些检索器可能使用不同的检索模型（如密集检索、稀疏检索、混合检索）。</p></li><li><p><strong>独立排名</strong>：每个检索器对相关文档进行排名。</p></li><li><p><strong>RRF 融合</strong>：使用 RRF 公式将所有检索器的排名结果合并。</p></li><li><p><strong>生成最终排名</strong>：根据 RRF 分数生成一个统一的文档排名。</p></li><li><p><strong>生成答案</strong>：生成模型使用排名最高的文档生成最终答案。</p></li></ol><h4 id="RRF背后的数学直觉"><strong>RRF背后的数学直觉</strong></h4><ol><li><strong>倒数排名</strong>：RRF 通过 1/(rank + k) 的公式，给排名靠前的文档更多的权重，这确保了在多个检索器中排名靠前的文档在最终排名中被优先考虑。</li><li><strong>收益递减</strong>：随着排名的增加，分数的贡献呈非线性递减。这反映了排名 1 和 2 之间的相关性差异通常比排名 100 和 101 之间的差异更大。</li><li><strong>排名聚合</strong>：通过对所有检索器的倒数秩求和，RRF 能够有效地结合多个来源的证据，使得最终排名更稳健，并且减少了单个检索器的偏见对结果的影响。</li><li><strong>归一化</strong>：常数 k 作为平滑因子，防止任何单个检索器对结果的主导，并有助于更优雅地处理低排名项目中的平局。</li></ol><h4 id="k-值的选择"><strong>k 值的选择</strong></h4><p>RRF 中常用的 k 值为 60，这一选择背后有几个原因：</p><ol><li><strong>实证表现</strong>：k = 60 在各种数据集和检索任务中表现良好。</li><li><strong>平衡影响力</strong>：这个值在高排名和低排名项目的影响之间提供了良好的平衡。</li><li><strong>有效的平局</strong>：k = 60 有助于在低排名项目中有效打破平局。</li><li><strong>鲁棒性</strong>：该值在不同类型的检索系统和数据分布中表现出很强的鲁棒性。</li></ol><p><strong>尽管 k = 60 是常用的选择，但最佳值可能因具体应用和数据特性而异。某些系统可能需要调整这个参数以获得更好的表现。</strong></p><h2 id="向量存储与检索">向量存储与检索</h2><h3 id="langchain的memory">langchain的memory</h3><p>来自<a target="_blank" rel="noopener external nofollow noreferrer" href="https://zhuanlan.zhihu.com/p/628734321">知乎</a></p><p>在LangChain中，Memory指的是大语言模型（LLM）的短期记忆。为什么是短期记忆？那是因为LLM训练好之后（获得了一些长期记忆），它的参数便不会因为用户的输入而发生改变。当用户与训练好的LLM进行对话时，LLM会暂时记住用户的输入和它已经生成的输出，以便预测之后的输出，而模型输出完毕后，它便会“遗忘”之前用户的输入和它的输出。因此，之前的这些信息只能称作为LLM的短期记忆。</p><img src="v2-2027c941850f8e258773b9632516aef2_1440w.jpg" style="zoom:33%"><p>为了延长LLM短期记忆的保留时间，则需要借助一些外部存储方式来进行记忆，以便在用户与LLM对话中，LLM能够尽可能的知道用户与它所进行的历史对话信息。</p><img src="v2-70cf4cc63525f23756e3c11c39684cab_1440w.jpg" alt="img" style="zoom:33%"><p>将历史的对话信息，作为短期记忆输入给LLM</p><p>在LangChain中提供了如下几种短期记忆管理的方式：<a target="_blank" rel="noopener external nofollow noreferrer" href="https://zhida.zhihu.com/search?content_id=227850286&amp;content_type=Article&amp;match_order=1&amp;q=BufferMemory&amp;zhida_source=entity">BufferMemory</a>、<a target="_blank" rel="noopener external nofollow noreferrer" href="https://zhida.zhihu.com/search?content_id=227850286&amp;content_type=Article&amp;match_order=1&amp;q=BufferWindowMemory&amp;zhida_source=entity">BufferWindowMemory</a>、ConversionMemory、<a target="_blank" rel="noopener external nofollow noreferrer" href="https://zhida.zhihu.com/search?content_id=227850286&amp;content_type=Article&amp;match_order=1&amp;q=VectorStore-backed+Memory&amp;zhida_source=entity">VectorStore-backed Memory</a>等。</p><p>1.BufferMemory，它是直接将之前的对话，完全存储下来。这样在每一轮新的对话中，都会将原来的所有对话传递给LLM。</p><img src="v2-bc994d480f5e26f5f3e723a49ae1a19a_1440w.jpg" alt="img" style="zoom:33%"><p>2.BufferWindowMemory，它是将最近的K组对话存储下来，这样在每一轮新的对话中将这K组对话传递给LLM。</p><img src="v2-999f19fa4d066b1c496cbad38200872c_1440w.jpg" alt="img" style="zoom:33%"><p>3.VectorStore-backed Memory，它是将所有之前的对话通过向量的方式存储到VectorDB（向量数据库）中，在每一轮新的对话中，会根据用户的输入信息，匹配向量数据库中最相似的K组对话。</p><img src="v2-07d831c47e109723e19c8d71f924072a_1440w.jpg" alt="img" style="zoom:33%"><p>取出与当前问题相似的K轮对话作为短期记忆</p><p>4.ConversionMemory，它是将对话进行时对对话信息进行摘要，并将当前摘要存储在内存中。然后在新一轮对话中，可以将此摘要作为短期记忆传递给LLM。这种方式对于较长的对话非常有用，因为它是相当于压缩了历史的对话信息，能够将做够多的短期记忆发送给LLM。</p><img src="v2-df3c695f1a476ccec51c0a15a2ab412e_1440w.jpg" alt="img" style="zoom:33%"><p>将以前的对话先做总结，然后再传给LLM</p><h3 id="向量数据库">向量数据库</h3><h4 id="Faiss">Faiss</h4><p>Meta的<a target="_blank" rel="noopener external nofollow noreferrer" href="https://faiss.ai/">Faiss</a>是一个用于高效相似性搜索和密集向量聚类的库。 它包含搜索任意大小的向量集的算法，直到可能不适合 RAM 的向量集。 它还包含用于评估和参数调整的支持代码。</p><p>以下摘自https://zhuanlan.zhihu.com/p/628148081</p><table><thead><tr><th>数据库名称</th><th>是否开源</th><th>社区影响力</th><th>编程语言</th><th>核心特性</th><th>适用场景</th></tr></thead><tbody><tr><td>Pinecone</td><td>否</td><td></td><td>未知</td><td>向量存储与检索、全托管</td><td>Saas类业务场景</td></tr><tr><td>weaviate</td><td>是</td><td>5.3k star</td><td>Go</td><td>同时支持向量与对象的存储、支持向量检索与结构化过滤、具备主流模式成熟的使用案例。高速、灵活，不仅仅具备向量检索，还会支持推荐、总结等能力</td><td></td></tr><tr><td>qdrant</td><td>是</td><td>6.3k star</td><td>Rust</td><td>向量存储与检索、云原生、分布式、支持过滤、丰富的数据类型、WAL日志写入</td><td></td></tr><tr><td>milvus</td><td>是</td><td>17.7k star</td><td>Go</td><td>极高的检索性能: 万亿矢量数据集的毫秒级搜索非结构化数据的极简管理丰富的API跨平台实时搜索和分析可靠：具有很高的容灾与故障转移能力高度可拓展与弹性支持混合检索统一的Lambda架构社区支持、行业认可</td><td></td></tr><tr><td>Chroma</td><td>是</td><td>4.1k star</td><td>python</td><td>轻量、内存级</td><td></td></tr></tbody></table><h2 id="langchain">langchain</h2><p>可以参考：</p><p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.langchain.asia/">https://www.langchain.asia/</a></p><p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://aitutor.liduos.com/02-langchain/02-1.html">https://aitutor.liduos.com/02-langchain/02-1.html</a></p><h2 id="FlashAttention">FlashAttention</h2><p>摘自https://blog.csdn.net/v_JULY_v/article/details/133619540，原文更详细</p><h3 id="Transformer计算复杂度-——-Self-Attention层与MLP层">Transformer计算复杂度*——*Self-Attention层与MLP层</h3><p>简单理解的话，计算复杂度和序列长度的平方<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>N</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">N^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8141079999999999em;vertical-align:0"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.10903em">N</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8141079999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>成正比，可以看一个小例子，比如两个相乘的矩阵大小分别为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>N</mi><mo>×</mo><mi>d</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(N \times d)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:.10903em">N</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal">d</span><span class="mclose">)</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>d</mi><mo>×</mo><mi>N</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(d \times N)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord mathnormal">d</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.10903em">N</span><span class="mclose">)</span></span></span></span>，矩阵乘法的一种计算方式是使用第一个矩阵的每一行与第二个矩阵的每一列做点乘</p><p><img src="32621ee67c3d4f74997ef2545ee417b1.png" alt=""></p><p>因为我们需要拿第一个矩阵的每一行去与第二个矩阵的每一列做点乘，所以总共就需要 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>N</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">N^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8141079999999999em;vertical-align:0"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.10903em">N</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8141079999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span> 次点乘。而每次点乘又需要 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi></mrow><annotation encoding="application/x-tex">d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord mathnormal">d</span></span></span></span> 次乘法，所以总复杂度就为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">O</mi><mo stretchy="false">(</mo><msup><mi>N</mi><mn>2</mn></msup><mi>d</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathrm O(N^2d)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.064108em;vertical-align:-.25em"></span><span class="mord mathrm">O</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.10903em">N</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8141079999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mord mathnormal">d</span><span class="mclose">)</span></span></span></span></p><blockquote><p>空间复杂度等可以参考原文，这里就不再展开，但建议还是看一下</p></blockquote><h3 id="Flash-Attention：通过kernel融合降低HBM读写次数，避免频繁地从HBM中读写数据">Flash Attention：通过kernel融合降低HBM读写次数，<strong>避免频繁地从HBM中读写数据</strong></h3><p>如上文说过的</p><ol><li>在标准注意力实现中，注意力的性能主要受限于内存带宽，是内存受限的，频繁地从HBM中读写<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi><mo>×</mo><mi>N</mi></mrow><annotation encoding="application/x-tex">N \times N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.76666em;vertical-align:-.08333em"></span><span class="mord mathnormal" style="margin-right:.10903em">N</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.10903em">N</span></span></span></span> 的矩阵是影响性能的主要瓶颈</li><li>稀疏近似和低秩近似等近似注意力方法虽然减少了计算量FLOPs，但对于内存受限的操作，运行时间的瓶颈是从HBM中读写数据的耗时，减少计算量并不能有效地减少运行时间(wall-clock time)</li><li>针对内存受限的标准注意力，Flash Attention是IO感知的，目标是<strong>避免频繁地从HBM中读写数据</strong></li></ol><p>所以，减少对HBM的读写次数，有效利用更高速的SRAM来进行计算是非常重要的，而对于性能受限于内存带宽的操作，进行加速的常用方式就是kernel融合，该操作的典型方式分为三步：</p><ol><li>每个kernel将输入数据从低速的HBM中加载到高速的SRAM中</li><li>在SRAM中，进行计算</li><li>计算完毕后，将计算结果从SRAM中写入到HBM中</li></ol><p>如此，便可避免反复执行“从HBM中读取输入数据，SRAM执行计算，最后将计算结果写入到HBM中”，将多个操作融合成一个操作，<strong>减少读写HBM的次数</strong></p><h3 id="Flash-Attention2：比Flash-Attention快2倍"><strong>Flash Attention2：比Flash Attention快2倍</strong></h3><p>2023年7月，Tri Dao通过此篇论文《<a target="_blank" rel="noopener external nofollow noreferrer" href="https://arxiv.org/abs/2307.08691">FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning</a>》提出了Flash Attention2(<em>这是<a target="_blank" rel="noopener external nofollow noreferrer" href="https://openreview.net/forum?id=mZn2Xyh9Ec">该篇论文所对应的审稿意见</a></em>)，其在第一个版本的基础上做了一系列改进</p><p>那第一个版本存在什么问题或不足呢？Flash Attention仍然不如其他基本操作(比如矩阵乘法)高效</p><ul><li>虽然Flash Attention已经比标准的注意力实现快2-4倍，但前向传播仅达到设备理论最大FLOPs/s的30-50%，而反向传播更具挑战性，仅达到A100 GPU最大吞吐量的25-35%</li><li>相比之下，优化的矩阵乘法可以达到理论最大设备吞吐量的80-90%。 通过仔细的分析，观察到Flash Attention在GPU上不同线程块和线程束之间的工作划分仍然不够优化，导致低占用率或不必要的共享内存读写</li></ul><p>因此，在Flash Attention的基础上，我们提出了Flash Attention2，具有更好的并行性和工作分区</p><ol><li><p>调整算法以减少<strong>非矩阵乘法操作的浮点运算次数</strong>，同时保持输出不变(<em>we tweak the algorithms to reduce <strong>the number of non-matmul FLOPs</strong> while not changing the output</em>)</p><ul><li><p>尽管非矩阵乘法操作仅占总浮点运算次数FLOPs的一小部分，但执行非矩阵乘法操作的时间较长(<em>While the non-matmul FLOPs only account for a small fraction of the total FLOPs, they take longer to perform</em>)</p></li><li><p>原因在于GPU具有专门用于矩阵乘法的计算单元(<em>as GPUs have specialized units for matrix multiply</em>)，例如Nvidia GPU上的张量核心，可让矩阵乘法的吞吐量相比非矩阵乘法高达16倍(<em>as a result the matmul throughput can be up to 16× higher than non-matmul throughput</em>)<br>以A100 GPU为例，其FP16/BF16矩阵乘法的最大理论吞吐量为312 TFLOPs/s，而非矩阵乘法的FP32吞吐量仅为19.5 TFLOPs/s。换言之，每个非矩阵乘法的FLOP比矩阵乘法的FLOP贵16倍</p></li></ul><p>因此，<strong>减少非矩阵乘法操作的浮点运算次数并尽可能多地执行矩阵乘法操作</strong>非常重要<br><em>It is thus important to reduce non-matmul FLOPs and spend as much time as possible doing matmul FLOPs</em></p></li><li><p>在序列长度维度上同时并行化前向传播和反向传播，除了批次和头数维度。 这样做可以提高GPU资源的利用率，特别是在序列较长(因此批次大小通常较小)的情况下。</p></li><li><p>即使在注意力计算的一个块内部，我们也将工作分配给不同的线程块以减少通信和共享内存的读写</p></li></ol><p>最终，通过实验证明Flash Attention2相对于Flash Attention具有显著的加速效果，比如在不同设置的基准测试中(有无因果掩码，不同的头维度)，Flash Attention2在前向传递中实现了约2×的加速(<em><strong>FlashAttention-2比FlashAttention快2倍</strong>，意味着同样的费用之前只能训练8k上下文的模型，而现在可以训练具有16k更长上下文的模型</em>)，达到了理论最大吞吐量的73%，且在反向传递中达到了理论最大吞吐量的63%。而当用于端到端训练GPT风格的模型时，每个A100 GPU的训练速度可达到225 TFLOPs/s</p><h2 id="deepseek">deepseek</h2><h3 id="MLA">MLA</h3><p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://blog.csdn.net/v_JULY_v/article/details/141535986">https://blog.csdn.net/v_JULY_v/article/details/141535986</a></p><h3 id="GRPO">GRPO</h3><p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://blog.csdn.net/v_JULY_v/article/details/136656918">https://blog.csdn.net/v_JULY_v/article/details/136656918</a></p><h3 id="R1-Zero：RL算法GRPO、格式奖励、训练模板">R1-Zero：RL算法GRPO、格式奖励、训练模板</h3><p>蒸馏自：<a target="_blank" rel="noopener external nofollow noreferrer" href="https://blog.csdn.net/v_JULY_v/article/details/145289228">https://blog.csdn.net/v_JULY_v/article/details/145289228</a></p><p>DeepSeek-R1-Zero 通过纯RL训练，无冷启动、无SFT，这是很有魄力的举动，而其主要有三点独特的设计：RL算法GRPO、格式奖励、训练模板</p><h4 id="RL算法GRPO：不需要critic">RL算法GRPO：不需要critic</h4><p>为了节省强化学习的训练成本，作者采用组相对策略优化GRPO，该方法放弃了通常与策略模型大小相同的critic模型「<em>关于<strong>actor critic训练大模型策略</strong>那一套，详见上面提到过的此文《<a target="_blank" rel="noopener external nofollow noreferrer" href="https://blog.csdn.net/v_JULY_v/article/details/128579457" title="ChatGPT技术原理解析：从RL之PPO算法、RLHF到GPT4、instructGPT">ChatGPT技术原理解析：从RL之PPO算法、RLHF到GPT4、instructGPT</a>》，尽管很多文章都声称自己写的最棒，但都不如此文</em>」，而是从组得分中估计baseline</p><p>具体来说，对于每个问题<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathnormal" style="margin-right:.03588em">q</span></span></span></span>，GRPO 从旧策略 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>π</mi><msub><mi>θ</mi><mtext>old </mtext></msub></msub></mrow><annotation encoding="application/x-tex">\pi_{\theta_{\text {old }}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68642em;vertical-align:-.25586em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.33610799999999985em"><span style="top:-2.55em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.02778em">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3448em"><span style="top:-2.3487714285714287em;margin-left:-.02778em;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">old </span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15122857142857138em"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.25586em"><span></span></span></span></span></span></span></span></span></span> 中抽取一组输出<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo fence="true">{</mo><msub><mi>o</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>o</mi><mn>2</mn></msub><mo separator="true">,</mo><mo>⋯</mo><mtext> </mtext><mo separator="true">,</mo><msub><mi>o</mi><mi>G</mi></msub><mo fence="true">}</mo></mrow><annotation encoding="application/x-tex">\left\{o_{1}, o_{2}, \cdots, o_{G}\right\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="minner"><span class="mopen delimcenter" style="top:0">{</span><span class="mord"><span class="mord mathnormal">o</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathnormal">o</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner">⋯</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathnormal">o</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.32833099999999993em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">G</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0">}</span></span></span></span></span>，然后通过最大化以下目标来优化策略模型 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>π</mi><mi>θ</mi></msub></mrow><annotation encoding="application/x-tex">π_θ</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.58056em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.33610799999999996em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.02778em">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span>：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.2500em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><msub><mi mathvariant="script">J</mi><mrow><mi>G</mi><mi>R</mi><mi>P</mi><mi>O</mi></mrow></msub><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mi mathvariant="double-struck">E</mi><mrow><mo fence="true">[</mo><mi>q</mi><mo>∼</mo><mi>P</mi><mo stretchy="false">(</mo><mi>Q</mi><mo stretchy="false">)</mo><mo separator="true">,</mo><msubsup><mrow><mo fence="true">{</mo><msub><mi>o</mi><mi>i</mi></msub><mo fence="true">}</mo></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>G</mi></msubsup><mo>∼</mo><msub><mi>π</mi><msub><mi>θ</mi><mtext>old </mtext></msub></msub><mo stretchy="false">(</mo><mi>O</mi><mo>∣</mo><mi>q</mi><mo stretchy="false">)</mo><mo fence="true">]</mo></mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mfrac><mn>1</mn><mi>G</mi></mfrac><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>G</mi></munderover><mrow><mo fence="true">(</mo><mi>min</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><mfrac><mrow><msub><mi>π</mi><mi>θ</mi></msub><mrow><mo fence="true">(</mo><msub><mi>o</mi><mi>i</mi></msub><mo>∣</mo><mi>q</mi><mo fence="true">)</mo></mrow></mrow><mrow><msub><mi>π</mi><msub><mi>θ</mi><mtext>old </mtext></msub></msub><mrow><mo fence="true">(</mo><msub><mi>o</mi><mi>i</mi></msub><mo>∣</mo><mi>q</mi><mo fence="true">)</mo></mrow></mrow></mfrac><msub><mi>A</mi><mi>i</mi></msub><mo separator="true">,</mo><mi mathvariant="normal">clip</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><mfrac><mrow><msub><mi>π</mi><mi>θ</mi></msub><mrow><mo fence="true">(</mo><msub><mi>o</mi><mi>i</mi></msub><mo>∣</mo><mi>q</mi><mo fence="true">)</mo></mrow></mrow><msub><mi>π</mi><mrow><msub><mi>θ</mi><mtext>old </mtext></msub><mrow><mo fence="true">(</mo><msub><mi>o</mi><mi>i</mi></msub><mo>∣</mo><mi>q</mi><mo fence="true">)</mo></mrow></mrow></msub></mfrac><mo separator="true">,</mo><mn>1</mn><mo>−</mo><mi>ε</mi><mo separator="true">,</mo><mn>1</mn><mo>+</mo><mi>ε</mi><mo fence="true">)</mo></mrow><msub><mi>A</mi><mi>i</mi></msub><mo fence="true">)</mo></mrow><mo>−</mo><mi>β</mi><msub><mi mathvariant="double-struck">D</mi><mrow><mi>K</mi><mi>L</mi></mrow></msub><mrow><mo fence="true">(</mo><msub><mi>π</mi><mi>θ</mi></msub><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><msub><mi>π</mi><mrow><mi>r</mi><mi>e</mi><mi>f</mi></mrow></msub><mo fence="true">)</mo></mrow><mo fence="true">)</mo></mrow></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned} \mathcal{J}_{G R P O}(\theta) &amp; =\mathbb{E}\left[q \sim P(Q),\left\{o_{i}\right\}_{i=1}^{G} \sim \pi_{\theta_{\text {old }}}(O \mid q)\right] \\ &amp; \frac{1}{G} \sum_{i=1}^{G}\left(\min \left(\frac{\pi_{\theta}\left(o_{i} \mid q\right)}{\pi_{\theta_{\text {old }}}\left(o_{i} \mid q\right)} A_{i}, \operatorname{clip}\left(\frac{\pi_{\theta}\left(o_{i} \mid q\right)}{\pi_{\theta_{\text {old }}\left(o_{i} \mid q\right)}}, 1-\varepsilon, 1+\varepsilon\right) A_{i}\right)-\beta \mathbb{D}_{K L}\left(\pi_{\theta}| | \pi_{r e f}\right)\right) \end{aligned}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:5.506024999999999em;vertical-align:-2.5030124999999996em"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:3.0030124999999996em"><span style="top:-5.6813485em"><span class="pstrut" style="height:3.828336em"></span><span class="mord"><span class="mord"><span class="mord mathcal" style="margin-right:.18472em">J</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.32833099999999993em"><span style="top:-2.5500000000000003em;margin-left:-.18472em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.02778em">GRPO</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:.02778em">θ</span><span class="mclose">)</span></span></span><span style="top:-2.9029925000000008em"><span class="pstrut" style="height:3.828336em"></span><span class="mord"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.5030124999999996em"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:3.0030124999999996em"><span style="top:-5.6813485em"><span class="pstrut" style="height:3.828336em"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mord mathbb">E</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner"><span class="mopen delimcenter" style="top:0"><span class="delimsizing size2">[</span></span><span class="mord mathnormal" style="margin-right:.03588em">q</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mord mathnormal" style="margin-right:.13889em">P</span><span class="mopen">(</span><span class="mord mathnormal">Q</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner"><span class="minner"><span class="mopen delimcenter" style="top:0">{</span><span class="mord"><span class="mord mathnormal">o</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0">}</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.981231em"><span style="top:-2.4003em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">G</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.29969999999999997em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.33610799999999985em"><span style="top:-2.55em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.02778em">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3448em"><span style="top:-2.3487714285714287em;margin-left:-.02778em;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">old </span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15122857142857138em"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.25586em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:.02778em">O</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mord mathnormal" style="margin-right:.03588em">q</span><span class="mclose">)</span><span class="mclose delimcenter" style="top:0"><span class="delimsizing size2">]</span></span></span></span></span><span style="top:-2.9029925000000008em"><span class="pstrut" style="height:3.828336em"></span><span class="mord"><span class="mord"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal">G</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.686em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283360000000002em"><span style="top:-1.872331em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">G</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em"><span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner"><span class="mopen delimcenter" style="top:0"><span class="delimsizing size3">(</span></span><span class="mop">min</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner"><span class="mopen delimcenter" style="top:0"><span class="delimsizing size3">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.33610799999999985em"><span style="top:-2.55em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.02778em">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3448em"><span style="top:-2.3487714285714287em;margin-left:-.02778em;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">old </span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15122857142857138em"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.25586em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner"><span class="mopen delimcenter" style="top:0">(</span><span class="mord"><span class="mord mathnormal">o</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mord mathnormal" style="margin-right:.03588em">q</span><span class="mclose delimcenter" style="top:0">)</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.33610799999999996em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.02778em">θ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner"><span class="mopen delimcenter" style="top:0">(</span><span class="mord"><span class="mord mathnormal">o</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mord mathnormal" style="margin-right:.03588em">q</span><span class="mclose delimcenter" style="top:0">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.94186em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mop"><span class="mord mathrm">clip</span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner"><span class="mopen delimcenter" style="top:0"><span class="delimsizing size3">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.34480000000000005em"><span style="top:-2.5198em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.02778em">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3448em"><span style="top:-2.3487714285714287em;margin-left:-.02778em;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">old </span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15122857142857138em"><span></span></span></span></span></span></span><span class="minner mtight"><span class="mopen mtight delimcenter" style="top:0"><span class="mtight">(</span></span><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3280857142857143em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span><span class="mrel mtight">∣</span><span class="mord mathnormal mtight" style="margin-right:.03588em">q</span><span class="mclose mtight delimcenter" style="top:0"><span class="mtight">)</span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.3551999999999999em"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.33610799999999996em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.02778em">θ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner"><span class="mopen delimcenter" style="top:0">(</span><span class="mord"><span class="mord mathnormal">o</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mord mathnormal" style="margin-right:.03588em">q</span><span class="mclose delimcenter" style="top:0">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.0412em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord">1</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord mathnormal">ε</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord">1</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord mathnormal">ε</span><span class="mclose delimcenter" style="top:0"><span class="delimsizing size3">)</span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0"><span class="delimsizing size3">)</span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord mathnormal" style="margin-right:.05278em">β</span><span class="mord"><span class="mord mathbb">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.32833099999999993em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.07153em">K</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner"><span class="mopen delimcenter" style="top:0">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.33610799999999996em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.02778em">θ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mord">∣∣</span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3361079999999999em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">re</span><span class="mord mathnormal mtight" style="margin-right:.10764em">f</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0">)</span></span><span class="mclose delimcenter" style="top:0"><span class="delimsizing size3">)</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.5030124999999996em"><span></span></span></span></span></span></span></span></span></span></span></span></p><p>且</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="double-struck">D</mi><mrow><mi>K</mi><mi>L</mi></mrow></msub><mrow><mo fence="true">(</mo><msub><mi>π</mi><mi>θ</mi></msub><mi mathvariant="normal">∥</mi><msub><mi>π</mi><mrow><mi>r</mi><mi>e</mi><mi>f</mi></mrow></msub><mo fence="true">)</mo></mrow><mo>=</mo><mfrac><mrow><msub><mi>π</mi><mrow><mi>r</mi><mi>e</mi><mi>f</mi></mrow></msub><mrow><mo fence="true">(</mo><msub><mi>o</mi><mi>i</mi></msub><mo>∣</mo><mi>q</mi><mo fence="true">)</mo></mrow></mrow><mrow><msub><mi>π</mi><mi>θ</mi></msub><mrow><mo fence="true">(</mo><msub><mi>o</mi><mi>i</mi></msub><mo>∣</mo><mi>q</mi><mo fence="true">)</mo></mrow></mrow></mfrac><mo>−</mo><mi>log</mi><mo>⁡</mo><mfrac><mrow><msub><mi>π</mi><mrow><mi>r</mi><mi>e</mi><mi>f</mi></mrow></msub><mrow><mo fence="true">(</mo><msub><mi>o</mi><mi>i</mi></msub><mo>∣</mo><mi>q</mi><mo fence="true">)</mo></mrow></mrow><mrow><msub><mi>π</mi><mi>θ</mi></msub><mrow><mo fence="true">(</mo><msub><mi>o</mi><mi>i</mi></msub><mo>∣</mo><mi>q</mi><mo fence="true">)</mo></mrow></mrow></mfrac><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\mathbb{D}_{K L}\left(\pi_{\theta} \| \pi_{r e f}\right)=\frac{\pi_{r e f}\left(o_{i} \mid q\right)}{\pi_{\theta}\left(o_{i} \mid q\right)}-\log \frac{\pi_{r e f}\left(o_{i} \mid q\right)}{\pi_{\theta}\left(o_{i} \mid q\right)}-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-.286108em"></span><span class="mord"><span class="mord mathbb">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.32833099999999993em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.07153em">K</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner"><span class="mopen delimcenter" style="top:0">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.33610799999999996em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.02778em">θ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mord">∥</span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3361079999999999em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">re</span><span class="mord mathnormal mtight" style="margin-right:.10764em">f</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0">)</span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:2.363em;vertical-align:-.936em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.33610799999999996em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.02778em">θ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner"><span class="mopen delimcenter" style="top:0">(</span><span class="mord"><span class="mord mathnormal">o</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mord mathnormal" style="margin-right:.03588em">q</span><span class="mclose delimcenter" style="top:0">)</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3361079999999999em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">re</span><span class="mord mathnormal mtight" style="margin-right:.10764em">f</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner"><span class="mopen delimcenter" style="top:0">(</span><span class="mord"><span class="mord mathnormal">o</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mord mathnormal" style="margin-right:.03588em">q</span><span class="mclose delimcenter" style="top:0">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.936em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:2.363em;vertical-align:-.936em"></span><span class="mop">lo<span style="margin-right:.01389em">g</span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.33610799999999996em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.02778em">θ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner"><span class="mopen delimcenter" style="top:0">(</span><span class="mord"><span class="mord mathnormal">o</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mord mathnormal" style="margin-right:.03588em">q</span><span class="mclose delimcenter" style="top:0">)</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3361079999999999em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">re</span><span class="mord mathnormal mtight" style="margin-right:.10764em">f</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner"><span class="mopen delimcenter" style="top:0">(</span><span class="mord"><span class="mord mathnormal">o</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mord mathnormal" style="margin-right:.03588em">q</span><span class="mclose delimcenter" style="top:0">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.936em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">1</span></span></span></span></span></p><p>其中，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ε</mi></mrow><annotation encoding="application/x-tex">\varepsilon</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathnormal">ε</span></span></span></span> 和<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="mord mathnormal" style="margin-right:.05278em">β</span></span></span></span>是超参数，而<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">A_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.83333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span>是优势，使用一组奖励<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo fence="true">{</mo><msub><mi>r</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>r</mi><mn>2</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>r</mi><mi>G</mi></msub><mo fence="true">}</mo></mrow><annotation encoding="application/x-tex">\left\{r_{1}, r_{2}, \ldots, r_{G}\right\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="minner"><span class="mopen delimcenter" style="top:0">{</span><span class="mord"><span class="mord mathnormal" style="margin-right:.02778em">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.02778em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.02778em">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.02778em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner">…</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.02778em">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.32833099999999993em"><span style="top:-2.5500000000000003em;margin-left:-.02778em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">G</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0">}</span></span></span></span></span>计算，该奖励对应于每个组内的输出</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>A</mi><mi>i</mi></msub><mo>=</mo><mfrac><mrow><msub><mi>r</mi><mi>i</mi></msub><mo>−</mo><mi mathvariant="normal">mean</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><mrow><mo fence="true">{</mo><msub><mi>r</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>r</mi><mn>2</mn></msub><mo separator="true">,</mo><mo>⋯</mo><mtext> </mtext><mo separator="true">,</mo><msub><mi>r</mi><mi>G</mi></msub><mo fence="true">}</mo></mrow><mo fence="true">)</mo></mrow></mrow><mrow><mi mathvariant="normal">std</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><mrow><mo fence="true">{</mo><msub><mi>r</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>r</mi><mn>2</mn></msub><mo separator="true">,</mo><mo>⋯</mo><mtext> </mtext><mo separator="true">,</mo><msub><mi>r</mi><mi>G</mi></msub><mo fence="true">}</mo></mrow><mo fence="true">)</mo></mrow></mrow></mfrac></mrow><annotation encoding="application/x-tex">A_{i}=\frac{r_{i}-\operatorname{mean}\left(\left\{r_{1}, r_{2}, \cdots, r_{G}\right\}\right)}{\operatorname{std}\left(\left\{r_{1}, r_{2}, \cdots, r_{G}\right\}\right)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.83333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:2.363em;vertical-align:-.936em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mop"><span class="mord mathrm">std</span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner"><span class="mopen delimcenter" style="top:0">(</span><span class="minner"><span class="mopen delimcenter" style="top:0">{</span><span class="mord"><span class="mord mathnormal" style="margin-right:.02778em">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.02778em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.02778em">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.02778em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner">⋯</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.02778em">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.32833099999999993em"><span style="top:-2.5500000000000003em;margin-left:-.02778em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">G</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0">}</span></span><span class="mclose delimcenter" style="top:0">)</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:.02778em">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:-.02778em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mop"><span class="mord mathrm">mean</span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner"><span class="mopen delimcenter" style="top:0">(</span><span class="minner"><span class="mopen delimcenter" style="top:0">{</span><span class="mord"><span class="mord mathnormal" style="margin-right:.02778em">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.02778em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.02778em">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.02778em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner">⋯</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.02778em">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.32833099999999993em"><span style="top:-2.5500000000000003em;margin-left:-.02778em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">G</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0">}</span></span><span class="mclose delimcenter" style="top:0">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.936em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><blockquote><p>可以参考：<a target="_blank" rel="noopener external nofollow noreferrer" href="https://blog.csdn.net/v_JULY_v/article/details/136656918">https://blog.csdn.net/v_JULY_v/article/details/136656918</a></p><hr><p><strong>“</strong> DeepSeek提出了群体相对策略优化GRPO——Group Relative Policy Optimization</p><img src="/ec6ea111e67943b9a4c3c538e2c3f682.png" style="zoom:20%"><ol><li><p>它避免了像 PPO 那样需要额外的价值函数近似——说白了 就是不要PPO当中的value model或value function去做价值评估</p><p>就是丢掉critic，也就没有了value(不需要基于value做估计)，也就不需要GAE</p></li><li><p>而是使用对同一问题的多个采样输出的平均奖励作为基线(<em>说白了，直接暴力采样 N 次求均值</em>)</p><p>毕竟优势函数不就重点考察那些超出预期、超出基线baseline的表现么，所以问题的关键就是基线baseline的定义，因为一旦定义好了baseline，目标就明确了——越发鼓励可以超过baseline的行为(而每个行为是由背后的策略所决定的，故优化行为的同时就是策略的不断迭代与优化)，而这就是优势函数所追求的</p></li><li><p>… <strong>”</strong></p></li></ol></blockquote><h4 id="规则奖励建模-准确性奖励-格式奖励-：不用训练专门的偏好奖励模型">规则奖励建模(准确性奖励 + 格式奖励)：不用训练专门的偏好奖励模型</h4><p>奖励是训练信号的来源，它决定了强化学习的优化方向</p><p>为了训练DeepSeek-R1-Zero，作者采用了一个基于规则的奖励系统(rule-based reward)，主要由两种类型的奖励组成：</p><ul><li><p><strong>准确性</strong>Accuracy<strong>奖励</strong>：准确性奖励模型评估响应是否正确。例如，对于具有确定性结果的数学问题，模型需要以指定格式（例如，框内）提供最终答案，从而实现基于规则的正确性验证——毕竟数学问题的答案具有明确的结果确定性与唯一性，对就是对，错就是错。同样，对于LeetCode问题，可以使用编译器根据预定义的测试用例生成反馈</p><p>如此，这些自动化生成的训练信号都能直接用于模型优化。这一过程自然需要在小批量样本中处理大量案例，并通过连续训练迭代，逐步优化</p></li><li><p><strong>格式奖励</strong>：除了准确性奖励模型外，作者还采用了格式奖励模型，比如要求模型**在’<think>‘和’</think>'**标签之间放置CoT思考过程，那么，系统会检查模型输出是否正确地将推理过程包含在<think>…</think>标签内，并将最终答案包裹在<answer>…</answer>标签中，若格式正确，则模型可以获得奖励</p></li></ul><p>而他们在开发DeepSeek-R1-Zero时并没有应用结果或过程神经奖励模型，因为他们发现神经奖励模型在大规模强化学习过程中可能会遭受奖励欺骗，而重新训练奖励模型需要额外的训练资源，并且会使整个训练流程变得复杂</p><h4 id="训练模板：通过prompt让Zero启动深度思考的推理模式">训练模板：通过prompt让Zero启动深度思考的推理模式</h4><p>为了训练 DeepSeek-R1-Zero，他们首先设计了一个简单的模板，以指导基础模型遵循作者指定的指令</p><p>如下表表 1 -DeepSeek-R1-Zero的模板所示</p><p><img src="b7c118e9577b461aa823d9ee5e94702c.png" alt=""></p><ol><li><em>prompt</em> <em>在训练期间将被替换为特定的推理问题</em></li><li>该模板要求 DeepSeek-R1-Zero <strong>先生成推理过程，然后再给出最终答案</strong>——<em>相当于prompt，<strong><think>推理轨迹COT</think></strong>，answer/response</em></li></ol><p>作者故意设置这种结构格式，避免对任何内容有特定的偏见，例如<strong>要求反思性推理</strong>或促进特定的问题解决策略，以确保在RL过程中，他们能够准确观察模型的自然进展</p><h3 id="DeepSeek-R1：纯RL训练的性能跃升">DeepSeek R1：纯RL训练的性能跃升</h3><p>蒸馏自：<a target="_blank" rel="noopener external nofollow noreferrer" href="https://blog.csdn.net/v_JULY_v/article/details/145289228">https://blog.csdn.net/v_JULY_v/article/details/145289228</a></p><p>通过纯RL来提升大模型推理能力，他们期望在没有任何监督数据的情况下，强化大模型的推理能力，特别是关注纯RL过程的自我进化。具体而言，他们通过使用DeepSeek-V3-Base作为基础模型，并采用GRPO作为RL框架来提高模型在推理方面的性能。算是<strong>首次公开研究验证LLM的推理能力可以纯粹通过RL激励，而无需SFT</strong></p><blockquote><p>可能有的同学 还没体会到这个「舍弃SFT直接RL训练范式」的含金量，故咱们再对比下之前22年11月底发布的ChatGPT初版的训练模式，如下图所示</p><p><img src="https://i-blog.csdnimg.cn/direct/1312202b06dd478ba0821896dd265aab.png" alt=""></p><ul><li>是不是先SFT、然后训练一个AI奖励模型、最后PPO迭代策略「<em>如果不熟悉的，详看此文《<a target="_blank" rel="noopener external nofollow noreferrer" href="https://blog.csdn.net/v_JULY_v/article/details/128579457" title="ChatGPT技术原理解析：从RL之PPO算法、RLHF到GPT4、instructGPT">ChatGPT技术原理解析：从RL之PPO算法、RLHF到GPT4、instructGPT</a>》，你一定会有收获的</em>」</li><li>而R1-Zero直接摒弃掉最开始的SFT，直接RL训练——规则奖励建模 然后没有critic的GRPO迭代</li></ul></blockquote><p>至于怎么通过RL训练DeepSeek-V3-Base，涉及到RL的常规训练方法「<em>如果对RL不熟，参阅上文提到过的此文《<a target="_blank" rel="noopener external nofollow noreferrer" href="https://blog.csdn.net/v_JULY_v/article/details/128965854" title="强化学习极简入门">强化学习极简入门</a>》</em>」，简言之，类似下图</p><p><img src="https://i-blog.csdnimg.cn/direct/008f74188b9a46168ca313c4eaa3212d.png" alt=""></p><ol><li>上图中的Agent便是我们需要训练的V3，当人类提出一个问题/prompt时，这个问题/prompt就相当于V3所面临的Environment</li><li>接下来，V3便要针对上述问题/prompt做出反应，比如回答该问题/prompt，即输出token给到该问题/Environment——这个V3输出token的动作便是上图中的action，而预测下一个token的策略越好，越能通过实际的token输出，得到更符合问题/Environment的答案—— 故我们要做的就是<strong>不断优化V3的预测策略</strong></li><li>最后，问题/Environment会根据V3的回答给出反馈，这个反馈便是上图中的reward ，而V3追求奖励最大化，从而在奖励最大化的目标下，V3不断优化它自身的预测策略 然后输出更好的token</li></ol><p>最终，在经过数千个RL 步骤后，DeepSeek-R1-Zero 在推理基准测试中表现出超强性能。</p><h4 id="R1的提出背景：解决Zero可读性差等问题">R1的提出背景：解决Zero可读性差等问题</h4><p>作者在受到DeepSeek-R1-Zero令人鼓舞的结果的启发后，自然的出现了两个问题：</p><ol><li>通过结合少量高质量数据作为冷启动，是否可以进一步提高推理性能或加速收敛？</li><li>如何训练一个用户友好的模型，该模型不仅能产生清晰连贯的思维链CoT，还展示出强大的通用能力？</li></ol><p>为了解决这些问题，作者设计了一个训练DeepSeek-R1的流程，该流程包括以下4个阶段：</p><ol><li><strong>SFT</strong> (<em>数千条cold start data</em>)</li><li><strong>RL</strong>/GRPO</li><li><strong>SFT</strong> (<em>结合rejection sampling，80w的推理和非推理数据</em>)</li><li><strong>RL</strong>/GRPO</li></ol><p>具体而言：</p><ol><li>首先收集了数千个冷启动数据来微调 <strong>DeepSeek-V3-Base</strong> 模型</li><li>随后，进行类似 DeepSeek-R1-Zero 的面向推理的强化学习</li><li>当强化学习过程接近收敛时，通过对 RL 检查点进行拒绝采样，结合 DeepSeek-V3 在写作、事实问答和自我认知等领域的监督数据，创建新的 SFT 数据，然后重新训练<strong>DeepSeek-V3-Base</strong> 模型</li><li>在用新数据微调后，检查点会经历额外的 RL 过程——且会考虑到所有场景的提示</li></ol><p>具体如下图所示(这是<a target="_blank" rel="noopener external nofollow noreferrer" href="https://magazine.sebastianraschka.com/p/understanding-reasoning-llms" title="图源">图源</a>，来自Sebastian Raschka所绘)</p><p><img src="7b7251d67ea9440e9c32d0d3d3364812.png" alt=""></p><h4 id="阶段一-冷启动-主要关注推理-：通过R1-Zero生成数千条长CoT数据">阶段一 冷启动(主要关注推理)：通过<strong>R1-Zero生成</strong>数千条长CoT数据</h4><p>与DeepSeek-R1-Zero不同，为了防止RL训练在初期出现不稳定的冷启动阶段，对于DeepSeek-R1，作者构建并收集了一小部分长CoT数据，以微调模型作为初始RL执行者</p><p>为了收集这些数据，他们探索了几种方法：</p><ol><li><p>使用长CoT作为示例进行少样本提示<br><em>比如模型接收到的训练示例如下</em></p><pre><code>Problem: Train travels at 60 mph for 2 hours, how far?Solution: | special_token | Use the formula: Distance = Speed times Time. Speed is 60 mph, Time is 2 hours. Distance = 60 * 2 = 120 miles. | special_token | Summary: Train travels 120 miles. Problem: What is 7 + 3 * 7?Solution:
</code></pre><p><em>然后针对“ 7 + 3*7 = ？ ”这个问题，模型便会按照对应的格式进行回答</em></p><pre><code>| special_token |  Following order of operations (PEMDAS/BODMAS), do multiplication before addition.  So, first calculate 3 * 7 = 21. Then, add 7 to 21. 7 + 21 = 28. | special_token | Summary: The answer is 28.
</code></pre></li><li><p>直接提示模型生成带有反思和验证的详细答案<br>相当于不仅要求模型解决问题，还要明确展示其推理过程，并对答案进行检查<br><em>比如针对上面的老问题：7 + 3*7 = ？</em></p><pre><code>Problem: Solve this, show reasoning step-by-step, and verify:What is 7 + 3*7？
</code></pre></li><li><p>以<strong>可读格式收集DeepSeek-R1-Zero的输出</strong><em>——注意，此举相当于<strong>冷启动的数据来源于R1-Zero的生成</strong></em></p></li><li><p>通过人工注释者的后处理来优化结果<br><em>比如R1-Zero 面对7 + 3*7 = ？，可能生成一个混乱的答案</em></p><pre><code>&lt;think&gt;  ummm... multiply 3 and 7... get 21... then add 7...&lt;/think&gt;&lt;answer&gt; 28 &lt;/answer&gt;
</code></pre><p><em>这个时候，就需要做一定的人工修正，使得推理过程清晰、答案来的明确</em></p><pre><code>| special_token | Reasoning: To solve this, we use order of operations,doing multiplication before addition.Step 1: Multiply 3 by 7, which is 21.Step 2: Add 7 to the result: 7 + 21 = 28.| special_token | Summary: The answer is 28. 
</code></pre></li></ol><p>总之，他们收集了<strong>R1-Zero生成</strong>的数千个冷启动数据来微调DeepSeek-V3-Base作为RL的起点。与DeepSeek-R1-Zero相比，冷启动数据的优势包括</p><ul><li><p>可读性：DeepSeek-R1-Zero 的一个主要限制是其内容通常不适合阅读。其response可能会混合多种语言或缺乏markdown格式来为用户显示答案</p><p>相比之下，在为 DeepSeek-R1创建冷启动数据时，设计了一种可读的模式，包括在每个response的末尾添加摘要，并筛选掉可读性比较差的response<br>比如，他们将输出格式定义为</p><pre><code>|special_token|&lt;reasoning_process&gt;|special_token|&lt;summary&gt;
</code></pre><p>其中reasoning_process是查询的 CoT，summary用于总结推理结果</p></li><li><p>潜力：通过精心设计带有人类先验知识的冷启动数据模式，可以观察到相较于DeepSeek-R1-Zero有更好的表现<br>故，作者认为迭代训练是推理模型的一种更好的方法</p></li></ul><p>在获得高质量的冷启动数据后，便可以对 DeepSeek-V3-Base 进行监督微调SFT</p><h4 id="阶段二-面向推理的GRPO-RL：类似Zero的规则奖励，但增加语言一致性奖励">阶段二 面向推理的GRPO RL：类似Zero的规则奖励，但增加语言一致性奖励</h4><p>在对DeepSeek-V3-Base进行冷启动数据微调后，作者应用与DeepSeek-R1-Zero相同的大规模RL训练过程(背后的RL算法自然也是GRPO了)</p><p>具体而言</p><ol><li>此阶段重点在于增强模型的推理能力，特别是在编码、数学、科学和逻辑推理等推理密集型任务中，这些任务涉及定义明确的问题和清晰的解决方案<br>但面对的问题是，在训练过程中，作者观察到当RL提示涉及多种语言时，CoT经常表现出语言混合现象</li><li>为了缓解语言混合问题<ul><li>作者在RL训练中引入了一种<strong>语言一致性奖励</strong>，该奖励的计算方式为CoT中目标语言词汇的比例<br>尽管消融实验表明这种对齐会导致模型性能略有下降，但这种奖励符合人类偏好，使其更具可读性</li><li>最后，作者通过直接将<strong>推理任务的准确性</strong>和语言一致性奖励<strong>相加来形成最终奖励</strong></li></ul></li><li>然后，作者在阶段一通过冷启动数据的微调模型上应用强化学习RL训练，直到其在推理任务上收敛</li></ol><h4 id="阶段三-V3上的的两轮SFT-结合rejection-sampling-：涉及80w通用层面的推理和非推理数据">阶段三 <strong>V3上的</strong>的两轮SFT(结合rejection sampling)：涉及80w通用层面的推理和非推理数据</h4><p><strong>当阶段二 面向推理的强化学习RL收敛时，作者利用所得的checkpoint来收集用于下一轮(<em>对应着阶段三</em>)的SFT(监督微调)数据</strong>——<em>你是不想问 合着阶段一 阶段二就是为了方便阶段三来收集推理层面的SFT数据？直白点说 不为模型 <strong>为推理数据</strong></em></p><p>与最初冷启动数据主要关注推理不同，此阶段结合了来自其他领域的数据，以增强模型在写作、角色扮演和其他通用任务方面的能力</p><p>具体来说，作者生成数据并按如下所述微调模型</p><ul><li><p><strong>推理SFT数据：来自阶段二模型</strong></p><ul><li><p>作者通过执行拒绝采样「<em>只有那些正确且推理清晰的输出才会被保留，质量较低的输出会被丢弃</em>」，从上述阶段二 RL训练的checkpoint中整理推理提示并生成推理轨迹<br><em>We</em> <em>curate reasoning prompts and generate reasoning trajectories</em> <em>by perform-ing rejection sampling from</em> <em>the checkpoint from the above RL training</em></p></li><li><p><em>在之前的DeepSeek-R1-Zero阶段，作者只包括可以使用**基于规则的奖励(准确性奖励 + 格式奖励)**进行评估的数据</em> 。<strong>然而，在这一阶段，作者通过加入额外的数据来扩展数据集，其中一些使用生成奖励模型</strong>，通过将“真实值和模型预测”输入DeepSeek-V3进行判断，即_we expand the dataset by incorporating additional data, some of which use a generative reward model by feeding the ground-truth and model predictions <strong>into DeepSeek-V3 for judgment</strong>_</p></li><li><p>此外，由于模型输出有时混乱且难以阅读，作者已过滤掉混合语言、长段落和代码块的思维链。对于每个prompt，采样多个response并仅保留正确的响应</p></li><li><p>总共，作者收集了约60万条与推理相关的训练样本</p></li></ul></li><li><p><strong>非推理SFT数据：来自DeepSeek-V3</strong></p><ul><li><p>对于非推理数据，例如写作、事实问答、自我认知，和翻译，作者采用DeepSeek-V3管道并重用DeepSeek-V3的SFT数据集的部分内容</p></li><li><p>对于某些非推理任务，作者调用DeepSeek-V3在回答问题之前通过prompt生成潜在的思维链</p></li><li><p>然而，对于更简单的查询，例如“你好”，不会提供思维链作为响应——因为此时不存在推理的必要性</p></li><li><p>最终，作者总共收集了大约20万个与推理无关的训练样本</p></li></ul></li></ul><p>然后使用上述大约80万样本的精心整理数据集对<strong>DeepSeek-V3-Base</strong>进行两轮微调</p><ul><li>两轮微调相当于两个epoch的sft(<em>当然，具体 如何精心整理、如何具体编排的，在技术报告中暂未透露</em>)</li><li>此外，不知读者_注意到了没有，本阶段三微调的仍然是V3-Base__，而非上面阶段一 SFT之后的模型或阶段二 RL训练的模型__，即We fine-tune DeepSeek-V3-Base for two epochs using the above curated dataset of about 800k samples_」</li></ul><h4 id="阶段四-所有场景的RL：提高有用性和无害性，且混合规则奖励和偏好奖励">阶段四 所有场景的RL：提高有用性和无害性，且混合规则奖励和偏好奖励</h4><p>为了进一步使模型符合人类偏好，作者实施了一个辅助的强化学习阶段，旨在提升模型的有用性和无害性，同时优化其推理能力</p><p>具体来说，作者使用奖励信号和多样的提示分布组合来训练模型</p><ul><li><p>对于推理数据</p><ul><li>作者遵循DeepSeek-R1-Zero中概述的方法，该方法利用基于规则的奖励(<strong>rule-based reward</strong>)来指导数学、代码和逻辑推理领域的学习过程</li><li><em>For reasoning data, we adhere to themethodology outlined in DeepSeek-R1-Zero, which utilizes rule-based rewards to guide thelearning process in math, code, and logical reasoning domains</em></li></ul></li><li><p>对于一般数据</p><ul><li>作者使用奖励模型来捕捉复杂和微妙场景中的人类偏好——<strong>preference reward</strong></li><li><em>For general data, we resort to reward models to capture human preferences in complex and nuanced scenarios.</em></li><li>比如基于 DeepSeek-V3 管道进行构建，并采用类似的偏好对分布和训练提示</li><li><em>We build upon the DeepSeek-V3 pipeline and adopt a similar</em> <em>distribution of preference pairs</em> <em>and training prompts</em></li></ul><p><em>类似的，有个DPO的工作，详见此文《<a target="_blank" rel="noopener external nofollow noreferrer" href="https://blog.csdn.net/v_JULY_v/article/details/134242910" title="RLHF的替代之DPO原理解析：从RLHF、Claude的RAILF到DPO、Zephyr">RLHF的替代之DPO原理解析：从RLHF、Claude的RAILF到DPO、Zephyr</a>》</em></p></li><li><p>对于有用性</p><ul><li>作者专注于最终总结，确保评估强调响应对用户的实用性和相关性，同时尽量减少对基础推理过程的干扰</li></ul></li><li><p>对于无害性</p><ul><li>作者评估模型的整个response，包括推理过程和总结，以识别和减轻生成过程中可能出现的任何潜在风险、偏见或有害内容</li></ul></li></ul><p>最终，奖励信号和多样数据分布的整合使作者能够训练出一个在推理上表现出色，同时优先考虑有用性和无害性的模型</p><blockquote><p>最后，我再把上面4个阶段 用下述表格汇总一下</p><p><strong>阶段一 冷启动SFT</strong></p><p><strong>阶段二 规则奖励下的RL</strong></p><p>R1-Zero模型生成的冷启动数据(包含一定的人工修正)：微调V3</p><p>面向推理的RL：结合三个规则奖励——准确性奖励、格式奖励、语言一致性奖励</p><p><strong>阶段三 增强SFT</strong></p><p><strong>阶段四 规则+偏好奖励下的RL</strong></p><p>来自阶段二模型的60w推理数据</p><p>和V3模型的20w非推理数据：微调V3</p><p>全场景RL</p><p>规则奖励、偏好奖励</p><hr><p>此外，在经过我上面4个阶段的解读之后，你再看本1.3节开头Sebastian Raschka画的那个图 是不是完全清晰、一目了然了？</p><p><img src="7b7251d67ea9440e9c32d0d3d3364812.png" alt=""></p></blockquote><h3 id="DeepSeek-R1一些经验总结：他们不成功的尝试">DeepSeek-R1一些经验总结：他们不成功的尝试</h3><blockquote><p>出处同上</p></blockquote><p>在开发DeepSeek-R1的早期阶段，作者表示也遇到了失败和挫折</p><p>他们在技术报告里分享了他们的失败经验以提供一些见解，但<strong>注意：这并不意味着这些方法无法开发出有效的推理模型</strong></p><h4 id="关于过程奖励模型PRM">关于过程奖励模型PRM</h4><p>PRM是一种合理的方法「<em>关于什么是PRM，详见此文《<a target="_blank" rel="noopener external nofollow noreferrer" href="https://blog.csdn.net/v_JULY_v/article/details/142865592" title="一文通透OpenAI o1：从CoT、Quiet-STaR、Self-Correct、Self-play RL、MCTS等技术细节到工程复现">一文通透OpenAI o1：从CoT、Quiet-STaR、Self-Correct、Self-play RL、MCTS等技术细节到工程复现</a>》的1.3.1节Let’s Verify Step by Step(含ORM、PRM的介绍)</em>」，引导模型朝向更好的方向发展解决推理任务的方法（Lightman等，2023；Uesato等，2022；Wang等，2023）</p><p><img src="59c0443660de4113b0ac7746ad85c196.png" alt=""></p><p>然而，在实践中，PRM有三个主要的限制可能会阻碍其最终成功</p><ol><li>首先，在一般推理中明确定义一个细粒度步骤是具有挑战性的</li><li>其次，确定当前中间步骤是否正确是一项挑战。使用模型进行自动注释可能不会产生令人满意的结果，而手动注释不利于规模化</li><li>第三，一旦引入基于模型的PRM，就不可避免地导致奖励黑客行为（Gao等，2022），重新训练奖励模型需要额外的训练资源，并且复杂化了整个训练流程</li></ol><p>总之，虽然PRM在重新排序模型生成的前N个响应或辅助引导搜索（Snell等，2024）方面表现出良好的能力，但与其在他们实验中引入的大规模强化学习过程中的额外计算开销相比，其优势是有限的</p><h4 id="关于蒙特卡罗树搜索MCTS">关于蒙特卡罗树搜索MCTS</h4><p>受AlphaGo和AlphaZero的启发，作者探索了使用蒙特卡罗树搜索MCTS 来增强测试时计算的可扩展性。这种方法涉及将答案分解成更小的部分，以便模型能够系统地探索解决方案空间</p><ol><li>为此，他们提示模型生成多个标签，这些标签对应于搜索所需的具体推理步骤，在训练中，首先使用收集的提示通过预训练的价值模型引导的MCTS来寻找答案</li><li>随后，使用生成的问题-答案对来训练actor模型和critic模型，迭代地完善这一过程</li></ol><p>然而，当扩大训练规模时，这种方法会遇到几个挑战</p><ol><li><p>首先，与棋类游戏不同，棋类游戏的搜索空间相对明确，而token生成则呈现出指数级增长的搜索空间</p><ul><li>为了解决这个问题，他们为每个节点设置了最大扩展限制，但这可能导致模型陷入局部最优</li></ul></li><li><p>其次，critic模型直接影响生成的质量，因为它指导搜索过程的每一步。而训练一个细粒度的价值模型本质上是困难的，这使得模型难以迭代改进</p><p>虽然AlphaGo的核心成功依赖于训练一个critic模型来逐步提升其性能，但由于token生成的复杂性，这一原则在他们的设置中很难复制</p></li></ol><p>总之，虽然MCTS可以在与预训练的critic模型配对时提高推理性能，但通过自我搜索迭代提升模型性能仍然是一个重大挑战</p><blockquote><p>最后，再说一下DeepSeek-R1的不足与未来计划</p><ol><li>通用能力：目前，DeepSeek-R1在函数调用、多轮对话、复杂角色扮演和json输出等任务中的能力不如DeepSeek-V3<br>未来，他们计划探索如何利用长CoT来增强这些领域的任务</li><li>语言混合：DeepSeek-R1目前针对中文和英文进行了优化，这可能会在处理其他语言的查询时导致语言混合问题。例如，即使查询是用非英语或中文的语言进行的，DeepSeek-R1可能仍会使用英语进行推理和响应<br>故他们计划在未来的更新中解决这一限制</li><li>提示工程：在评估 DeepSeek-R1 时，作者观察到它对提示非常敏感。少样本提示会持续降低其性能。因此，作者建议用户直接描述问题，并使用零样本设置指定输出格式，以获得最佳结果</li><li>软件工程任务：由于长时间的评估影响了强化学习过程的效率，大规模的强化学习在软件工程任务中尚未被广泛应用<br>因此，在软件工程基准测试中，DeepSeek-R1未能显示出比DeepSeek-V3更大的改进<br>未来的版本将通过在软件工程数据上实施拒绝采样或在强化学习过程中引入异步评估来提高效率</li></ol></blockquote><h2 id="MoE">MoE</h2><p>推荐阅读：</p><p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://huggingface.co/blog/zh/moe">https://huggingface.co/blog/zh/moe</a></p><p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://zhuanlan.zhihu.com/p/672712751">https://zhuanlan.zhihu.com/p/672712751</a></p><p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://zhuanlan.zhihu.com/p/673048264">https://zhuanlan.zhihu.com/p/673048264</a></p><p>以下是对https://huggingface.co/blog/zh/moe 的摘抄：</p><p>模型规模是提升模型性能的关键因素之一。在有限的计算资源预算下，用更少的训练步数训练一个更大的模型，往往比用更多的步数训练一个较小的模型效果更佳。</p><p>混合专家模型 (MoE) 的一个显著优势是它们能够在远少于稠密模型所需的计算资源下进行有效的预训练。这意味着在相同的计算预算条件下，您可以显著扩大模型或数据集的规模。特别是在预训练阶段，与稠密模型相比，混合专家模型通常能够更快地达到相同的质量水平。</p><p>那么，究竟什么是一个混合专家模型 (MoE) 呢？作为一种基于 Transformer 架构的模型，混合专家模型主要由两个关键部分组成:</p><ul><li><strong>稀疏 MoE 层</strong>: 这些层代替了传统 Transformer 模型中的前馈网络 (FFN) 层。MoE 层包含若干“专家”(例如 8 个)，每个专家本身是一个独立的神经网络。在实际应用中，这些专家通常是前馈网络 (FFN)，但它们也可以是更复杂的网络结构，甚至可以是 MoE 层本身，从而形成层级式的 MoE 结构。</li><li><strong>门控网络或路由</strong>: 这个部分用于决定哪些令牌 (token) 被发送到哪个专家。例如，在下图中，“More”这个令牌可能被发送到第二个专家，而“Parameters”这个令牌被发送到第一个专家。有时，一个令牌甚至可以被发送到多个专家。令牌的路由方式是 MoE 使用中的一个关键点，因为路由器由学习的参数组成，并且与网络的其他部分一同进行预训练。</li></ul><p><img src="00_switch_transformer.png" alt=""></p><p>总结来说，在混合专家模型 (MoE) 中，我们将传统 Transformer 模型中的每个前馈网络 (FFN) 层替换为 MoE 层，其中 MoE 层由两个核心部分组成: 一个门控网络和若干数量的专家。</p><p>尽管混合专家模型 (MoE) 提供了若干显著优势，例如更高效的预训练和与稠密模型相比更快的推理速度，但它们也伴随着一些挑战:</p><ul><li><strong>训练挑战</strong>: 虽然 MoE 能够实现更高效的计算预训练，但它们在微调阶段往往面临泛化能力不足的问题，长期以来易于引发过拟合现象。</li><li><strong>推理挑战</strong>: MoE 模型虽然可能拥有大量参数，但在推理过程中只使用其中的一部分，这使得它们的推理速度快于具有相同数量参数的稠密模型。然而，这种模型需要将所有参数加载到内存中，因此对内存的需求非常高。以 Mixtral 8x7B 这样的 MoE 为例，需要足够的 VRAM 来容纳一个 47B 参数的稠密模型。之所以是 47B 而不是 8 x 7B = 56B，是因为在 MoE 模型中，只有 FFN 层被视为独立的专家，而模型的其他参数是共享的。此外，假设每个令牌只使用两个专家，那么推理速度 (以 FLOPs 计算) 类似于使用 12B 模型 (而不是 14B 模型)，因为虽然它进行了 2x7B 的矩阵乘法计算，但某些层是共享的。</li></ul><h3 id="什么是稀疏性">什么是稀疏性?</h3><p>稀疏性的概念采用了条件计算的思想。在传统的稠密模型中，所有的参数都会对所有输入数据进行处理。相比之下，稀疏性允许我们仅针对整个系统的某些特定部分执行计算。这意味着并非所有参数都会在处理每个输入时被激活或使用，而是根据输入的特定特征或需求，只有部分参数集合被调用和运行。</p><p>让我们深入分析 Shazeer 对混合专家模型 (MoE) 在翻译应用中的贡献。条件计算的概念 (即仅在每个样本的基础上激活网络的不同部分) 使得在不增加额外计算负担的情况下扩展模型规模成为可能。这一策略在每个 MoE 层中实现了数以千计甚至更多的专家的有效利用。</p><p>这种稀疏性设置确实带来了一些挑战。例如，在混合专家模型 (MoE) 中，尽管较大的批量大小通常有利于提高性能，但当数据通过激活的专家时，实际的批量大小可能会减少。比如，假设我们的输入批量包含 10 个令牌， <strong>可能会有五个令牌被路由到同一个专家，而剩下的五个令牌分别被路由到不同的专家。这导致了批量大小的不均匀分配和资源利用效率不高的问题</strong>。在接下来的部分中，将会讨论 <a target="_blank" rel="noopener external nofollow noreferrer" href="https://huggingface.co/blog/zh/moe#%E8%AE%A9moe%E8%B5%B7%E9%A3%9E">让 MoE 高效运行</a> 的其他挑战以及相应的解决方案。</p><p>那我们应该如何解决这个问题呢？一个可学习的门控网络 (G) 决定将输入的哪一部分发送给哪些专家 (E):</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>y</mi><mo>=</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>G</mi><mo stretchy="false">(</mo><mi>x</mi><msub><mo stretchy="false">)</mo><mi>i</mi></msub><msub><mi>E</mi><mi>i</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">y = \sum_{i=1}^{n} G(x)_i E_i(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathnormal" style="margin-right:.03588em">y</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:2.929066em;vertical-align:-1.277669em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6513970000000002em"><span style="top:-1.872331em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em"><span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathnormal">G</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:.05764em">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:-.05764em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span></span></p><p>在这种设置下，虽然所有专家都会对所有输入进行运算，但通过门控网络的输出进行加权乘法操作。但是，如果 G (门控网络的输出) 为 0 会发生什么呢？如果是这种情况，就没有必要计算相应的专家操作，因此我们可以节省计算资源。那么一个典型的门控函数是什么呢？一个典型的门控函数通常是一个带有 softmax 函数的简单的网络。这个网络将学习将输入发送给哪个专家。</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>G</mi><mi>σ</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mtext>Softmax</mtext><mo stretchy="false">(</mo><mi>x</mi><mo>⋅</mo><msub><mi>W</mi><mi>g</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">G_\sigma(x) = \text{Softmax}(x \cdot W_g)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord"><span class="mord mathnormal">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.151392em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.03588em">σ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord text"><span class="mord">Softmax</span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-.286108em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.15139200000000003em"><span style="top:-2.5500000000000003em;margin-left:-.13889em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.03588em">g</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p><p>Shazeer 等人的工作还探索了其他的门控机制，其中包括带噪声的 TopK 门控 (Noisy Top-K Gating)。这种门控方法引入了一些可调整的噪声，然后保留前 k 个值。具体来说:</p><ol><li>添加一些噪声</li></ol><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>H</mi><mo stretchy="false">(</mo><mi>x</mi><msub><mo stretchy="false">)</mo><mi>i</mi></msub><mo>=</mo><mo stretchy="false">(</mo><mi>x</mi><mo>⋅</mo><msub><mi>W</mi><mi>g</mi></msub><msub><mo stretchy="false">)</mo><mi>i</mi></msub><mo>+</mo><mtext>StandardNormal</mtext><mo stretchy="false">(</mo><mo stretchy="false">)</mo><mo>⋅</mo><mtext>Softplus</mtext><mo stretchy="false">(</mo><mo stretchy="false">(</mo><mi>x</mi><mo>⋅</mo><msub><mi>W</mi><mtext>noise</mtext></msub><msub><mo stretchy="false">)</mo><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">H(x)_i = (x \cdot W_g)_i + \text{StandardNormal}() \cdot \text{Softplus}((x \cdot W_{\text{noise}})_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.08125em">H</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-.286108em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.15139200000000003em"><span style="top:-2.5500000000000003em;margin-left:-.13889em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.03588em">g</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord text"><span class="mord">StandardNormal</span></span><span class="mopen">(</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord text"><span class="mord">Softplus</span></span><span class="mopen">((</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31750199999999995em"><span style="top:-2.5500000000000003em;margin-left:-.13889em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">noise</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p><ol start="2"><li>选择保留前 K 个值</li></ol><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>KeepTopK</mtext><mo stretchy="false">(</mo><mi>v</mi><mo separator="true">,</mo><mi>k</mi><msub><mo stretchy="false">)</mo><mi>i</mi></msub><mo>=</mo><mrow><mo fence="true">{</mo><mtable rowspacing="0.3600em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>v</mi><mi>i</mi></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if </mtext><msub><mi>v</mi><mi>i</mi></msub><mtext> is in the top </mtext><mi>k</mi><mtext> elements of </mtext><mi>v</mi><mo separator="true">,</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mi mathvariant="normal">∞</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mtext>otherwise.</mtext></mstyle></mtd></mtr></mtable></mrow></mrow><annotation encoding="application/x-tex">\text{KeepTopK}(v, k)_i = \begin{cases} v_i &amp; \text{if } v_i \text{ is in the top } k \text{ elements of } v, \\ -\infty &amp; \text{otherwise.} \end{cases}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord text"><span class="mord">KeepTopK</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:.03588em">v</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathnormal" style="margin-right:.03148em">k</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:3.0000299999999998em;vertical-align:-1.25003em"></span><span class="minner"><span class="mopen delimcenter" style="top:0"><span class="delimsizing size4">{</span></span><span class="mord"><span class="mtable"><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.69em"><span style="top:-3.69em"><span class="pstrut" style="height:3.008em"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span><span style="top:-2.25em"><span class="pstrut" style="height:3.008em"></span><span class="mord"><span class="mord">−</span><span class="mord">∞</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.19em"><span></span></span></span></span></span><span class="arraycolsep" style="width:1em"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.69em"><span style="top:-3.69em"><span class="pstrut" style="height:3.008em"></span><span class="mord"><span class="mord text"><span class="mord">if </span></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mord text"><span class="mord"> is in the top </span></span><span class="mord mathnormal" style="margin-right:.03148em">k</span><span class="mord text"><span class="mord"> elements of </span></span><span class="mord mathnormal" style="margin-right:.03588em">v</span><span class="mpunct">,</span></span></span><span style="top:-2.25em"><span class="pstrut" style="height:3.008em"></span><span class="mord"><span class="mord text"><span class="mord">otherwise.</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.19em"><span></span></span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><ol start="3"><li>应用 Softmax 函数</li></ol><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>G</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mtext>Softmax</mtext><mo stretchy="false">(</mo><mtext>KeepTopK</mtext><mo stretchy="false">(</mo><mi>H</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo separator="true">,</mo><mi>k</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">G(x) = \text{Softmax}(\text{KeepTopK}(H(x), k))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal">G</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord text"><span class="mord">Softmax</span></span><span class="mopen">(</span><span class="mord text"><span class="mord">KeepTopK</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:.08125em">H</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathnormal" style="margin-right:.03148em">k</span><span class="mclose">))</span></span></span></span></span></p><p>这种稀疏性引入了一些有趣的特性。通过使用较低的 k 值 (例如 1 或 2)，我们可以比激活多个专家时更快地进行训练和推理。为什么不仅选择最顶尖的专家呢？最初的假设是，需要将输入路由到不止一个专家，以便门控学会如何进行有效的路由选择，因此至少需要选择两个专家。<a target="_blank" rel="noopener external nofollow noreferrer" href="https://huggingface.co/blog/zh/moe#switch-transformers">Switch Transformers</a> 就这点进行了更多的研究。</p><p>我们为什么要添加噪声呢？这是为了专家间的负载均衡！</p><h3 id="混合专家模型中令牌的负载均衡">混合专家模型中令牌的负载均衡</h3><p>正如之前讨论的，如果所有的令牌都被发送到只有少数几个受欢迎的专家，那么训练效率将会降低。在通常的混合专家模型 (MoE) 训练中，门控网络往往倾向于主要激活相同的几个专家。这种情况可能会自我加强，因为受欢迎的专家训练得更快，因此它们更容易被选择。为了缓解这个问题，引入了一个 <strong>辅助损失</strong>，旨在鼓励给予所有专家相同的重要性。这个损失确保所有专家接收到大致相等数量的训练样本，从而平衡了专家之间的选择。接下来的部分还将探讨专家容量的概念，它引入了一个关于专家可以处理多少令牌的阈值。在 <code>transformers</code> 库中，可以通过 <code>aux_loss</code> 参数来控制辅助损失。</p><h3 id="MoEs-and-Transformers">MoEs and Transformers</h3><p>Transformer 类模型明确表明，增加参数数量可以提高性能，因此谷歌使用 <a target="_blank" rel="noopener external nofollow noreferrer" href="https://arxiv.org/abs/2006.16668">GShard</a> 尝试将 Transformer 模型的参数量扩展到超过 6000 亿并不令人惊讶。</p><p>GShard 将在编码器和解码器中的每个前馈网络 (FFN) 层中的替换为使用 Top-2 门控的混合专家模型 (MoE) 层。下图展示了编码器部分的结构。这种架构对于大规模计算非常有效: 当扩展到多个设备时，MoE 层在不同设备间共享，而其他所有层则在每个设备上复制。我们将在 <a target="_blank" rel="noopener external nofollow noreferrer" href="https://huggingface.co/blog/zh/moe#%E8%AE%A9moe%E8%B5%B7%E9%A3%9E">“让 MoE 起飞”</a> 部分对这一点进行更详细的讨论。</p><p><img src="02_moe_block.png" alt="MoE Transformer Encoder"></p><p>为了保持负载平衡和训练效率，GShard 的作者除了引入了上一节中讨论的类似辅助损失外，还引入了一些关键变化:</p><ul><li><strong>随机路由</strong>: 在 Top-2 设置中，我们始终选择排名最高的专家，但第二个专家是根据其权重比例随机选择的。</li><li><strong>专家容量</strong>: 我们可以设定一个阈值，定义一个专家能处理多少令牌。如果两个专家的容量都达到上限，令牌就会溢出，并通过残差连接传递到下一层，或在某些情况下被完全丢弃。专家容量是 MoE 中最重要的概念之一。为什么需要专家容量呢？因为所有张量的形状在编译时是静态确定的，我们无法提前知道多少令牌会分配给每个专家，因此需要一个固定的容量因子。</li></ul><p>GShard 的工作对适用于 MoE 的并行计算模式也做出了重要贡献，但这些内容的讨论超出了这篇博客的范围。</p><p><strong>注意</strong>: 在推理过程中，只有部分专家被激活。同时，有些计算过程是共享的，例如自注意力 (self-attention) 机制，它适用于所有令牌。这就解释了为什么我们可以使用相当于 12B 稠密模型的计算资源来运行一个包含 8 个专家的 47B 模型。如果我们采用 Top-2 门控，模型会使用高达 14B 的参数。但是，由于自注意力操作 (专家间共享) 的存在，实际上模型运行时使用的参数数量是 12B。</p><h3 id="Switch-Transformers">Switch Transformers</h3><p>尽管混合专家模型 (MoE) 显示出了很大的潜力，但它们在训练和微调过程中存在稳定性问题。<a target="_blank" rel="noopener external nofollow noreferrer" href="https://arxiv.org/abs/2101.03961">Switch Transformers</a> 是一项非常激动人心的工作，它深入研究了这些话题。作者甚至在 Hugging Face 上发布了一个 <a target="_blank" rel="noopener external nofollow noreferrer" href="https://huggingface.co/google/switch-c-2048">1.6 万亿参数的 MoE</a>，拥有 2048 个专家，你可以使用 <code>transformers</code> 库来运行它。Switch Transformers 实现了与 T5-XXL 相比 4 倍的预训练速度提升。</p><p><img src="03_switch_layer.png" alt="Switch Transformer Layer"></p><p>就像在 GShard 中一样，作者用混合专家模型 (MoE) 层替换了前馈网络 (FFN) 层。Switch Transformers 提出了一个 Switch Transformer 层，它接收两个输入 (两个不同的令牌) 并拥有四个专家。</p><p>与最初使用至少两个专家的想法相反，Switch Transformers 采用了简化的单专家策略。这种方法的效果包括:</p><ul><li>减少门控网络 (路由) 计算负担</li><li>每个专家的批量大小至少可以减半</li><li>降低通信成本</li><li>保持模型质量</li></ul><p>Switch Transformers 也对 <strong>专家容量</strong> 这个概念进行了研究。</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mrow><mi mathvariant="normal">E</mi><mi mathvariant="normal">x</mi><mi mathvariant="normal">p</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">t</mi><mtext> </mtext><mi mathvariant="normal">C</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">p</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">y</mi></mrow><mo>=</mo><mrow><mo fence="true">(</mo><mfrac><mtext>tokens per batch</mtext><mtext>number of experts</mtext></mfrac><mo fence="true">)</mo></mrow><mo>×</mo><mtext>capacity factor</mtext></mrow><annotation encoding="application/x-tex">\mathrm{Expert~Capacity}=\left(\frac{\text{tokens per batch}}{\text{number of experts}}\right)\times\text{capacity factor}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord"><span class="mord mathrm">Expert</span><span class="mspace nobreak"> </span><span class="mord mathrm" style="margin-right:.01389em">Capacity</span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:2.40003em;vertical-align:-.95003em"></span><span class="minner"><span class="mopen delimcenter" style="top:0"><span class="delimsizing size3">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714399999999998em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord text"><span class="mord">number of experts</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord text"><span class="mord">tokens per batch</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.8804400000000001em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0"><span class="delimsizing size3">)</span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">capacity factor</span></span></span></span></span></span></p><p>上述建议的容量是将批次中的令牌数量均匀分配到各个专家。如果我们使用大于 1 的容量因子，我们为令牌分配不完全平衡时提供了一个缓冲。增加容量因子会导致更高的设备间通信成本，因此这是一个需要考虑的权衡。特别值得注意的是，Switch Transformers 在低容量因子 (例如 1 至 1.25) 下表现出色。</p><p>Switch Transformer 的作者还重新审视并简化了前面章节中提到的负载均衡损失。在训练期间，对于每个 Switch 层的辅助损失被添加到总模型损失中。这种损失鼓励均匀路由，并可以使用超参数进行加权。</p><p>作者还尝试了混合精度的方法，例如用 <code>bfloat16</code> 精度训练专家，同时对其余计算使用全精度进行。较低的精度可以减少处理器间的通信成本、计算成本以及存储张量的内存。然而，在最初的实验中，当专家和门控网络都使用 <code>bfloat16</code> 精度训练时，出现了不稳定的训练现象。这种不稳定性特别是由路由计算引起的，因为路由涉及指数函数等操作，这些操作对精度要求较高。因此，为了保持计算的稳定性和精确性，保持更高的精度是重要的。为了减轻不稳定性，路由过程也使用了全精度。</p><p>Switch Transformers 采用了编码器 - 解码器的架构，实现了与 T5 类似的混合专家模型 (MoE) 版本。<a target="_blank" rel="noopener external nofollow noreferrer" href="https://arxiv.org/abs/2112.06905">GLaM</a> 这篇工作探索了如何使用仅为原来 1/3 的计算资源 (因为 MoE 模型在训练时需要的计算量较少，从而能够显著降低碳足迹) 来训练与 GPT-3 质量相匹配的模型来提高这些模型的规模。作者专注于仅解码器 (decoder-only) 的模型以及少样本和单样本评估，而不是微调。他们使用了 Top-2 路由和更大的容量因子。此外，他们探讨了将容量因子作为一个动态度量，根据训练和评估期间所使用的计算量进行调整。</p><p>以下摘自：<a target="_blank" rel="noopener external nofollow noreferrer" href="https://zhuanlan.zhihu.com/p/673048264">https://zhuanlan.zhihu.com/p/673048264</a></p><h3 id="Moe的优点">Moe的优点</h3><ol><li>任务特异性：采用混合专家方法可以有效地充分利用多个专家模型的优势，每个专家都可以专门处理不同的任务或数据的不同部分，在处理复杂任务时取得更卓越的性能。各个专家模型能够针对不同的数据分布和模式进行建模，从而显著提升模型的准确性和泛化能力，因此模型可以更好地适应任务的复杂性。</li><li>灵活性：混合专家方法展现出卓越的灵活性，能够根据任务的需求灵活选择并组合适宜的专家模型。模型的结构允许根据任务的需要动态选择激活的专家模型，实现对输入数据的灵活处理。这使得模型能够适应不同的输入分布和任务场景，提高了模型的灵活性。</li><li>高效性：由于只有少数专家模型被激活，大部分模型处于未激活状态，混合专家模型具有很高的稀疏性。这种稀疏性带来了计算效率的提升，因为只有特定的专家模型对当前输入进行处理，减少了计算的开销。</li><li>表现能力：每个专家模型可以被设计为更加专业化，能够更好地捕捉输入数据中的模式和关系。整体模型通过组合这些专家的输出，提高了对复杂数据结构的建模能力，从而增强了模型的性能。</li><li>可解释性：由于每个专家模型相对独立，因此模型的决策过程更易于解释和理解，为用户提供更高的可解释性，这对于一些对模型决策过程有强解释要求的应用场景非常重要。</li><li>适应大规模数据：混合专家方法是处理大规模数据集的理想选择，能够有效地应对数据量巨大和特征复杂的挑战，可以利用稀疏矩阵的高效计算，利用GPU的并行能力计算所有专家层，能够有效地应对海量数据和复杂特征的挑战。</li></ol><h3 id="混合专家模型可能面临的问题">混合专家模型可能面临的问题</h3><ol><li>训练复杂性：混合专家模型的训练相对复杂，尤其是涉及到门控网络的参数调整。为了正确地学习专家的权重和整体模型的参数，可能需要更多的训练时间。</li><li>超参数调整：选择适当的超参数，特别是与门控网络相关的参数，以达到最佳性能，是一个复杂的任务。这可能需要通过交叉验证等技术进行仔细调整。</li><li>专家模型设计：专家模型的设计对模型的性能影响显著。选择适当的专家模型结构，确保其在特定任务上有足够的表现力，是一个挑战。</li><li>稀疏性失真：在某些情况下，为了实现稀疏性，门控网络可能会过度地激活或不激活某些专家，导致模型性能下降。需要谨慎设计稀疏性调整策略，以平衡效率和性能。</li><li>动态性问题：在处理动态或快速变化的数据分布时，门控网络可能需要更加灵活的调整，以适应输入数据的变化。这需要额外的处理和设计。</li></ol><p>6.对数据噪声的敏感性：混合专家模型对于数据中的噪声相对敏感，可能在一些情况下表现不如其他更简单的模型。</p><p>此外，还有重要的一点是混合专家模型在分布式计算环境下可能面临通信宽带瓶颈的问题。这主要涉及到混合专家模型的分布式部署，其中不同的专家模型或门控网络可能分布在不同的计算节点上。在这种情况下，模型参数的传输和同步可能导致通信开销过大，成为性能的一个瓶颈。</p><p><img src="https://picx.zhimg.com/v2-063e21031e458f2a1e48c0d5e181d273_1440w.jpg" alt="img"></p><h3 id="缓解通信瓶颈的策略">缓解通信瓶颈的策略</h3><ul><li>模型剪枝和量化：减小模型的大小，包括专家模型和门控网络的参数数量，以降低通信开销。</li><li>异步更新：考虑采用异步更新策略，而不是同步地更新所有节点的参数。这可以减少通信开销，但可能导致模型的一致性稍有降低。</li><li>本地计算：尽可能在本地计算节点上完成任务，减少节点之间的通信需求。这可以通过在节点上部署更多的计算资源来实现。</li><li>压缩技术：使用参数压缩技术，如模型压缩或渐进压缩算法，以减小传输的数据量。</li></ul><blockquote><p>模型压缩技术主要分为两大类：<br>量化（Quantization）：使用低精度（≤16位）存储模型权重。<br>精简Attention：通过一些变种的Attention算法减少模型计算量。</p></blockquote><p>在实际应用中，需要根据具体任务和数据的特性仔细权衡这些问题，选择或调整混合专家模型的结构和参数，以充分发挥其优势并降低可能存在的问题。</p><h3 id="DeepSeekMoE的创新：细粒度专家分割与共享专家隔离">DeepSeekMoE的创新：细粒度专家分割与共享专家隔离</h3><p>摘自：<a target="_blank" rel="noopener external nofollow noreferrer" href="https://blog.csdn.net/v_JULY_v/article/details/145406756">https://blog.csdn.net/v_JULY_v/article/details/145406756</a></p><p>DeepSeekMoE到底有什么创新性呢？</p><p>首先，传统的 MoE 架构用 MoE 层替代了 Transformer 中的前馈网络 (FFNs)。每个 MoE 层由多个专家组成，每个专家在结构上与标准 FFN 相同，每个token被分配给一个 或两个专家</p><blockquote><p>这里面存在两个问题</p><ol><li>在专家数量有限的情况下，分配给特定专家的token更有可能涵盖多种类型的知识，因此，指定的专家将倾向于在其参数中学习截然不同类型的知识，而这些知识难以同时利用。然而，<em>如果每个token可以被路由到更多的专家，分散的知识将有可能在不同的专家中分别学习</em></li><li><em>有些知识是比较大众通用的，所以会导致某几个专家会被调用的异常频繁</em></li></ol></blockquote><p>那是否可以比较好的解决这两个问题呢</p><ul><li><p><strong>对于前者，DeepSeekMoE提出细粒度专家分割——Fine-Grained Expert Segmentation</strong>：在保持参数数量不变的情况下，通过拆分FFN 中间隐藏维度来将专家分割为更细的粒度(<em>说白了，细粒度的专家分割允许将多样化的知识更精细地分解，并更精确地学习到不同的专家中，从而使得专家更专业</em>)</p><p>相应地，在保持计算成本不变的情况下，还激活了更多细粒度的专家，以实现更灵活和适应性更强的激活专家组合(<em>增加的激活专家组合的灵活性也有助于更准确和有针对性的知识获取</em>)</p></li><li><p><strong>对于后者，DeepSeekMoE提出共享专家隔离——Shared Expert Isolatio</strong>：隔离某些专家作为共享专家，这些专家始终被激活，旨在捕捉和巩固不同上下文中的共同知识</p></li></ul><p>综上，如下图所示(<em>子图a展示了具有传统 top-2 路由策略的 MoE 层；子图b说明了细粒度专家分割策略；随后，子图c展示了共享专家隔离策略的集成</em><strong><em>，</em></strong><em>从而构成了完整的 DeepSeekMoE 架构</em>）</p><img src="39337db0e1c64e519f874a934a132fa6.png" style="zoom:20%"><h4 id="粒度专家分割">粒度专家分割</h4><p>具体来说</p><ol><li>在下图a所示的典型MoE架构的基础上，通过将FFN中间隐藏维度减少到<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mi>m</mi></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{m}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.190108em;vertical-align:-.345em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.845108em"><span style="top:-2.6550000000000002em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>其原始大小(<em>比如下图 m=2</em>)，从而将每个专家FFN分割成 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathnormal">m</span></span></span></span> 个更小的专家</li><li>由于每个专家变得更小，特此可以增加激活专家的数量到 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>𝑚</mi></mrow><annotation encoding="application/x-tex">𝑚</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathnormal">m</span></span></span></span> 倍，以保持相同的计算成本，如下图b所示(<em>正因为 m=2，所以下图 b有2N个专家</em>)</li></ol><img src="cb8a0e9ab83d450380f914ef4ddbf77e.png" style="zoom:23%"><p>通过细粒度的专家分割，MoE层的输出可以表示为</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msubsup><mi>h</mi><mi>t</mi><mi>l</mi></msubsup><mo>=</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>m</mi><mi>N</mi></mrow></munderover><mo stretchy="false">(</mo><msub><mi>g</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>t</mi></mrow></msub><msub><mtext>FFN</mtext><mi>i</mi></msub><mo stretchy="false">(</mo><msubsup><mi>u</mi><mi>t</mi><mi>l</mi></msubsup><mo stretchy="false">)</mo><mo>+</mo><msubsup><mi>u</mi><mi>t</mi><mi>l</mi></msubsup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">h_t^l = \sum_{i=1}^{mN} (g_{i,t} \text{FFN}_i (u_t^l) + u_t^l)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.146108em;vertical-align:-.247em"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8991079999999998em"><span style="top:-2.4530000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.01968em">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.247em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:3.106005em;vertical-align:-1.277669em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283360000000002em"><span style="top:-1.872331em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight" style="margin-right:.10903em">N</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mord"><span class="mord text"><span class="mord">FFN</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8991079999999998em"><span style="top:-2.4530000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.01968em">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.247em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1.1491079999999998em;vertical-align:-.25em"></span><span class="mord"><span class="mord mathnormal">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8991079999999998em"><span style="top:-2.4530000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.01968em">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.247em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>g</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>t</mi></mrow></msub><mo>=</mo><mrow><mo fence="true">{</mo><mtable rowspacing="0.3600em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>s</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>t</mi></mrow></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if </mtext><msub><mi>s</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>t</mi></mrow></msub><mo>∈</mo><msub><mtext>Top</mtext><mi>k</mi></msub><mo stretchy="false">(</mo><mo stretchy="false">{</mo><msub><mi>s</mi><mrow><mi>j</mi><mo separator="true">,</mo><mi>t</mi></mrow></msub><mi mathvariant="normal">∣</mi><mn>1</mn><mo>≤</mo><mi>j</mi><mo>≤</mo><mi>m</mi><mi>N</mi><mo stretchy="false">}</mo><mo separator="true">,</mo><mi>m</mi><mi>K</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mtext>otherwise</mtext></mstyle></mtd></mtr></mtable></mrow></mrow><annotation encoding="application/x-tex">g_{i,t} = \begin{cases} s_{i,t} &amp; \text{if } s_{i,t} \in \text{Top}_k(\{s_{j,t} | 1 \leq j \leq mN\}, mK) \\ 0 &amp; \text{otherwise} \end{cases}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.716668em;vertical-align:-.286108em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:3.0000299999999998em;vertical-align:-1.25003em"></span><span class="minner"><span class="mopen delimcenter" style="top:0"><span class="delimsizing size4">{</span></span><span class="mord"><span class="mtable"><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.69em"><span style="top:-3.69em"><span class="pstrut" style="height:3.008em"></span><span class="mord"><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span></span></span><span style="top:-2.25em"><span class="pstrut" style="height:3.008em"></span><span class="mord"><span class="mord">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.19em"><span></span></span></span></span></span><span class="arraycolsep" style="width:1em"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.69em"><span style="top:-3.69em"><span class="pstrut" style="height:3.008em"></span><span class="mord"><span class="mord text"><span class="mord">if </span></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mord"><span class="mord text"><span class="mord">Top</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.24196799999999993em"><span style="top:-2.4558600000000004em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.24414em"><span></span></span></span></span></span></span><span class="mopen">({</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mord">∣1</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mord mathnormal" style="margin-right:.05724em">j</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mord mathnormal">m</span><span class="mord mathnormal" style="margin-right:.10903em">N</span><span class="mclose">}</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathnormal">m</span><span class="mord mathnormal" style="margin-right:.07153em">K</span><span class="mclose">)</span></span></span><span style="top:-2.25em"><span class="pstrut" style="height:3.008em"></span><span class="mord"><span class="mord text"><span class="mord">otherwise</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.19em"><span></span></span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>s</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>t</mi></mrow></msub><mo>=</mo><msub><mtext>Softmax</mtext><mi>i</mi></msub><mo stretchy="false">(</mo><msubsup><mi>u</mi><mi>t</mi><mrow><mi>l</mi><mi>T</mi></mrow></msubsup><msub><mi>e</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">s_{i,t} = \text{Softmax}_i (u_t^{lT} e_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.716668em;vertical-align:-.286108em"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.1491079999999998em;vertical-align:-.25em"></span><span class="mord"><span class="mord text"><span class="mord">Softmax</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8991079999999998em"><span style="top:-2.4530000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.13889em">lT</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.247em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p><blockquote><ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi mathvariant="bold">u</mi><mrow><mn>1</mn><mo>:</mo><mi>T</mi></mrow><mi>l</mi></msubsup><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>T</mi><mo>×</mo><mi>d</mi></mrow></msup></mrow><annotation encoding="application/x-tex">\mathbf{u}_{1: T}^{l} \in \mathbb{R}^{T \times d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.124439em;vertical-align:-.275331em"></span><span class="mord"><span class="mord mathbf">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.849108em"><span style="top:-2.424669em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight" style="margin-right:.13889em">T</span></span></span></span><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.01968em">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.275331em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.8491079999999999em;vertical-align:0"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8491079999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.13889em">T</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight">d</span></span></span></span></span></span></span></span></span></span></span></span>表示第<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi></mrow><annotation encoding="application/x-tex">l</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.01968em">l</span></span></span></span>层注意力模块的所有token的隐藏状态</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi mathvariant="bold">h</mi><mi>t</mi><mi>l</mi></msubsup><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mi>d</mi></msup></mrow><annotation encoding="application/x-tex">\mathbf{h}_{t}^{l} \in \mathbb{R}^{d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.096108em;vertical-align:-.247em"></span><span class="mord"><span class="mord mathbf">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.849108em"><span style="top:-2.4530000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.01968em">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.247em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.849108em;vertical-align:0"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.849108em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span></span></span></span></span></span></span></span></span></span></span></span> 是第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi></mrow><annotation encoding="application/x-tex">l</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.01968em">l</span></span></span></span> 层transformer块后第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.61508em;vertical-align:0"></span><span class="mord mathnormal">t</span></span></span></span> 个token的输出隐藏状态</li></ul></blockquote><p>其中专家参数的总数等于<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.10903em">N</span></span></span></span>乘以标准FFN中的参数数量，并且 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mi>N</mi></mrow><annotation encoding="application/x-tex">mN</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal">m</span><span class="mord mathnormal" style="margin-right:.10903em">N</span></span></span></span> 表示细粒度专家的总数。通 过细粒度专家分割策略，非零门的数量也将增加到 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mi>K</mi></mrow><annotation encoding="application/x-tex">mK</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal">m</span><span class="mord mathnormal" style="margin-right:.07153em">K</span></span></span></span>(相当于K从2到了4)</p><p>举个例子，如果 𝑁 =16，一个典型的top-2路由策略可以产生<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mo fence="true">(</mo><mfrac linethickness="0px"><mn>16</mn><mn>2</mn></mfrac><mo fence="true">)</mo></mrow><mo>=</mo><mn>120</mn></mrow><annotation encoding="application/x-tex">\binom{16}{2}=120</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.245118em;vertical-align:-.35001em"></span><span class="mord"><span class="mopen delimcenter" style="top:0"><span class="delimsizing size1">(</span></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8951079999999999em"><span style="top:-2.3550000000000004em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style="top:-3.144em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">16</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.345em"><span></span></span></span></span></span><span class="mclose delimcenter" style="top:0"><span class="delimsizing size1">)</span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">120</span></span></span></span>种可能的组合。相比之下，如果每个专家被分成4个更小的专家，细粒度路由策略可以产生<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mo fence="true">(</mo><mfrac linethickness="0px"><mn>64</mn><mn>8</mn></mfrac><mo fence="true">)</mo></mrow><mo>=</mo><mn>4</mn><mo separator="true">,</mo><mn>426</mn><mo separator="true">,</mo><mn>165</mn><mo separator="true">,</mo><mn>368</mn></mrow><annotation encoding="application/x-tex">\binom{64}{8}=4,426,165,368</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.245118em;vertical-align:-.35001em"></span><span class="mord"><span class="mopen delimcenter" style="top:0"><span class="delimsizing size1">(</span></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8951079999999999em"><span style="top:-2.3550000000000004em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">8</span></span></span></span><span style="top:-3.144em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">64</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.345em"><span></span></span></span></span></span><span class="mclose delimcenter" style="top:0"><span class="delimsizing size1">)</span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.8388800000000001em;vertical-align:-.19444em"></span><span class="mord">4</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord">426</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord">165</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord">368</span></span></span></span>种。潜在的组合数量以及组合灵活性的激增，增强了实现更准确和有针对性的知识获取的潜力</p><h4 id="共享专家隔离">共享专家隔离</h4><p>在传统的路由策略中，分配给不同专家的token可能需要一些共同的知识或信息。因此，多个专家可能会在各自的参数中获取共享知识，从而导致专家参数的冗余</p><ol><li>然而，如果有共享专家专门用于捕捉和整合不同上下文中的共同知识，那么其他路由专家之间的参数冗余将会减少，这种冗余的减少将有助于构建一个参数更高效且专家更专业化的模型</li><li>为实现这一目标，除了细粒度的专家分割策略外，DeepSeekMoE进一步隔离了<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>K</mi><mi>s</mi></msub></mrow><annotation encoding="application/x-tex">K_{s}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.83333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.07153em">K</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.151392em"><span style="top:-2.5500000000000003em;margin-left:-.07153em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span>个专家作为共享专家，使得无论路由模块如何，每个token都将被确定性地分配给这些共享专家</li></ol><p>为了保持恒定的计算成本，其他路由专家中被激活的专家数量将减少<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>K</mi><mi>s</mi></msub></mrow><annotation encoding="application/x-tex">K_{s}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.83333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.07153em">K</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.151392em"><span style="top:-2.5500000000000003em;margin-left:-.07153em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span>，如下图c所示</p><img src="/f7b389051cd84edb94c070321abdbe98.png" style="zoom:25%"><p>在集成了共享专家隔离策略后，完整的 DeepSeekMoE 架构中的 MoE 层公式如下</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.1600em" columnalign="left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msubsup><mi mathvariant="bold">h</mi><mi>t</mi><mi>l</mi></msubsup><mo>=</mo><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>K</mi><mi>s</mi></msub></msubsup><msub><mrow><mi mathvariant="normal">FFN</mi><mo>⁡</mo></mrow><mi>i</mi></msub><mrow><mo fence="true">(</mo><msubsup><mi mathvariant="bold">u</mi><mi>t</mi><mi>l</mi></msubsup><mo fence="true">)</mo></mrow><mo>+</mo><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><msub><mi>K</mi><mi>s</mi></msub><mo>+</mo><mn>1</mn></mrow><mrow><mi>m</mi><mi>N</mi></mrow></msubsup><mrow><mo fence="true">(</mo><msub><mi>g</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>t</mi></mrow></msub><msub><mrow><mi mathvariant="normal">FFN</mi><mo>⁡</mo></mrow><mi>i</mi></msub><mrow><mo fence="true">(</mo><msubsup><mi mathvariant="bold">u</mi><mi>t</mi><mi>l</mi></msubsup><mo fence="true">)</mo></mrow><mo fence="true">)</mo></mrow><mo>+</mo><msubsup><mi mathvariant="bold">u</mi><mi>t</mi><mi>l</mi></msubsup><mo separator="true">,</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msub><mi>g</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>t</mi></mrow></msub><mo>=</mo><mrow><mo fence="true">{</mo><mtable rowspacing="0.1600em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msub><mi>s</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>t</mi></mrow></msub><mo separator="true">,</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msub><mi>s</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>t</mi></mrow></msub><mo>∈</mo><mi mathvariant="normal">Topk</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><mrow><mo fence="true">{</mo><msub><mi>s</mi><mrow><mi>j</mi><mo separator="true">,</mo><mi>t</mi></mrow></msub><mo>∣</mo><msub><mi>K</mi><mi>s</mi></msub><mo>+</mo><mn>1</mn><mo>⩽</mo><mi>j</mi><mo>⩽</mo><mi>m</mi><mi>N</mi><mo fence="true">}</mo></mrow><mo separator="true">,</mo><mi>m</mi><mi>K</mi><mo>−</mo><msub><mi>K</mi><mi>s</mi></msub><mo fence="true">)</mo></mrow><mo separator="true">,</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mn>0</mn><mo separator="true">,</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mtext> otherwise, </mtext></mstyle></mtd></mtr></mtable></mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msub><mi>s</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>t</mi></mrow></msub><mo>=</mo><msub><mrow><mi mathvariant="normal">Softmax</mi><mo>⁡</mo></mrow><mi>i</mi></msub><mrow><mo fence="true">(</mo><msubsup><mi mathvariant="bold">u</mi><mi>t</mi><msup><mi>l</mi><mi>T</mi></msup></msubsup><msubsup><mi mathvariant="bold">e</mi><mi>i</mi><mi>l</mi></msubsup><mo fence="true">)</mo></mrow><mi mathvariant="normal">.</mi></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{array}{l} \mathbf{h}_{t}^{l}=\sum_{i=1}^{K_{s}} \operatorname{FFN}_{i}\left(\mathbf{u}_{t}^{l}\right)+\sum_{i=K_{s}+1}^{m N}\left(g_{i, t} \operatorname{FFN}_{i}\left(\mathbf{u}_{t}^{l}\right)\right)+\mathbf{u}_{t}^{l}, \\ g_{i, t}=\left\{\begin{array}{ll} s_{i, t}, &amp; s_{i, t} \in \operatorname{Topk}\left(\left\{s_{j, t} \mid K_{s}+1 \leqslant j \leqslant m N\right\}, m K-K_{s}\right), \\ 0, &amp; \text { otherwise, } \end{array}\right. \\ s_{i, t}=\operatorname{Softmax}_{i}\left(\mathbf{u}_{t}^{l^{T}} \mathbf{e}_{i}^{l}\right) . \end{array}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:5.581090999999999em;vertical-align:-2.5405454999999995em"></span><span class="mord"><span class="mtable"><span class="arraycolsep" style="width:.5em"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:3.0405454999999995em"><span style="top:-5.5093145em"><span class="pstrut" style="height:3.45em"></span><span class="mord"><span class="mord"><span class="mord mathbf">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.849108em"><span style="top:-2.4530000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.01968em">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.247em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-.0000050000000000050004em">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.981231em"><span style="top:-2.40029em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.07153em">K</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.16454285714285719em"><span style="top:-2.357em;margin-left:-.07153em;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.29971000000000003em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mop"><span class="mop"><span class="mord mathrm">FFN</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner"><span class="mopen delimcenter" style="top:0"><span class="delimsizing size1">(</span></span><span class="mord"><span class="mord mathbf">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.849108em"><span style="top:-2.4530000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.01968em">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.247em"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0"><span class="delimsizing size1">)</span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-.0000050000000000050004em">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.981231em"><span style="top:-2.40029em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.07153em">K</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.16454285714285719em"><span style="top:-2.357em;margin-left:-.07153em;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight" style="margin-right:.10903em">N</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.39981em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner"><span class="mopen delimcenter" style="top:0"><span class="delimsizing size1">(</span></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mop"><span class="mop"><span class="mord mathrm">FFN</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner"><span class="mopen delimcenter" style="top:0"><span class="delimsizing size1">(</span></span><span class="mord"><span class="mord mathbf">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.849108em"><span style="top:-2.4530000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.01968em">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.247em"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0"><span class="delimsizing size1">)</span></span></span><span class="mclose delimcenter" style="top:0"><span class="delimsizing size1">)</span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord"><span class="mord mathbf">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.849108em"><span style="top:-2.4530000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.01968em">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.247em"><span></span></span></span></span></span></span><span class="mpunct">,</span></span></span><span style="top:-3.6595044999999997em"><span class="pstrut" style="height:3.45em"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="minner"><span class="mopen delimcenter" style="top:0"><span class="delimsizing size3">{</span></span><span class="mord"><span class="mtable"><span class="arraycolsep" style="width:.5em"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.45em"><span style="top:-3.61em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mpunct">,</span></span></span><span style="top:-2.4099999999999997em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">0</span><span class="mpunct">,</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.9500000000000004em"><span></span></span></span></span></span><span class="arraycolsep" style="width:.5em"></span><span class="arraycolsep" style="width:.5em"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.45em"><span style="top:-3.61em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mop"><span class="mord mathrm">Topk</span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner"><span class="mopen delimcenter" style="top:0">(</span><span class="minner"><span class="mopen delimcenter" style="top:0">{</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.07153em">K</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.151392em"><span style="top:-2.5500000000000003em;margin-left:-.07153em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord">1</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel amsrm">⩽</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mord mathnormal" style="margin-right:.05724em">j</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel amsrm">⩽</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mord mathnormal">m</span><span class="mord mathnormal" style="margin-right:.10903em">N</span><span class="mclose delimcenter" style="top:0">}</span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathnormal">m</span><span class="mord mathnormal" style="margin-right:.07153em">K</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.07153em">K</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.151392em"><span style="top:-2.5500000000000003em;margin-left:-.07153em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0">)</span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mpunct">,</span></span></span><span style="top:-2.4099999999999997em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord text"><span class="mord"> otherwise, </span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.9500000000000004em"><span></span></span></span></span></span><span class="arraycolsep" style="width:.5em"></span></span></span><span class="mclose nulldelimiter"></span></span></span></span><span style="top:-1.5594745000000008em"><span class="pstrut" style="height:3.45em"></span><span class="mord"><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mop"><span class="mop"><span class="mord mathrm">Softmax</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner"><span class="mopen delimcenter" style="top:0"><span class="delimsizing size2">(</span></span><span class="mord"><span class="mord mathbf">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.006365em"><span style="top:-2.4530000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.01968em">l</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.9190928571428572em"><span style="top:-2.931em;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.13889em">T</span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.247em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathbf">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.849108em"><span style="top:-2.441336em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.01968em">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.258664em"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0"><span class="delimsizing size2">)</span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord">.</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.5405454999999995em"><span></span></span></span></span></span><span class="arraycolsep" style="width:.5em"></span></span></span></span></span></span></span></p><p>最后，在 DeepSeekMoE 的完整结构中</p><p><img src="39337db0e1c64e519f874a934a132fa6.png" alt=""></p><ul><li>共享专家的数量是<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>K</mi><mi>s</mi></msub></mrow><annotation encoding="application/x-tex">K_{s}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.83333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.07153em">K</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.151392em"><span style="top:-2.5500000000000003em;margin-left:-.07153em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span>，相当于1</li><li>路由专家的总数是<img src="https://latex.csdn.net/eq?m%20N-K_%7Bs%7D" alt="m N-K_{s}">，相当于2N-1</li><li>非零门的数量是<img src="https://latex.csdn.net/eq?m%20K-K_%7Bs%7D" alt="m K-K_{s}">(<em>如果没有共享专家 则是mK，有共享专家 则减掉共享专家即可</em>)，相当于4 - 1 = 3</li></ul><h4 id="负载平衡：专家级平衡损失、设备级平衡损失">负载平衡：专家级平衡损失、设备级平衡损失</h4><p>自动学习的路由策略可能会遇到负载不平衡的问题，这会表现出两个显著缺陷</p><ol><li><p>首先，存在路由崩溃的风险(Shazeer等人，2017年)，即模型总是选择少数几个专家，导致其他专家无法得到充分训练</p><img src="2b233065b27f4d5fad0c894b17498120.png" style="zoom:30%"></li><li><p>其次，如果专家分布在多个设备上，负载不平衡会加剧计算瓶颈</p></li></ol><p>为了减轻路由崩溃的风险，他们采取了以下两种措施</p><p><strong>第一种，专家级平衡损失</strong></p><img src="2917ce92c443427eba0fa30923370487.png" style="zoom:38%"><p>其中 𝛼1是一个称为专家级平衡因子的超参数，路由专家的数量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>N</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></mrow><annotation encoding="application/x-tex">N^{\prime}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.751892em;vertical-align:0"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.10903em">N</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.751892em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span> 等于 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mi>N</mi><mo>−</mo><msub><mi>K</mi><mi>s</mi></msub></mrow><annotation encoding="application/x-tex">m N-K_{s}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.76666em;vertical-align:-.08333em"></span><span class="mord mathnormal">m</span><span class="mord mathnormal" style="margin-right:.10903em">N</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.83333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.07153em">K</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.151392em"><span style="top:-2.5500000000000003em;margin-left:-.07153em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span>，非零门的数量<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>K</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></mrow><annotation encoding="application/x-tex">K^{\prime}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.751892em;vertical-align:0"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.07153em">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.751892em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span>等于<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mi>K</mi><mo>−</mo><msub><mi>K</mi><mi>s</mi></msub></mrow><annotation encoding="application/x-tex">m K-K_{s}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.76666em;vertical-align:-.08333em"></span><span class="mord mathnormal">m</span><span class="mord mathnormal" style="margin-right:.07153em">K</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.83333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.07153em">K</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.151392em"><span style="top:-2.5500000000000003em;margin-left:-.07153em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span></p><blockquote><p>我个人觉得 上面这种表述 其实挺难理解的，其实通俗点来说，可以如下理解</p><hr><ol><li><p>可以限制每个专家处理的token数量——相当于专家容量，当一个专家的容量达到上限时(<em>比如下图中每个专家的容量是3，这个3 算是代表容量因子</em> )，剩余的token自动会发送给下一个专家</p><img src="21cadefbbfdd4c07aea90ee970825abe.png" style="zoom:33%"></li><li><p>如果被选中的两个专家的容量都已满，则token将不会被任何专家处理，而是被发送给下一层——相当于token溢出 (下图<a target="_blank" rel="noopener external nofollow noreferrer" href="https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-mixture-of-experts" title="图源">图源</a>)</p><img src="4de0a80780544b39be7e7f586128bdcf.png" style="zoom:33%"></li></ol><hr><blockquote><p>此外，为方便大家的理解，我解释一下上面提到的容量因子的概念</p><hr><p>容量因子，简言之，其决定了每个专家可以处理多少个token</p><img src="386a059bdf8d4a80a519fe0098ac016d.png" style="zoom:33%"><p>其组成部分 也很直接</p><img src="4dd7e2004a524792aeb1bcd0de047b22.png" style="zoom:33%"><p>如果增加容量因子，每个专家就能处理更多的 token——<em>当然了，如果容量因子过大 会浪费计算资源；相反，如果容量因子过小，由于 token 溢出，模型性能将下降</em></p><img src="ad0c1b0fe76244479a365430d9109959.png" style="zoom:33%"></blockquote></blockquote><p><strong>第二种，设备级平衡损失</strong></p><p>当旨在缓解计算瓶颈时，在专家级别强制执行严格的平衡约束变得不必要，因为对负载平衡的过度约束会损害模型性能</p><p>相反，主要目标是确保设备间的计算平衡。如果将所有路由的专家划分为组<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo fence="true">{</mo><msub><mi mathvariant="script">E</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi mathvariant="script">E</mi><mn>2</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi mathvariant="script">E</mi><mi>D</mi></msub><mo fence="true">}</mo></mrow><annotation encoding="application/x-tex">\left\{\mathcal{E}_{1}, \mathcal{E}_{2}, \ldots, \mathcal{E}_{D}\right\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="minner"><span class="mopen delimcenter" style="top:0">{</span><span class="mord"><span class="mord mathcal" style="margin-right:.08944em">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.08944em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathcal" style="margin-right:.08944em">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.08944em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner">…</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathcal" style="margin-right:.08944em">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.32833099999999993em"><span style="top:-2.5500000000000003em;margin-left:-.08944em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.02778em">D</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0">}</span></span></span></span></span>，并将每组部署在一个设备上，则设备级平衡损失计算如下</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.2500em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><msub><mi mathvariant="script">L</mi><mtext>DevBal </mtext></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><msub><mi>α</mi><mn>2</mn></msub><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>D</mi></munderover><msubsup><mi>f</mi><mi>i</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><msubsup><mi>P</mi><mi>i</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><msubsup><mi>f</mi><mi>i</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mfrac><mn>1</mn><mrow><mo fence="true">∣</mo><msub><mi mathvariant="script">E</mi><mi>i</mi></msub><mo fence="true">∣</mo></mrow></mfrac><munder><mo>∑</mo><mrow><mi>j</mi><mo>∈</mo><msub><mi mathvariant="script">E</mi><mi>i</mi></msub></mrow></munder><msub><mi>f</mi><mi>j</mi></msub></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><msubsup><mi>P</mi><mi>i</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><munder><mo>∑</mo><mrow><mi>j</mi><mo>∈</mo><msub><mi mathvariant="script">E</mi><mi>i</mi></msub></mrow></munder><msub><mi>P</mi><mi>j</mi></msub></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned} \mathcal{L}_{\text {DevBal }} &amp; =\alpha_{2} \sum_{i=1}^{D} f_{i}^{\prime} P_{i}^{\prime} \\ f_{i}^{\prime} &amp; =\frac{1}{\left|\mathcal{E}_{i}\right|} \sum_{j \in \mathcal{E}_{i}} f_{j} \\ P_{i}^{\prime} &amp; =\sum_{j \in \mathcal{E}_{i}} P_{j} \end{aligned}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:9.238338em;vertical-align:-4.369169em"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:4.869169em"><span style="top:-6.869169em"><span class="pstrut" style="height:3.828336em"></span><span class="mord"><span class="mord"><span class="mord mathcal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.33610799999999996em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">DevBal </span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span><span style="top:-3.97006em"><span class="pstrut" style="height:3.828336em"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:.10764em">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8018919999999999em"><span style="top:-2.4530000000000003em;margin-left:-.10764em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.247em"><span></span></span></span></span></span></span></span></span><span style="top:-1.189611em"><span class="pstrut" style="height:3.828336em"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8018919999999999em"><span style="top:-2.4530000000000003em;margin-left:-.13889em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.247em"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:4.369169em"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:4.869169em"><span style="top:-6.869169em"><span class="pstrut" style="height:3.828336em"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.0037em">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.0037em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283360000000002em"><span style="top:-1.872331em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.02778em">D</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em"><span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.10764em">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8018919999999999em"><span style="top:-2.4530000000000003em;margin-left:-.10764em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.247em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8018919999999999em"><span style="top:-2.4530000000000003em;margin-left:-.13889em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.247em"><span></span></span></span></span></span></span></span></span><span style="top:-3.97006em"><span class="pstrut" style="height:3.828336em"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="minner"><span class="mopen delimcenter" style="top:0">∣</span><span class="mord"><span class="mord mathcal" style="margin-right:.08944em">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:-.08944em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0">∣</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.936em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.050005em"><span style="top:-1.8556639999999998em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span><span class="mrel mtight">∈</span><span class="mord mtight"><span class="mord mathcal mtight" style="margin-right:.08944em">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3280857142857143em"><span style="top:-2.357em;margin-left:-.08944em;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.0500049999999996em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.430444em"><span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.10764em">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:-.10764em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span></span></span><span style="top:-1.189611em"><span class="pstrut" style="height:3.828336em"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.050005em"><span style="top:-1.8556639999999998em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span><span class="mrel mtight">∈</span><span class="mord mtight"><span class="mord mathcal mtight" style="margin-right:.08944em">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3280857142857143em"><span style="top:-2.357em;margin-left:-.08944em;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.0500049999999996em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.430444em"><span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:-.13889em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:4.369169em"><span></span></span></span></span></span></span></span></span></span></span></span></p><p>其中 𝛼2是一个称为设备级平衡因子的超参数</p><p>在实践中，一般设置一个较小的专家级平衡因子以减轻路由崩溃的风险，同时设置一个较大的设备级平衡因子以促进设备之间的计算平衡</p><h2 id="其他">其他</h2><p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://blog.csdn.net/v_JULY_v/article/details/128965854">https://blog.csdn.net/v_JULY_v/article/details/128965854</a></p><p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://zhuanlan.zhihu.com/p/625184011">https://zhuanlan.zhihu.com/p/625184011</a></p><p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://zhuanlan.zhihu.com/p/702294441">https://zhuanlan.zhihu.com/p/702294441</a></p><h3 id="精度">精度</h3><p>BP16 和 FP16 在存储结构、精度表现、数值范围以及适用场景方面有什么不同？</p><ul><li>训练时使用bf16更稳定，表示范围大，并且自带隐式正则化buffer；</li><li>推理时使用fp16比bf16更好，因为fp16表示精度高。 <a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.zhihu.com/question/616600181/answer/3194881239">https://www.zhihu.com/question/616600181/answer/3194881239</a></li></ul><p>在计算领域，<strong>BP16</strong> 和 <strong>FP16</strong> 是两种不同的 <strong>16位浮点数格式</strong>，主要用于深度学习、高性能计算等场景，目的是在内存占用和计算精度之间取得平衡。以下是它们的核心区别、应用场景及技术细节：</p><h4 id="1-FP16（Half-Precision-Floating-Point）"><strong>1. FP16（Half-Precision Floating Point）</strong></h4><ul><li><p><strong>定义</strong>：FP16 是 IEEE 754 标准定义的 <strong>半精度浮点数</strong>，使用 <strong>16位</strong> 存储数值。</p></li><li><p><strong>结构</strong>：</p><ul><li><strong>1位符号位</strong>（Sign）</li><li><strong>5位指数位</strong>（Exponent）</li><li><strong>10位尾数位</strong>（Mantissa）</li><li><strong>动态范围</strong>：约 $$6.1 \times 10^{-5}$$ 到 $$6.5 \times 10^4$$</li><li><strong>精度</strong>：约 3-4 位有效小数位。</li></ul></li><li><p><strong>优点</strong>：</p><ul><li>内存占用仅为 FP32（单精度）的 <strong>1/2</strong>，适合内存敏感场景（如移动端、嵌入式）。</li><li>计算速度更快（尤其在支持 FP16 的 GPU 上，如 NVIDIA Tensor Core）。</li></ul></li><li><p><strong>缺点</strong>：</p><ul><li><strong>动态范围小</strong>：容易导致数值溢出（Inf）或下溢（接近零的值被截断为0）。</li><li><strong>精度不足</strong>：在深度学习训练中可能引发梯度消失或爆炸。</li></ul></li><li><p><strong>应用场景</strong>：</p><ul><li>混合精度训练（搭配 FP32 做梯度累积）。</li><li>推理加速（如 TensorRT 优化模型）。</li><li>移动端/边缘设备部署。</li></ul></li></ul><h4 id="2-BP16（Bfloat16-Brain-Floating-Point）"><strong>2. BP16（Bfloat16, Brain Floating Point）</strong></h4><ul><li><p><strong>定义</strong>：<br>BP16（通常写作 <strong>BF16</strong>）是 Google 提出的 <strong>16位浮点数格式</strong>，专为机器学习设计，<strong>保留与 FP32 相同的指数位</strong>。</p></li><li><p><strong>结构</strong>：</p><ul><li><strong>1位符号位</strong></li><li><strong>8位指数位</strong>（与 FP32 相同）</li><li><strong>7位尾数位</strong></li><li><strong>动态范围</strong>：与 FP32 完全一致（约 $$1.2 \times 10^{-38}$$ 到 $$3.4 \times 10^{38}$$）。</li><li><strong>精度</strong>：约 2-3 位有效小数位。</li></ul></li><li><p><strong>优点</strong>：</p><ul><li><strong>动态范围大</strong>：避免训练中的溢出/下溢问题。</li><li>兼容性高：指数位与 FP32 对齐，方便与 FP32 混合使用。</li><li>硬件支持广泛（如 Intel CPU、Google TPU、NVIDIA Ampere GPU）。</li></ul></li><li><p><strong>缺点</strong>：</p><ul><li>精度比 FP16 <strong>更低</strong>（尾数位更少），可能影响模型收敛。</li></ul></li><li><p><strong>应用场景</strong>：</p><ul><li>深度学习训练（尤其是大模型，如 BERT、GPT）。</li><li>TPU 加速计算。</li><li>需要大动态范围的科学计算。</li></ul></li></ul><h4 id="3-FP16-vs-BP16-关键对比"><strong>3. FP16 vs BP16 关键对比</strong></h4><table><thead><tr><th>特性</th><th>FP16</th><th>BP16（BF16）</th></tr></thead><tbody><tr><td><strong>指数位</strong></td><td>5 bits</td><td>8 bits（同 FP32）</td></tr><tr><td><strong>尾数位</strong></td><td>10 bits</td><td>7 bits</td></tr><tr><td><strong>动态范围</strong></td><td>小（易溢出/下溢）</td><td>大（与 FP32 一致）</td></tr><tr><td><strong>精度</strong></td><td>较高（3-4位小数）</td><td>较低（2-3位小数）</td></tr><tr><td><strong>硬件支持</strong></td><td>NVIDIA GPU</td><td>TPU、Intel、AMD</td></tr><tr><td><strong>典型用途</strong></td><td>推理、移动端</td><td>训练、大模型</td></tr></tbody></table><h4 id="4-混合精度训练（Mixed-Precision-Training）"><strong>4. 混合精度训练（Mixed Precision Training）</strong></h4><ul><li><strong>原理</strong>： 结合 FP16/BP16 和 FP32：<ul><li>前向传播和反向传播用 FP16/BP16 加速计算。</li><li>权重更新和梯度累积用 FP32 维持精度。</li></ul></li></ul><h4 id="5-如何选择-FP16-和-BP16？"><strong>5. 如何选择 FP16 和 BP16？</strong></h4><ul><li><p><strong>选择 FP16</strong>：</p><ul><li>推理场景（内存和速度优先）。</li><li>硬件仅支持 FP16（如早期 GPU）。</li></ul></li><li><p><strong>选择 BP16</strong>：</p><ul><li>训练大模型（需要大动态范围）。</li><li>使用 TPU 或 Intel/AMD 硬件。</li></ul></li><li><p><strong>注意事项</strong>：</p><ul><li><strong>梯度缩放</strong>（Gradient Scaling）：FP16 训练时需放大损失值，避免梯度下溢。</li><li><strong>NaN 检查</strong>：BP16 的精度损失可能导致异常值，需监控数值稳定性。</li></ul></li></ul><h3 id="微调后模型出现复读">微调后模型出现复读</h3><p>微调后模型出现复读现象加剧的原因可能涉及数据、训练策略和解码参数等多个维度，以下是具体分析和解决方案</p><ol><li><p><strong>数据层面</strong></p><ul><li><strong>数据重复性</strong><br>微调数据若包含重复内容（如FAQ问答、用户重复提问），模型会强化记忆这些模式。例如客服对话数据中高频出现的标准回答模板。</li><li><strong>数据多样性下降</strong><br>原生模型训练数据覆盖全网多样化文本，而微调数据往往领域狭窄。如法律文书微调后，模型可能反复使用固定法条表述。</li></ul></li><li><p><strong>训练策略</strong></p><ul><li><strong>过拟合风险</strong><br>小规模数据集（如1万条）微调时，模型容易记住训练样本的局部特征。实验表明，当训练数据量&lt;10%预训练数据时，过拟合概率提升60%以上。</li><li><strong>学习率不当</strong><br>过高的学习率（如&gt;5e-5）会导致权重剧烈抖动，破坏原生模型的泛化能力。实验数据显示，学习率超过1e-4时复读概率增加35%。</li></ul></li><li><p><strong>解码策略</strong></p><ul><li><strong>Temperature设置过低</strong><br>当temperature=0.7时，top-k采样多样性比temperature=0.3时提升2.8倍。微调后若未调整该参数，会加剧确定性输出。</li><li><strong>缺乏重复惩罚</strong><br>GPT-3的API提供<code>frequency_penalty</code>参数（默认0.0），设置1.2可降低重复率40%。若微调后未启用类似机制，复读难以抑制。</li></ul></li></ol><h3 id="softmax">softmax</h3><p>在 Self-Attention 机制中，<strong>Softmax 的核心作用是将注意力分数转换为概率分布</strong>，从而实现对不同位置信息的动态加权。以下是逐步解释：</p><h4 id="1-注意力分数的原始计算"><strong>1. 注意力分数的原始计算</strong></h4><p>Self-Attention 的计算过程始于 Query（Q）和 Key（K）的相似度计算：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>Attention</mtext><mo stretchy="false">(</mo><mi>Q</mi><mo separator="true">,</mo><mi>K</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo><mo>=</mo><mtext>Softmax</mtext><mrow><mo fence="true">(</mo><mfrac><mrow><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup></mrow><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt></mfrac><mo fence="true">)</mo></mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">\text{Attention}(Q, K, V) = \text{Softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord text"><span class="mord">Attention</span></span><span class="mopen">(</span><span class="mord mathnormal">Q</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathnormal" style="margin-right:.07153em">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathnormal" style="margin-right:.22222em">V</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:2.468361em;vertical-align:-.95003em"></span><span class="mord text"><span class="mord">Softmax</span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner"><span class="mopen delimcenter" style="top:0"><span class="delimsizing size3">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.5183309999999999em"><span style="top:-2.25278em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.85722em"><span class="svg-align" style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord" style="padding-left:.833em"><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.33610799999999996em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span><span style="top:-2.81722em"><span class="pstrut" style="height:3em"></span><span class="hide-tail" style="min-width:.853em;height:1.08em"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.18278000000000005em"><span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="mord"><span class="mord mathnormal" style="margin-right:.07153em">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8413309999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.13889em">T</span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.93em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0"><span class="delimsizing size3">)</span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathnormal" style="margin-right:.22222em">V</span></span></span></span></span></p><p>若不使用 Softmax，直接计算 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">QK^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.035771em;vertical-align:-.19444em"></span><span class="mord mathnormal">Q</span><span class="mord"><span class="mord mathnormal" style="margin-right:.07153em">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8413309999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.13889em">T</span></span></span></span></span></span></span></span></span></span></span> 的结果：</p><ul><li><strong>数值范围不可控</strong>：点积结果可能极大（如 1000）或极小（如 -500），导致后续计算不稳定。</li><li><strong>缺乏可比性</strong>：不同位置的注意力分数无法直接比较（例如，某个位置的分数为 100，另一个为 50，但两者绝对值差异未必反映真实重要性）。</li></ul><p>TODO：溢出问题</p><h3 id="正则化">正则化</h3><h4 id="L1-L2正则化">L1/L2正则化</h4><table><thead><tr><th>正则化类型</th><th>数学表达式</th><th>梯度更新公式</th></tr></thead><tbody><tr><td><strong>L1</strong></td><td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi><mo>∑</mo><mi mathvariant="normal">∥</mi><msub><mi>w</mi><mi>i</mi></msub><mi mathvariant="normal">∥</mi></mrow><annotation encoding="application/x-tex">\lambda \sum \|w_i\|</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.00001em;vertical-align:-.25001em"></span><span class="mord mathnormal">λ</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mop op-symbol small-op" style="position:relative;top:-.0000050000000000050004em">∑</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord">∥</span><span class="mord"><span class="mord mathnormal" style="margin-right:.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:-.02691em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mord">∥</span></span></span></span></td><td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mi>j</mi></msub><mo>:</mo><mo>=</mo><msub><mi>w</mi><mi>j</mi></msub><mo>−</mo><mi>η</mi><mo>⋅</mo><mo stretchy="false">(</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>L</mi><mi>o</mi><mi>s</mi><mi>s</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>w</mi><mi>j</mi></msub></mrow></mfrac><mo>+</mo><mi>λ</mi><mo>⋅</mo><mtext>sign</mtext><mo stretchy="false">(</mo><msub><mi>w</mi><mi>j</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">w_j := w_j - \eta \cdot (\frac{\partial Loss}{\partial w_j} + \lambda \cdot \text{sign}(w_j))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.716668em;vertical-align:-.286108em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:-.02691em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">:=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.8694379999999999em;vertical-align:-.286108em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:-.02691em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.63889em;vertical-align:-.19444em"></span><span class="mord mathnormal" style="margin-right:.03588em">η</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1.4224279999999998em;vertical-align:-.5423199999999999em"></span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8801079999999999em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:.05556em">∂</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3280857142857143em"><span style="top:-2.357em;margin-left:-.02691em;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.2818857142857143em"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:.05556em">∂</span><span class="mord mathnormal mtight">L</span><span class="mord mathnormal mtight">oss</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.5423199999999999em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord mathnormal">λ</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-.286108em"></span><span class="mord text"><span class="mord">sign</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:-.02691em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mclose">))</span></span></span></span></td></tr><tr><td><strong>L2</strong></td><td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mi>λ</mi><mn>2</mn></mfrac><mo>∑</mo><msubsup><mi>w</mi><mi>i</mi><mn>2</mn></msubsup></mrow><annotation encoding="application/x-tex">\frac{\lambda}{2} \sum w_i^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2251079999999999em;vertical-align:-.345em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8801079999999999em"><span style="top:-2.6550000000000002em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">λ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mop op-symbol small-op" style="position:relative;top:-.0000050000000000050004em">∑</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8141079999999999em"><span style="top:-2.441336em;margin-left:-.02691em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.258664em"><span></span></span></span></span></span></span></span></span></span></td><td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mi>j</mi></msub><mo>:</mo><mo>=</mo><msub><mi>w</mi><mi>j</mi></msub><mo>−</mo><mi>η</mi><mo>⋅</mo><mo stretchy="false">(</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>L</mi><mi>o</mi><mi>s</mi><mi>s</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>w</mi><mi>j</mi></msub></mrow></mfrac><mo>+</mo><mi>λ</mi><msub><mi>w</mi><mi>j</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">w_j := w_j - \eta \cdot (\frac{\partial Loss}{\partial w_j} + \lambda w_j)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.716668em;vertical-align:-.286108em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:-.02691em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">:=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.8694379999999999em;vertical-align:-.286108em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:-.02691em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.63889em;vertical-align:-.19444em"></span><span class="mord mathnormal" style="margin-right:.03588em">η</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1.4224279999999998em;vertical-align:-.5423199999999999em"></span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8801079999999999em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:.05556em">∂</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3280857142857143em"><span style="top:-2.357em;margin-left:-.02691em;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.2818857142857143em"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:.05556em">∂</span><span class="mord mathnormal mtight">L</span><span class="mord mathnormal mtight">oss</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.5423199999999999em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-.286108em"></span><span class="mord mathnormal">λ</span><span class="mord"><span class="mord mathnormal" style="margin-right:.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:-.02691em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></td></tr></tbody></table><p><strong>关键差异</strong>：</p><ul><li>L1惩罚绝对值，梯度更新时固定增减（符号函数）</li><li>L2惩罚平方值，梯度更新与权重值线性相关</li></ul><table><thead><tr><th>特性</th><th>L1正则化</th><th>L2正则化</th></tr></thead><tbody><tr><td><strong>稀疏性</strong></td><td>✅ 产生稀疏解（自动特征选择）</td><td>❌ 非稀疏解</td></tr><tr><td><strong>抗噪声能力</strong></td><td>❌ 对异常值敏感</td><td>✅ 鲁棒性更强</td></tr><tr><td><strong>解的唯一性</strong></td><td>❌ 可能多解</td><td>✅ 凸优化保证唯一解</td></tr><tr><td><strong>计算复杂度</strong></td><td>较高（需处理不可导点）</td><td>较低（处处可导）</td></tr><tr><td><strong>适用场景</strong></td><td>高维特征选择（NLP/基因）</td><td>防止过拟合（CV/推荐系统）</td></tr></tbody></table><h3 id="分类为什么用cse而不是mse">分类为什么用cse而不是mse</h3><p>分类交叉熵，回归MSE</p><p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://blog.csdn.net/wxc971231/article/details/123866413">https://blog.csdn.net/wxc971231/article/details/123866413</a></p><p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.nowcoder.com/discuss/391362387058716672">https://www.nowcoder.com/discuss/391362387058716672</a></p></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://zwn2001.space">琉璃月</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://zwn2001.space/posts/Graduate-Works/Works/LLM%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/">https://zwn2001.space/posts/Graduate-Works/Works/LLM%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="external nofollow noreferrer" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://zwn2001.space" target="_blank">ZWN's blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/LLM/">LLM</a></div><div class="post_share"><div class="social-share" data-image="/img/cover/41.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://unpkg.com/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload='this.media="all"'><script src="https://unpkg.com/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/posts/Graduate-Works/Works/Defects4J%E4%BD%BF%E7%94%A8%E6%89%8B%E5%86%8C/" title="Defects4J使用"><img class="cover" src="/img/cover/57.jpg" onerror='onerror=null,src="/img/404.webp"' alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Defects4J使用</div></div></a></div><div class="next-post pull-right"><a href="/posts/Graduate-Works/Paper-Read/%E8%AF%BBpaper20-%E5%9F%BA%E4%BA%8ELLM%E7%9A%84%E7%BC%BA%E9%99%B7%E4%BF%AE%E5%A4%8D6/" title="读paper20-基于LLM的缺陷修复6"><img class="cover" src="/img/cover/6.jpg" onerror='onerror=null,src="/img/404.webp"' alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">读paper20-基于LLM的缺陷修复6</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/posts/Graduate-Works/Course-Notes/%E4%BD%BF%E7%94%A8%E4%B8%A2%E7%95%AA%E5%9B%BE%E9%80%BC%E8%BF%91%E4%BC%98%E5%8C%96%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8F%82%E6%95%B0/" title="使用丢番图逼近优化大语言模型的参数"><img class="cover" src="/img/cover/47.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-12-18</div><div class="title">使用丢番图逼近优化大语言模型的参数</div></div></a></div></div></div><hr><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="giscus-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/favicon.webp" onerror='this.onerror=null,this.src="/img/friend_404.gif"' alt="avatar"></div><div class="author-info__name">琉璃月</div><div class="author-info__description">我虽无意逐鹿，却知苍生苦楚</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">171</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">52</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">8</div></a></div><a id="card-info-btn" target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/ZWN2001"><i class="fab fa-github"></i><span>我的Github</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/ZWN2001" rel="external nofollow noreferrer" target="_blank" title="Github"><i class="fab fa-github"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">新域名：www.zwn2001.space，有效期：10年。https://www.zwn-blog.xyz已过期。访问时建议科学上网，否则博客内公式渲染会出现问题且速度慢。Ctrl+shift+r可强制刷新网站以避免浏览器缓存造成的更新不及时</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">LLM基础知识整理</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#LLM-Base"><span class="toc-number">1.1.</span> <span class="toc-text">LLM-Base</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#BERT"><span class="toc-number">1.1.1.</span> <span class="toc-text">BERT</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-%E6%A0%B8%E5%BF%83%E6%9E%B6%E6%9E%84%EF%BC%9ATransformer%E7%BC%96%E7%A0%81%E5%99%A8"><span class="toc-number">1.1.1.1.</span> <span class="toc-text">1. 核心架构：Transformer编码器</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-%E9%A2%84%E8%AE%AD%E7%BB%83%E4%BB%BB%E5%8A%A1"><span class="toc-number">1.1.1.2.</span> <span class="toc-text">2. 预训练任务</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#2-1-%E6%8E%A9%E7%A0%81%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%88Masked-Language-Model-MLM%EF%BC%89"><span class="toc-number">1.1.1.2.1.</span> <span class="toc-text">2.1 掩码语言模型（Masked Language Model, MLM）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-2-%E4%B8%8B%E4%B8%80%E5%8F%A5%E9%A2%84%E6%B5%8B%EF%BC%88Next-Sentence-Prediction-NSP%EF%BC%89"><span class="toc-number">1.1.1.2.2.</span> <span class="toc-text">2.2 下一句预测（Next Sentence Prediction, NSP）</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-%E8%BE%93%E5%85%A5%E8%A1%A8%E7%A4%BA"><span class="toc-number">1.1.1.3.</span> <span class="toc-text">3. 输入表示</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-%E5%85%B3%E9%94%AE%E4%BC%98%E5%8A%BF%E4%B8%8E%E5%B1%80%E9%99%90"><span class="toc-number">1.1.1.4.</span> <span class="toc-text">5. 关键优势与局限</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%89%E7%A7%8D%E5%B5%8C%E5%85%A5"><span class="toc-number">1.1.2.</span> <span class="toc-text">三种嵌入</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-%E8%AF%8D%E5%B5%8C%E5%85%A5%EF%BC%88Token-Embeddings%EF%BC%89"><span class="toc-number">1.1.2.1.</span> <span class="toc-text">1. 词嵌入（Token Embeddings）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BD%9C%E7%94%A8"><span class="toc-number">1.1.2.1.1.</span> <span class="toc-text">作用</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%AE%9E%E7%8E%B0%E7%BB%86%E8%8A%82"><span class="toc-number">1.1.2.1.2.</span> <span class="toc-text">实现细节</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-%E4%BD%8D%E7%BD%AE%E5%B5%8C%E5%85%A5%EF%BC%88Position-Embeddings%EF%BC%89"><span class="toc-number">1.1.2.2.</span> <span class="toc-text">2. 位置嵌入（Position Embeddings）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BD%9C%E7%94%A8-2"><span class="toc-number">1.1.2.2.1.</span> <span class="toc-text">作用</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%AE%9E%E7%8E%B0%E7%BB%86%E8%8A%82-2"><span class="toc-number">1.1.2.2.2.</span> <span class="toc-text">实现细节</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-%E6%AE%B5%E8%90%BD%E5%B5%8C%E5%85%A5%EF%BC%88Segment-Embeddings%EF%BC%89"><span class="toc-number">1.1.2.3.</span> <span class="toc-text">3. 段落嵌入（Segment Embeddings）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BD%9C%E7%94%A8-3"><span class="toc-number">1.1.2.3.1.</span> <span class="toc-text">作用</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%AE%9E%E7%8E%B0%E7%BB%86%E8%8A%82-3"><span class="toc-number">1.1.2.3.2.</span> <span class="toc-text">实现细节</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-%E8%BE%93%E5%85%A5%E6%95%B4%E5%90%88%E6%B5%81%E7%A8%8B"><span class="toc-number">1.1.2.4.</span> <span class="toc-text">4. 输入整合流程</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%AD%A5%E9%AA%A4%E7%A4%BA%E4%BE%8B%EF%BC%88%E8%BE%93%E5%85%A5%E5%8F%A5%E5%AD%90%E5%AF%B9%EF%BC%9A%E2%80%9CHow-are-you-%E2%80%9D-%E5%92%8C-%E2%80%9CI%E2%80%99m-fine-%E2%80%9D%EF%BC%89"><span class="toc-number">1.1.2.4.1.</span> <span class="toc-text">步骤示例（输入句子对：“How are you?” 和 “I’m fine.”）</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Transformer"><span class="toc-number">1.1.3.</span> <span class="toc-text">Transformer</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81Transformer%EF%BC%9F"><span class="toc-number">1.1.3.1.</span> <span class="toc-text">为什么需要Transformer？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A0%B8%E5%BF%83%E7%BB%93%E6%9E%84%EF%BC%9A%E7%BC%96%E7%A0%81%E5%99%A8-%E8%A7%A3%E7%A0%81%E5%99%A8%E6%9E%B6%E6%9E%84"><span class="toc-number">1.1.3.2.</span> <span class="toc-text">核心结构：编码器-解码器架构</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1-%E7%BC%96%E7%A0%81%E5%99%A8%EF%BC%88Encoder%EF%BC%89"><span class="toc-number">1.1.3.2.1.</span> <span class="toc-text">1. 编码器（Encoder）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-%E8%A7%A3%E7%A0%81%E5%99%A8%EF%BC%88Decoder%EF%BC%89"><span class="toc-number">1.1.3.2.2.</span> <span class="toc-text">2. 解码器（Decoder）</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B3%E9%94%AE%E6%8A%80%E6%9C%AF%E7%BB%86%E8%8A%82"><span class="toc-number">1.1.3.3.</span> <span class="toc-text">关键技术细节</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BC%98%E5%8A%BF%E4%B8%8E%E5%B1%80%E9%99%90"><span class="toc-number">1.1.3.4.</span> <span class="toc-text">优势与局限</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8EEncoder%E4%B8%AD%E7%9A%84Q%E3%80%81K%E3%80%81V%E5%85%A8%E9%83%A8%E6%9D%A5%E8%87%AA%E4%BA%8E%E4%B8%8A%E4%B8%80%E5%B1%82%E5%8D%95%E5%85%83%E7%9A%84%E8%BE%93%E5%87%BA%E4%B8%8D%E5%90%8C%EF%BC%8CDecoder%E5%8F%AA%E6%9C%89Q%E6%9D%A5%E8%87%AA%E4%BA%8E%E4%B8%8A%E4%B8%80%E4%B8%AADecoder%E5%8D%95%E5%85%83%E7%9A%84%E8%BE%93%E5%87%BA%EF%BC%8CK%E4%B8%8EV%E9%83%BD%E6%9D%A5%E8%87%AA%E4%BA%8EEncoder%E6%9C%80%E5%90%8E%E4%B8%80%E5%B1%82%E7%9A%84%E8%BE%93%E5%87%BA"><span class="toc-number">1.1.4.</span> <span class="toc-text">为什么与Encoder中的Q、K、V全部来自于上一层单元的输出不同，Decoder只有Q来自于上一个Decoder单元的输出，K与V都来自于Encoder最后一层的输出</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-Encoder%E4%B8%8EDecoder%E7%9A%84%E8%81%8C%E8%B4%A3%E5%B7%AE%E5%BC%82"><span class="toc-number">1.1.5.</span> <span class="toc-text">1. Encoder与Decoder的职责差异</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-Decoder%E7%9A%84%E7%BB%93%E6%9E%84%E4%B8%8E%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6"><span class="toc-number">1.1.6.</span> <span class="toc-text">2. Decoder的结构与注意力机制</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-%E6%8E%A9%E7%A0%81%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%EF%BC%88Masked-Self-Attention%EF%BC%89"><span class="toc-number">1.1.6.1.</span> <span class="toc-text">(1) 掩码自注意力（Masked Self-Attention）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-%E4%BA%A4%E5%8F%89%E6%B3%A8%E6%84%8F%E5%8A%9B%EF%BC%88Encoder-Decoder-Attention%EF%BC%89"><span class="toc-number">1.1.6.2.</span> <span class="toc-text">(2) 交叉注意力（Encoder-Decoder Attention）</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E4%B8%BA%E4%BD%95%E4%BA%A4%E5%8F%89%E6%B3%A8%E6%84%8F%E5%8A%9B%E4%B8%ADK%E3%80%81V%E5%BF%85%E9%A1%BB%E6%9D%A5%E8%87%AAEncoder%EF%BC%9F"><span class="toc-number">1.1.7.</span> <span class="toc-text">3. 为何交叉注意力中K、V必须来自Encoder？</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-%E8%BE%93%E5%85%A5%E4%B8%8E%E8%BE%93%E5%87%BA%E7%9A%84%E8%AF%AD%E4%B9%89%E5%AF%B9%E9%BD%90"><span class="toc-number">1.1.7.1.</span> <span class="toc-text">(1) 输入与输出的语义对齐</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-%E9%81%BF%E5%85%8D%E4%BF%A1%E6%81%AF%E6%B3%84%E9%9C%B2%E4%B8%8E%E8%81%8C%E8%B4%A3%E5%88%86%E7%A6%BB"><span class="toc-number">1.1.7.2.</span> <span class="toc-text">(2) 避免信息泄露与职责分离</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-%E8%AE%A1%E7%AE%97%E6%95%88%E7%8E%87%E4%B8%8E%E5%8F%82%E6%95%B0%E5%A4%8D%E7%94%A8"><span class="toc-number">1.1.7.3.</span> <span class="toc-text">(3) 计算效率与参数复用</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#FFN"><span class="toc-number">1.1.8.</span> <span class="toc-text">FFN</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#FFN%E7%9A%84%E8%AE%B0%E5%BF%86%E5%8A%9F%E8%83%BD"><span class="toc-number">1.1.8.1.</span> <span class="toc-text">FFN的记忆功能</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#FFN-%E6%98%AF%E4%B8%80%E7%A7%8D%E6%B7%B7%E5%90%88%E4%B8%93%E5%AE%B6%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.1.8.2.</span> <span class="toc-text">FFN 是一种混合专家模型</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%AE%8B%E5%B7%AE%E9%93%BE%E6%8E%A5-ResNet%E6%AE%8B%E5%B7%AE%E7%BD%91%E7%BB%9C"><span class="toc-number">1.1.9.</span> <span class="toc-text">残差链接&#x2F;ResNet残差网络</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E6%AE%8B%E5%B7%AE%E8%BF%9E%E6%8E%A5%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="toc-number">1.1.9.1.</span> <span class="toc-text">一、残差连接是什么？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81%E6%AE%8B%E5%B7%AE%E8%BF%9E%E6%8E%A5%EF%BC%9F"><span class="toc-number">1.1.9.2.</span> <span class="toc-text">二、为什么需要残差连接？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E5%9C%A8Transformer%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8"><span class="toc-number">1.1.9.3.</span> <span class="toc-text">三、在Transformer中的应用</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9B%9B%E3%80%81%E6%AE%8B%E5%B7%AE%E8%BF%9E%E6%8E%A5-vs-%E6%99%AE%E9%80%9A%E8%BF%9E%E6%8E%A5"><span class="toc-number">1.1.9.4.</span> <span class="toc-text">四、残差连接 vs 普通连接</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88Transformer%E7%9A%84%E9%95%BF%E8%B7%9D%E7%A6%BB%E4%BE%9D%E8%B5%96%E5%BB%BA%E6%A8%A1%E8%83%BD%E5%8A%9B%E5%BC%BA"><span class="toc-number">1.1.10.</span> <span class="toc-text">为什么Transformer的长距离依赖建模能力强</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81"><span class="toc-number">1.2.</span> <span class="toc-text">位置编码</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E7%BB%9D%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%EF%BC%88Absolute-Position-Encoding%EF%BC%89"><span class="toc-number">1.2.1.</span> <span class="toc-text">一、绝对位置编码（Absolute Position Encoding）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B8%E5%9E%8B%E7%BB%93%E6%9E%84"><span class="toc-number">1.2.1.1.</span> <span class="toc-text">典型结构</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%EF%BC%88Relative-Position-Encoding%EF%BC%89"><span class="toc-number">1.2.2.</span> <span class="toc-text">二、相对位置编码（Relative Position Encoding）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B8%E5%9E%8B%E7%BB%93%E6%9E%84-2"><span class="toc-number">1.2.2.1.</span> <span class="toc-text">典型结构</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E7%BB%9D%E5%AF%B9-vs-%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E7%9A%84%E5%BC%82%E5%90%8C"><span class="toc-number">1.2.3.</span> <span class="toc-text">三、绝对 vs. 相对位置编码的异同</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A0%B8%E5%BF%83%E5%B7%AE%E5%BC%82"><span class="toc-number">1.2.3.1.</span> <span class="toc-text">核心差异</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E4%B8%8E%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E5%A4%96%E6%8E%A8"><span class="toc-number">1.2.4.</span> <span class="toc-text">相对位置编码与位置编码外推</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B3%A8%E6%84%8F%E5%8A%9B"><span class="toc-number">1.3.</span> <span class="toc-text">注意力</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B3%A8%E6%84%8F%E5%8A%9B%E4%B8%8E%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="toc-number">1.3.1.</span> <span class="toc-text">注意力与自注意力的区别</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-%E8%BE%93%E5%85%A5%E6%9D%A5%E6%BA%90%E4%B8%8D%E5%90%8C"><span class="toc-number">1.3.1.1.</span> <span class="toc-text">1. 输入来源不同</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF%E4%B8%8D%E5%90%8C"><span class="toc-number">1.3.1.2.</span> <span class="toc-text">2. 应用场景不同</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-%E8%AE%A1%E7%AE%97%E6%96%B9%E5%BC%8F%E4%B8%8E%E7%BB%93%E6%9E%84%E7%89%B9%E7%82%B9"><span class="toc-number">1.3.1.3.</span> <span class="toc-text">3. 计算方式与结构特点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-%E5%8A%9F%E8%83%BD%E4%B8%8E%E4%BC%98%E5%8A%BF%E5%AF%B9%E6%AF%94"><span class="toc-number">1.3.1.4.</span> <span class="toc-text">4. 功能与优势对比</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">1.3.1.5.</span> <span class="toc-text">总结</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%80%9A%E8%BF%87%E5%90%91%E9%87%8F%E8%AE%A1%E7%AE%97%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B"><span class="toc-number">1.3.2.</span> <span class="toc-text">通过向量计算自注意力</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AC%AC%E4%B8%80%E6%AD%A5%EF%BC%9A%E7%94%9F%E6%88%90%E6%9F%A5%E8%AF%A2%E5%90%91%E9%87%8F%E3%80%81%E9%94%AE%E5%90%91%E9%87%8F%E5%92%8C%E5%80%BC%E5%90%91%E9%87%8F"><span class="toc-number">1.3.2.1.</span> <span class="toc-text">第一步：生成查询向量、键向量和值向量</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AC%AC%E4%BA%8C%E6%AD%A5%EF%BC%9A%E8%AE%A1%E7%AE%97%E5%BE%97%E5%88%86"><span class="toc-number">1.3.2.2.</span> <span class="toc-text">第二步：计算得分</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AC%AC%E4%B8%89%E3%80%81%E5%9B%9B%E6%AD%A5%EF%BC%9A%E5%88%86%E6%95%B0%E9%99%A4%E4%BB%A58%E7%84%B6%E5%90%8Esoftmax"><span class="toc-number">1.3.2.3.</span> <span class="toc-text">第三、四步：分数除以8然后softmax</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AC%AC%E4%BA%94%E3%80%81%E5%85%AD%E6%AD%A5%EF%BC%9A%E5%80%BC%E5%90%91%E9%87%8F%E4%B9%98%E4%BB%A5softmax%E5%88%86%E6%95%B0%E5%90%8E%E5%AF%B9%E5%8A%A0%E6%9D%83%E5%80%BC%E5%90%91%E9%87%8F%E6%B1%82%E5%92%8C"><span class="toc-number">1.3.2.4.</span> <span class="toc-text">第五、六步：值向量乘以softmax分数后对加权值向量求和</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E7%94%A8KV-Cache"><span class="toc-number">1.3.3.</span> <span class="toc-text">为什么用KV Cache</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-%E9%81%BF%E5%85%8D%E9%87%8D%E5%A4%8D%E8%AE%A1%E7%AE%97%EF%BC%8C%E9%99%8D%E4%BD%8E%E8%AE%A1%E7%AE%97%E5%A4%8D%E6%9D%82%E5%BA%A6"><span class="toc-number">1.3.3.1.</span> <span class="toc-text">1. 避免重复计算，降低计算复杂度</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-%E5%87%8F%E5%B0%91%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E5%BC%80%E9%94%80"><span class="toc-number">1.3.3.2.</span> <span class="toc-text">2. 减少内存访问开销</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-%E6%94%AF%E6%8C%81%E6%9B%B4%E9%95%BF%E7%9A%84%E7%94%9F%E6%88%90%E5%BA%8F%E5%88%97"><span class="toc-number">1.3.3.3.</span> <span class="toc-text">3. 支持更长的生成序列</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#KV-Cache%E7%9A%84%E4%BB%A3%E4%BB%B7"><span class="toc-number">1.3.3.4.</span> <span class="toc-text">KV Cache的代价</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%B6%85%E5%8F%82%E6%95%B0"><span class="toc-number">1.4.</span> <span class="toc-text">超参数</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E6%B8%A9%E5%BA%A6%E7%B3%BB%E6%95%B0%EF%BC%88Temperature%EF%BC%89"><span class="toc-number">1.4.1.</span> <span class="toc-text">一、温度系数（Temperature）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BD%9C%E7%94%A8%E6%9C%BA%E5%88%B6"><span class="toc-number">1.4.1.1.</span> <span class="toc-text">作用机制</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%88%E6%9E%9C"><span class="toc-number">1.4.1.2.</span> <span class="toc-text">效果</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%8C%E3%80%81Top-K-%E9%87%87%E6%A0%B7"><span class="toc-number">1.4.2.</span> <span class="toc-text">二、Top-K 采样</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BD%9C%E7%94%A8%E6%9C%BA%E5%88%B6-2"><span class="toc-number">1.4.2.1.</span> <span class="toc-text">作用机制</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%88%E6%9E%9C-2"><span class="toc-number">1.4.2.2.</span> <span class="toc-text">效果</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%89%E3%80%81Top-P%EF%BC%88Nucleus-Sampling%EF%BC%89"><span class="toc-number">1.4.3.</span> <span class="toc-text">三、Top-P（Nucleus Sampling）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BD%9C%E7%94%A8%E6%9C%BA%E5%88%B6-3"><span class="toc-number">1.4.3.1.</span> <span class="toc-text">作用机制</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%88%E6%9E%9C-3"><span class="toc-number">1.4.3.2.</span> <span class="toc-text">效果</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B9%BB%E8%A7%89"><span class="toc-number">1.5.</span> <span class="toc-text">幻觉</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E9%A2%84%E9%98%B2%E9%98%B6%E6%AE%B5%EF%BC%9A%E4%BC%98%E5%8C%96%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E4%B8%8E%E6%9E%B6%E6%9E%84"><span class="toc-number">1.5.1.</span> <span class="toc-text">一、预防阶段：优化模型训练与架构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E7%94%9F%E6%88%90%E6%97%B6%E5%B9%B2%E9%A2%84%EF%BC%9A%E6%8E%A7%E5%88%B6%E8%BE%93%E5%87%BA%E5%8F%AF%E9%9D%A0%E6%80%A7"><span class="toc-number">1.5.2.</span> <span class="toc-text">二、生成时干预：控制输出可靠性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E5%90%8E%E5%A4%84%E7%90%86%EF%BC%9A%E9%AA%8C%E8%AF%81%E4%B8%8E%E4%BF%AE%E6%AD%A3"><span class="toc-number">1.5.3.</span> <span class="toc-text">三、后处理：验证与修正</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9B%9B%E3%80%81%E9%95%BF%E6%9C%9F%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88"><span class="toc-number">1.5.4.</span> <span class="toc-text">四、长期解决方案</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BE%AE%E8%B0%83"><span class="toc-number">1.6.</span> <span class="toc-text">微调</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#LoRA"><span class="toc-number">1.6.1.</span> <span class="toc-text">LoRA</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BF%9B%E8%A1%8CLoRA%E8%AE%AD%E7%BB%83%E7%9A%84%E4%B8%80%E8%88%AC%E6%AD%A5%E9%AA%A4"><span class="toc-number">1.6.1.1.</span> <span class="toc-text">进行LoRA训练的一般步骤</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#QLoRA"><span class="toc-number">1.6.2.</span> <span class="toc-text">QLoRA</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Prompt-Tuning"><span class="toc-number">1.6.3.</span> <span class="toc-text">Prompt Tuning</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86"><span class="toc-number">1.6.3.1.</span> <span class="toc-text">1. 核心原理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-%E4%B8%BB%E8%A6%81%E6%96%B9%E6%B3%95"><span class="toc-number">1.6.3.2.</span> <span class="toc-text">2. 主要方法</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1-%E7%A1%AC%E6%8F%90%E7%A4%BA%EF%BC%88Hard-Prompts%EF%BC%89"><span class="toc-number">1.6.3.2.1.</span> <span class="toc-text">(1) 硬提示（Hard Prompts）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-%E8%BD%AF%E6%8F%90%E7%A4%BA%EF%BC%88Soft-Prompts%EF%BC%89"><span class="toc-number">1.6.3.2.2.</span> <span class="toc-text">(2) 软提示（Soft Prompts）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3-%E6%B7%B7%E5%90%88%E6%96%B9%E6%B3%95"><span class="toc-number">1.6.3.2.3.</span> <span class="toc-text">(3) 混合方法</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-%E4%BC%98%E5%8A%BF"><span class="toc-number">1.6.3.3.</span> <span class="toc-text">3. 优势</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#DPO%E3%80%81PPO"><span class="toc-number">1.7.</span> <span class="toc-text">DPO、PPO</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AE%80%E5%8D%95%E9%98%90%E8%BF%B0"><span class="toc-number">1.7.1.</span> <span class="toc-text">简单阐述</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#PPO%EF%BC%88Proximal-Policy-Optimization%EF%BC%89"><span class="toc-number">1.7.1.1.</span> <span class="toc-text">PPO（Proximal Policy Optimization）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86"><span class="toc-number">1.7.1.1.1.</span> <span class="toc-text">工作原理</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%AE%9E%E7%8E%B0%E6%AD%A5%E9%AA%A4"><span class="toc-number">1.7.1.1.2.</span> <span class="toc-text">实现步骤</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#reward-model%E5%92%8Ccritic-network%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="toc-number">1.7.1.1.3.</span> <span class="toc-text">reward model和critic network的区别</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#DPO-Direct-Preference-Optimization"><span class="toc-number">1.7.1.2.</span> <span class="toc-text">DPO (Direct Preference Optimization)</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#RL%E4%B8%AD%E7%9A%84%E6%94%B9%E8%BF%9B%E8%BF%87%E7%A8%8B"><span class="toc-number">1.7.2.</span> <span class="toc-text">RL中的改进过程</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Actor-Critic-%E7%AE%97%E6%B3%95"><span class="toc-number">1.7.2.1.</span> <span class="toc-text">Actor-Critic 算法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#TRPO"><span class="toc-number">1.7.2.2.</span> <span class="toc-text">TRPO</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#PPO"><span class="toc-number">1.7.2.3.</span> <span class="toc-text">PPO</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Agent"><span class="toc-number">1.8.</span> <span class="toc-text">Agent</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#RAG"><span class="toc-number">1.9.</span> <span class="toc-text">RAG</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BC%98%E5%8C%96"><span class="toc-number">1.9.1.</span> <span class="toc-text">优化</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-%E5%AF%B9%E6%96%87%E6%A1%A3%E5%86%85%E5%AE%B9%E8%BF%9B%E8%A1%8C%E9%87%8D%E6%96%B0%E5%A4%84%E7%90%86%EF%BC%8C%E4%BB%A5%E6%9B%B4%E5%87%86%E7%A1%AE%E5%9C%B0%E6%8F%90%E5%8F%96%E5%92%8C%E8%A1%A8%E7%A4%BA%E4%BF%A1%E6%81%AF%E3%80%82"><span class="toc-number">1.9.1.1.</span> <span class="toc-text">1. 对文档内容进行重新处理，以更准确地提取和表示信息。</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-%E5%AE%9E%E6%96%BD%E8%AF%AD%E4%B9%89%E5%88%87%E5%88%86%EF%BC%8C%E4%BB%A5%E4%BF%9D%E6%8C%81%E6%96%87%E6%9C%AC%E6%AE%B5%E8%90%BD%E7%9A%84%E5%AE%8C%E6%95%B4%E6%80%A7%E5%92%8C%E8%AF%AD%E4%B9%89%E8%BF%9E%E8%B4%AF%E6%80%A7%E3%80%82"><span class="toc-number">1.9.1.2.</span> <span class="toc-text">2. 实施语义切分，以保持文本段落的完整性和语义连贯性。</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-%E4%BD%BF%E7%94%A8RAG-Fusion%E6%8A%80%E6%9C%AF%E6%9D%A5%E5%A2%9E%E5%8A%A0%E7%9B%B8%E5%85%B3%E6%96%87%E6%9C%AC%E5%9D%97%E7%9A%84%E5%8F%AC%E5%9B%9E%E7%8E%87%E3%80%82"><span class="toc-number">1.9.1.3.</span> <span class="toc-text">3. 使用RAG Fusion技术来增加相关文本块的召回率。</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-%E5%BC%95%E5%85%A5%E8%BF%BD%E9%97%AE%E6%9C%BA%E5%88%B6%EF%BC%8C%E9%80%9A%E8%BF%87%E5%A4%9A%E8%BD%AE%E5%AF%B9%E8%AF%9D%E6%9D%A5%E6%98%8E%E7%A1%AE%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E3%80%82"><span class="toc-number">1.9.1.4.</span> <span class="toc-text">4. 引入追问机制，通过多轮对话来明确用户的问题。</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-%E5%BE%AE%E8%B0%83Embedding%E5%8F%A5%E5%90%91%E9%87%8F%E6%A8%A1%E5%9E%8B%EF%BC%8C%E4%BB%A5%E6%9B%B4%E5%A5%BD%E5%9C%B0%E9%80%82%E5%BA%94%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E7%9A%84%E7%9F%A5%E8%AF%86%E3%80%82"><span class="toc-number">1.9.1.5.</span> <span class="toc-text">5. 微调Embedding句向量模型，以更好地适应垂直领域的知识。</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E5%88%86%E5%B1%82%E7%B4%A2%E5%BC%95%E6%A3%80%E7%B4%A2"><span class="toc-number">1.9.2.</span> <span class="toc-text">使用分层索引检索</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#RAG-Fusion"><span class="toc-number">1.9.3.</span> <span class="toc-text">RAG Fusion</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#RRF-%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86"><span class="toc-number">1.9.3.1.</span> <span class="toc-text">RRF 算法原理</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#RRF%E7%9A%84%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B"><span class="toc-number">1.9.3.1.1.</span> <span class="toc-text">RRF的工作流程</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#RRF%E8%83%8C%E5%90%8E%E7%9A%84%E6%95%B0%E5%AD%A6%E7%9B%B4%E8%A7%89"><span class="toc-number">1.9.3.2.</span> <span class="toc-text">RRF背后的数学直觉</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#k-%E5%80%BC%E7%9A%84%E9%80%89%E6%8B%A9"><span class="toc-number">1.9.3.3.</span> <span class="toc-text">k 值的选择</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%90%91%E9%87%8F%E5%AD%98%E5%82%A8%E4%B8%8E%E6%A3%80%E7%B4%A2"><span class="toc-number">1.10.</span> <span class="toc-text">向量存储与检索</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#langchain%E7%9A%84memory"><span class="toc-number">1.10.1.</span> <span class="toc-text">langchain的memory</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93"><span class="toc-number">1.10.2.</span> <span class="toc-text">向量数据库</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Faiss"><span class="toc-number">1.10.2.1.</span> <span class="toc-text">Faiss</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#langchain"><span class="toc-number">1.11.</span> <span class="toc-text">langchain</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#FlashAttention"><span class="toc-number">1.12.</span> <span class="toc-text">FlashAttention</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Transformer%E8%AE%A1%E7%AE%97%E5%A4%8D%E6%9D%82%E5%BA%A6-%E2%80%94%E2%80%94-Self-Attention%E5%B1%82%E4%B8%8EMLP%E5%B1%82"><span class="toc-number">1.12.1.</span> <span class="toc-text">Transformer计算复杂度*——*Self-Attention层与MLP层</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Flash-Attention%EF%BC%9A%E9%80%9A%E8%BF%87kernel%E8%9E%8D%E5%90%88%E9%99%8D%E4%BD%8EHBM%E8%AF%BB%E5%86%99%E6%AC%A1%E6%95%B0%EF%BC%8C%E9%81%BF%E5%85%8D%E9%A2%91%E7%B9%81%E5%9C%B0%E4%BB%8EHBM%E4%B8%AD%E8%AF%BB%E5%86%99%E6%95%B0%E6%8D%AE"><span class="toc-number">1.12.2.</span> <span class="toc-text">Flash Attention：通过kernel融合降低HBM读写次数，避免频繁地从HBM中读写数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Flash-Attention2%EF%BC%9A%E6%AF%94Flash-Attention%E5%BF%AB2%E5%80%8D"><span class="toc-number">1.12.3.</span> <span class="toc-text">Flash Attention2：比Flash Attention快2倍</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#deepseek"><span class="toc-number">1.13.</span> <span class="toc-text">deepseek</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#MLA"><span class="toc-number">1.13.1.</span> <span class="toc-text">MLA</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#GRPO"><span class="toc-number">1.13.2.</span> <span class="toc-text">GRPO</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#R1-Zero%EF%BC%9ARL%E7%AE%97%E6%B3%95GRPO%E3%80%81%E6%A0%BC%E5%BC%8F%E5%A5%96%E5%8A%B1%E3%80%81%E8%AE%AD%E7%BB%83%E6%A8%A1%E6%9D%BF"><span class="toc-number">1.13.3.</span> <span class="toc-text">R1-Zero：RL算法GRPO、格式奖励、训练模板</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#RL%E7%AE%97%E6%B3%95GRPO%EF%BC%9A%E4%B8%8D%E9%9C%80%E8%A6%81critic"><span class="toc-number">1.13.3.1.</span> <span class="toc-text">RL算法GRPO：不需要critic</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%A7%84%E5%88%99%E5%A5%96%E5%8A%B1%E5%BB%BA%E6%A8%A1-%E5%87%86%E7%A1%AE%E6%80%A7%E5%A5%96%E5%8A%B1-%E6%A0%BC%E5%BC%8F%E5%A5%96%E5%8A%B1-%EF%BC%9A%E4%B8%8D%E7%94%A8%E8%AE%AD%E7%BB%83%E4%B8%93%E9%97%A8%E7%9A%84%E5%81%8F%E5%A5%BD%E5%A5%96%E5%8A%B1%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.13.3.2.</span> <span class="toc-text">规则奖励建模(准确性奖励 + 格式奖励)：不用训练专门的偏好奖励模型</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E6%A8%A1%E6%9D%BF%EF%BC%9A%E9%80%9A%E8%BF%87prompt%E8%AE%A9Zero%E5%90%AF%E5%8A%A8%E6%B7%B1%E5%BA%A6%E6%80%9D%E8%80%83%E7%9A%84%E6%8E%A8%E7%90%86%E6%A8%A1%E5%BC%8F"><span class="toc-number">1.13.3.3.</span> <span class="toc-text">训练模板：通过prompt让Zero启动深度思考的推理模式</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#DeepSeek-R1%EF%BC%9A%E7%BA%AFRL%E8%AE%AD%E7%BB%83%E7%9A%84%E6%80%A7%E8%83%BD%E8%B7%83%E5%8D%87"><span class="toc-number">1.13.4.</span> <span class="toc-text">DeepSeek R1：纯RL训练的性能跃升</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#R1%E7%9A%84%E6%8F%90%E5%87%BA%E8%83%8C%E6%99%AF%EF%BC%9A%E8%A7%A3%E5%86%B3Zero%E5%8F%AF%E8%AF%BB%E6%80%A7%E5%B7%AE%E7%AD%89%E9%97%AE%E9%A2%98"><span class="toc-number">1.13.4.1.</span> <span class="toc-text">R1的提出背景：解决Zero可读性差等问题</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%98%B6%E6%AE%B5%E4%B8%80-%E5%86%B7%E5%90%AF%E5%8A%A8-%E4%B8%BB%E8%A6%81%E5%85%B3%E6%B3%A8%E6%8E%A8%E7%90%86-%EF%BC%9A%E9%80%9A%E8%BF%87R1-Zero%E7%94%9F%E6%88%90%E6%95%B0%E5%8D%83%E6%9D%A1%E9%95%BFCoT%E6%95%B0%E6%8D%AE"><span class="toc-number">1.13.4.2.</span> <span class="toc-text">阶段一 冷启动(主要关注推理)：通过R1-Zero生成数千条长CoT数据</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%98%B6%E6%AE%B5%E4%BA%8C-%E9%9D%A2%E5%90%91%E6%8E%A8%E7%90%86%E7%9A%84GRPO-RL%EF%BC%9A%E7%B1%BB%E4%BC%BCZero%E7%9A%84%E8%A7%84%E5%88%99%E5%A5%96%E5%8A%B1%EF%BC%8C%E4%BD%86%E5%A2%9E%E5%8A%A0%E8%AF%AD%E8%A8%80%E4%B8%80%E8%87%B4%E6%80%A7%E5%A5%96%E5%8A%B1"><span class="toc-number">1.13.4.3.</span> <span class="toc-text">阶段二 面向推理的GRPO RL：类似Zero的规则奖励，但增加语言一致性奖励</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%98%B6%E6%AE%B5%E4%B8%89-V3%E4%B8%8A%E7%9A%84%E7%9A%84%E4%B8%A4%E8%BD%AESFT-%E7%BB%93%E5%90%88rejection-sampling-%EF%BC%9A%E6%B6%89%E5%8F%8A80w%E9%80%9A%E7%94%A8%E5%B1%82%E9%9D%A2%E7%9A%84%E6%8E%A8%E7%90%86%E5%92%8C%E9%9D%9E%E6%8E%A8%E7%90%86%E6%95%B0%E6%8D%AE"><span class="toc-number">1.13.4.4.</span> <span class="toc-text">阶段三 V3上的的两轮SFT(结合rejection sampling)：涉及80w通用层面的推理和非推理数据</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%98%B6%E6%AE%B5%E5%9B%9B-%E6%89%80%E6%9C%89%E5%9C%BA%E6%99%AF%E7%9A%84RL%EF%BC%9A%E6%8F%90%E9%AB%98%E6%9C%89%E7%94%A8%E6%80%A7%E5%92%8C%E6%97%A0%E5%AE%B3%E6%80%A7%EF%BC%8C%E4%B8%94%E6%B7%B7%E5%90%88%E8%A7%84%E5%88%99%E5%A5%96%E5%8A%B1%E5%92%8C%E5%81%8F%E5%A5%BD%E5%A5%96%E5%8A%B1"><span class="toc-number">1.13.4.5.</span> <span class="toc-text">阶段四 所有场景的RL：提高有用性和无害性，且混合规则奖励和偏好奖励</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#DeepSeek-R1%E4%B8%80%E4%BA%9B%E7%BB%8F%E9%AA%8C%E6%80%BB%E7%BB%93%EF%BC%9A%E4%BB%96%E4%BB%AC%E4%B8%8D%E6%88%90%E5%8A%9F%E7%9A%84%E5%B0%9D%E8%AF%95"><span class="toc-number">1.13.5.</span> <span class="toc-text">DeepSeek-R1一些经验总结：他们不成功的尝试</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B3%E4%BA%8E%E8%BF%87%E7%A8%8B%E5%A5%96%E5%8A%B1%E6%A8%A1%E5%9E%8BPRM"><span class="toc-number">1.13.5.1.</span> <span class="toc-text">关于过程奖励模型PRM</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B3%E4%BA%8E%E8%92%99%E7%89%B9%E5%8D%A1%E7%BD%97%E6%A0%91%E6%90%9C%E7%B4%A2MCTS"><span class="toc-number">1.13.5.2.</span> <span class="toc-text">关于蒙特卡罗树搜索MCTS</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#MoE"><span class="toc-number">1.14.</span> <span class="toc-text">MoE</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E7%A8%80%E7%96%8F%E6%80%A7"><span class="toc-number">1.14.1.</span> <span class="toc-text">什么是稀疏性?</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B7%B7%E5%90%88%E4%B8%93%E5%AE%B6%E6%A8%A1%E5%9E%8B%E4%B8%AD%E4%BB%A4%E7%89%8C%E7%9A%84%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1"><span class="toc-number">1.14.2.</span> <span class="toc-text">混合专家模型中令牌的负载均衡</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#MoEs-and-Transformers"><span class="toc-number">1.14.3.</span> <span class="toc-text">MoEs and Transformers</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Switch-Transformers"><span class="toc-number">1.14.4.</span> <span class="toc-text">Switch Transformers</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Moe%E7%9A%84%E4%BC%98%E7%82%B9"><span class="toc-number">1.14.5.</span> <span class="toc-text">Moe的优点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B7%B7%E5%90%88%E4%B8%93%E5%AE%B6%E6%A8%A1%E5%9E%8B%E5%8F%AF%E8%83%BD%E9%9D%A2%E4%B8%B4%E7%9A%84%E9%97%AE%E9%A2%98"><span class="toc-number">1.14.6.</span> <span class="toc-text">混合专家模型可能面临的问题</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%93%E8%A7%A3%E9%80%9A%E4%BF%A1%E7%93%B6%E9%A2%88%E7%9A%84%E7%AD%96%E7%95%A5"><span class="toc-number">1.14.7.</span> <span class="toc-text">缓解通信瓶颈的策略</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#DeepSeekMoE%E7%9A%84%E5%88%9B%E6%96%B0%EF%BC%9A%E7%BB%86%E7%B2%92%E5%BA%A6%E4%B8%93%E5%AE%B6%E5%88%86%E5%89%B2%E4%B8%8E%E5%85%B1%E4%BA%AB%E4%B8%93%E5%AE%B6%E9%9A%94%E7%A6%BB"><span class="toc-number">1.14.8.</span> <span class="toc-text">DeepSeekMoE的创新：细粒度专家分割与共享专家隔离</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%B2%92%E5%BA%A6%E4%B8%93%E5%AE%B6%E5%88%86%E5%89%B2"><span class="toc-number">1.14.8.1.</span> <span class="toc-text">粒度专家分割</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B1%E4%BA%AB%E4%B8%93%E5%AE%B6%E9%9A%94%E7%A6%BB"><span class="toc-number">1.14.8.2.</span> <span class="toc-text">共享专家隔离</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%B4%9F%E8%BD%BD%E5%B9%B3%E8%A1%A1%EF%BC%9A%E4%B8%93%E5%AE%B6%E7%BA%A7%E5%B9%B3%E8%A1%A1%E6%8D%9F%E5%A4%B1%E3%80%81%E8%AE%BE%E5%A4%87%E7%BA%A7%E5%B9%B3%E8%A1%A1%E6%8D%9F%E5%A4%B1"><span class="toc-number">1.14.8.3.</span> <span class="toc-text">负载平衡：专家级平衡损失、设备级平衡损失</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%B6%E4%BB%96"><span class="toc-number">1.15.</span> <span class="toc-text">其他</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%B2%BE%E5%BA%A6"><span class="toc-number">1.15.1.</span> <span class="toc-text">精度</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-FP16%EF%BC%88Half-Precision-Floating-Point%EF%BC%89"><span class="toc-number">1.15.1.1.</span> <span class="toc-text">1. FP16（Half-Precision Floating Point）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-BP16%EF%BC%88Bfloat16-Brain-Floating-Point%EF%BC%89"><span class="toc-number">1.15.1.2.</span> <span class="toc-text">2. BP16（Bfloat16, Brain Floating Point）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-FP16-vs-BP16-%E5%85%B3%E9%94%AE%E5%AF%B9%E6%AF%94"><span class="toc-number">1.15.1.3.</span> <span class="toc-text">3. FP16 vs BP16 关键对比</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-%E6%B7%B7%E5%90%88%E7%B2%BE%E5%BA%A6%E8%AE%AD%E7%BB%83%EF%BC%88Mixed-Precision-Training%EF%BC%89"><span class="toc-number">1.15.1.4.</span> <span class="toc-text">4. 混合精度训练（Mixed Precision Training）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-%E5%A6%82%E4%BD%95%E9%80%89%E6%8B%A9-FP16-%E5%92%8C-BP16%EF%BC%9F"><span class="toc-number">1.15.1.5.</span> <span class="toc-text">5. 如何选择 FP16 和 BP16？</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BE%AE%E8%B0%83%E5%90%8E%E6%A8%A1%E5%9E%8B%E5%87%BA%E7%8E%B0%E5%A4%8D%E8%AF%BB"><span class="toc-number">1.15.2.</span> <span class="toc-text">微调后模型出现复读</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#softmax"><span class="toc-number">1.15.3.</span> <span class="toc-text">softmax</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-%E6%B3%A8%E6%84%8F%E5%8A%9B%E5%88%86%E6%95%B0%E7%9A%84%E5%8E%9F%E5%A7%8B%E8%AE%A1%E7%AE%97"><span class="toc-number">1.15.3.1.</span> <span class="toc-text">1. 注意力分数的原始计算</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%AD%A3%E5%88%99%E5%8C%96"><span class="toc-number">1.15.4.</span> <span class="toc-text">正则化</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#L1-L2%E6%AD%A3%E5%88%99%E5%8C%96"><span class="toc-number">1.15.4.1.</span> <span class="toc-text">L1&#x2F;L2正则化</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E7%B1%BB%E4%B8%BA%E4%BB%80%E4%B9%88%E7%94%A8cse%E8%80%8C%E4%B8%8D%E6%98%AFmse"><span class="toc-number">1.15.5.</span> <span class="toc-text">分类为什么用cse而不是mse</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/posts/Graduate-Works/Works/Defects4J%E4%BD%BF%E7%94%A8%E6%89%8B%E5%86%8C/" title="Defects4J使用"><img src="/img/cover/57.jpg" onerror='this.onerror=null,this.src="/img/404.webp"' alt="Defects4J使用"></a><div class="content"><a class="title" href="/posts/Graduate-Works/Works/Defects4J%E4%BD%BF%E7%94%A8%E6%89%8B%E5%86%8C/" title="Defects4J使用">Defects4J使用</a><time datetime="2025-04-29T09:40:59.000Z" title="发表于 2025-04-29 17:40:59">2025-04-29</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/Graduate-Works/Works/LLM%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/" title="LLM基础知识整理"><img src="/img/cover/41.jpg" onerror='this.onerror=null,this.src="/img/404.webp"' alt="LLM基础知识整理"></a><div class="content"><a class="title" href="/posts/Graduate-Works/Works/LLM%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/" title="LLM基础知识整理">LLM基础知识整理</a><time datetime="2025-04-29T09:40:59.000Z" title="发表于 2025-04-29 17:40:59">2025-04-29</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/Graduate-Works/Paper-Read/%E8%AF%BBpaper20-%E5%9F%BA%E4%BA%8ELLM%E7%9A%84%E7%BC%BA%E9%99%B7%E4%BF%AE%E5%A4%8D6/" title="读paper20-基于LLM的缺陷修复6"><img src="/img/cover/6.jpg" onerror='this.onerror=null,this.src="/img/404.webp"' alt="读paper20-基于LLM的缺陷修复6"></a><div class="content"><a class="title" href="/posts/Graduate-Works/Paper-Read/%E8%AF%BBpaper20-%E5%9F%BA%E4%BA%8ELLM%E7%9A%84%E7%BC%BA%E9%99%B7%E4%BF%AE%E5%A4%8D6/" title="读paper20-基于LLM的缺陷修复6">读paper20-基于LLM的缺陷修复6</a><time datetime="2025-04-23T08:23:38.000Z" title="发表于 2025-04-23 16:23:38">2025-04-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/Graduate-Works/Paper-Read/%E8%AF%BBpaper19-%E5%9F%BA%E4%BA%8ELLM%E7%9A%84%E7%BC%BA%E9%99%B7%E4%BF%AE%E5%A4%8D5/" title="读paper19-基于LLM的缺陷修复5与总结"><img src="/img/cover/51.jpg" onerror='this.onerror=null,this.src="/img/404.webp"' alt="读paper19-基于LLM的缺陷修复5与总结"></a><div class="content"><a class="title" href="/posts/Graduate-Works/Paper-Read/%E8%AF%BBpaper19-%E5%9F%BA%E4%BA%8ELLM%E7%9A%84%E7%BC%BA%E9%99%B7%E4%BF%AE%E5%A4%8D5/" title="读paper19-基于LLM的缺陷修复5与总结">读paper19-基于LLM的缺陷修复5与总结</a><time datetime="2025-03-14T12:44:13.000Z" title="发表于 2025-03-14 20:44:13">2025-03-14</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/Graduate-Works/Paper-Read/%E8%AF%BBpaper18-Agent_for_code/" title="读paper18-Agent_for_code"><img src="/img/cover/43.jpg" onerror='this.onerror=null,this.src="/img/404.webp"' alt="读paper18-Agent_for_code"></a><div class="content"><a class="title" href="/posts/Graduate-Works/Paper-Read/%E8%AF%BBpaper18-Agent_for_code/" title="读paper18-Agent_for_code">读paper18-Agent_for_code</a><time datetime="2025-02-23T06:42:54.000Z" title="发表于 2025-02-23 14:42:54">2025-02-23</time></div></div></div></div></div></div></main><footer id="footer" style="background:0 0"></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">简</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span> 数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"></div></div><hr><div class="no-result" id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div><div class="js-pjax" id="rightMenu"><div class="rightMenu-group rightMenu-small"><a class="rightMenu-item" href="javascript:window.history.back();" rel="external nofollow noreferrer"><i class="fa fa-arrow-left"></i></a><a class="rightMenu-item" href="javascript:window.history.forward();" rel="external nofollow noreferrer"><i class="fa fa-arrow-right"></i></a><a class="rightMenu-item" href="javascript:window.location.reload();" rel="external nofollow noreferrer"><i class="fa fa-refresh"></i></a><a class="rightMenu-item" href="javascript:rmf.scrollToTop();" rel="external nofollow noreferrer"><i class="fa fa-arrow-up"></i></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-text"><a class="rightMenu-item" href="javascript:rmf.copySelect();" rel="external nofollow noreferrer"><i class="fa fa-copy"></i><span>复制</span></a><a class="rightMenu-item" href="javascript:window.open(&quot;https://www.google.com/search?q=&quot;+window.getSelection().toString());" rel="external nofollow noreferrer"><i class="iconfont icon-baidu"></i><span>搜索</span></a><a class="rightMenu-item" href="javascript:rmf.searchinThisPage();" rel="external nofollow noreferrer"><i class="fas fa-search"></i><span>站内搜索</span></a><a class="rightMenu-item" href="#post-comment" onclick="rmf.yinyong()"><i class="fa-solid fa-message"></i><span>引用文本评论</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-too"><a class="rightMenu-item" href="javascript:window.open(window.getSelection().toString());window.location.reload();" rel="external nofollow noreferrer"><i class="fa fa-link"></i><span>转到链接</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-paste"><a class="rightMenu-item" href="javascript:rmf.paste()" rel="external nofollow noreferrer"><i class="fa fa-copy"></i><span>粘贴</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-to"><a class="rightMenu-item" href="javascript:rmf.openWithNewTab()" rel="external nofollow noreferrer"><i class="fa fa-window-restore"></i><span>新窗口打开</span></a><a class="rightMenu-item" id="menu-too" href="javascript:rmf.open()" rel="external nofollow noreferrer"><i class="fa fa-link"></i><span>转到链接</span></a><a class="rightMenu-item" href="javascript:rmf.copyLink()" rel="external nofollow noreferrer"><i class="fa fa-copy"></i><span>复制链接</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-img"><a class="rightMenu-item" href="javascript:rmf.saveAs()" rel="external nofollow noreferrer"><i class="fa fa-download"></i><span>保存图片</span></a><a class="rightMenu-item" href="javascript:rmf.openWithNewTab()" rel="external nofollow noreferrer"><i class="fa fa-window-restore"></i><span>在新窗口打开</span></a><a class="rightMenu-item" href="javascript:rmf.click()" rel="external nofollow noreferrer"><i class="fa fa-arrows-alt"></i><span>全屏显示</span></a><a class="rightMenu-item" href="javascript:rmf.copyLink()" rel="external nofollow noreferrer"><i class="fa fa-copy"></i><span>复制图片链接</span></a></div><div class="rightMenu-group rightMenu-line"><a class="rightMenu-item" href="javascript:rmf.switchDarkMode();" rel="external nofollow noreferrer"><i class="fa fa-moon"></i><span>昼夜切换</span></a><a class="rightMenu-item" href="javascript:rmf.translate();" rel="external nofollow noreferrer"><i class="iconfont icon-fanti"></i><span>繁简转换</span></a><a class="rightMenu-item" href="javascript:rmf.switchReadMode();" rel="external nofollow noreferrer"><i class="fa fa-book"></i><span>阅读模式</span></a><a class="rightMenu-item" href="javascript:fullScreen();" rel="external nofollow noreferrer"><i class="fas fa-expand"></i><span>进入全屏</span></a></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://unpkg.com/@fancyapps/ui/dist/fancybox/fancybox.umd.js"></script><script>function panguFn(){"object"==typeof pangu?pangu.autoSpacingPage():getScript("https://unpkg.com/pangu/dist/browser/pangu.min.js").then(()=>{pangu.autoSpacingPage()})}function panguInit(){GLOBAL_CONFIG_SITE.isPost&&panguFn()}document.addEventListener("DOMContentLoaded",panguInit)</script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://unpkg.com/katex/dist/katex.min.css"><script src="https://unpkg.com/katex/dist/contrib/copy-tex.min.js"></script><script>document.querySelectorAll("#article-container span.katex-display").forEach(a=>{btf.wrap(a,"div",{class:"katex-wrap"})})</script><script>function getGiscusTheme(e){return"dark"===e?"dark":"light"}function loadGiscus(){var e,t=Object.assign({src:"https://giscus.app/client.js","data-repo":"ZWN2001/ZWN2001.github.io","data-repo-id":"R_kgDOGH1XWg","data-category-id":"DIC_kwDOGH1XWs4CXnHJ","data-mapping":"pathname","data-theme":getGiscusTheme(document.documentElement.getAttribute("data-theme")),"data-reactions-enabled":"1",crossorigin:"anonymous",async:!0},{"data-lang":"zh-CN","data-loading":"lazy",crossorigin:"anonymous","data-mapping":"og:title","data-input-position":"top","data-category":"Announcements"}),a=document.createElement("script");for(e in t)a.setAttribute(e,t[e]);document.getElementById("giscus-wrap").insertAdjacentElement("afterbegin",a)}function changeGiscusTheme(e){var t;e={setConfig:{theme:getGiscusTheme(e)}},(t=document.querySelector("iframe.giscus-frame"))&&t.contentWindow.postMessage({giscus:e},"https://giscus.app")}function loadOtherComment(){loadGiscus()}btf.addModeChange("giscus",changeGiscusTheme),btf.loadComment(document.getElementById("giscus-wrap"),loadGiscus)</script></div><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.7.1/jquery.min.js"></script><script type="text/javascript" src="/js/rightmenu.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span> 数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"></div></div><hr><div class="no-result" id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div><script data-pjax>var parent,child;document.getElementById("recent-posts")&&"/"===location.pathname&&(parent=document.getElementById("recent-posts"),child='<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="https://zwn2001.space/categories/编程知识/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📚 琉璃月の编程知识 (13)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://zwn2001.space/categories/实用知识/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">💡 琉璃月の实用知识 (10)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://zwn2001.space/categories/学习-课外拓展/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">👩‍💻 琉璃月の学习-课外拓展 (39)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://zwn2001.space/categories/学习-课内知识/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📒 琉璃月の学习-课内知识 (59)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><a class="magnet_link_more"  href="https://zwn2001.space/categories" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>',console.log("已挂载magnet"),parent.insertAdjacentHTML("afterbegin",child))</script><style>#catalog_magnet{flex-wrap:wrap;display:flex;width:100%;justify-content:space-between;padding:10px 10px 0 10px;align-content:flex-start}.magnet_item{flex-basis:calc(50% - 5px);background:#f2f2f2;margin-bottom:10px;border-radius:8px;transition:all .2s ease-in-out}.magnet_item:hover{background:#b30070}.magnet_link_more{color:#555}.magnet_link{color:#000}.magnet_link:hover{color:#fff}@media screen and (max-width:600px){.magnet_item{flex-basis:100%}}.magnet_link_context{display:flex;padding:10px;font-size:16px;transition:all .2s ease-in-out}.magnet_link_context:hover{padding:10px 20px}</style><style></style></body></html>