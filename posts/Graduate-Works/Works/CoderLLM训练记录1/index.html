<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover"><title>CoderLLM训练记录 | ZWN's blog</title><meta name="author" content="琉璃月"><meta name="copyright" content="琉璃月"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="CoderLLM训练记录 torchrun的时候执行rsync命令会导致NCCL通信超时，rsync 大文件传输会吃满节点间网络带宽，导致 NCCL 通信包排队等待。但是先rsync再torchrun就没事，有趣。 预训练-Dense 首先基于已有的chat-LLM的代码进行了训练，使用了 miniMind 的Dense模型代码，架构上来讲也是比较经典易懂的Decoder-Only结构，使用CLM"><meta property="og:type" content="article"><meta property="og:title" content="CoderLLM训练记录"><meta property="og:url" content="https://zwn2001.space/posts/Graduate-Works/Works/CoderLLM%E8%AE%AD%E7%BB%83%E8%AE%B0%E5%BD%951/index.html"><meta property="og:site_name" content="ZWN&#39;s blog"><meta property="og:description" content="CoderLLM训练记录 torchrun的时候执行rsync命令会导致NCCL通信超时，rsync 大文件传输会吃满节点间网络带宽，导致 NCCL 通信包排队等待。但是先rsync再torchrun就没事，有趣。 预训练-Dense 首先基于已有的chat-LLM的代码进行了训练，使用了 miniMind 的Dense模型代码，架构上来讲也是比较经典易懂的Decoder-Only结构，使用CLM"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://zwn2001.space/img/cover/58.jpg"><meta property="article:published_time" content="2025-06-15T12:11:50.000Z"><meta property="article:modified_time" content="2025-08-24T05:32:48.593Z"><meta property="article:author" content="琉璃月"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://zwn2001.space/img/cover/58.jpg"><link rel="shortcut icon" href="/img/favicon.webp"><link rel="canonical" href="https://zwn2001.space/posts/Graduate-Works/Works/CoderLLM%E8%AE%AD%E7%BB%83%E8%AE%B0%E5%BD%951/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://unpkg.com/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://unpkg.com/@fancyapps/ui/dist/fancybox/fancybox.css" media="print" onload='this.media="all"'><script>const GLOBAL_CONFIG={root:"/",algolia:void 0,localSearch:{path:"/search.xml",preload:!0,top_n_per_article:-1,unescape:!1,languages:{hits_empty:"找不到您查询的内容：${query}",hits_stats:"共找到 ${hits} 篇文章"}},translate:{defaultEncoding:2,translateDelay:0,msgToTraditionalChinese:"繁",msgToSimplifiedChinese:"简"},noticeOutdate:{limitDay:200,position:"top",messagePrev:"距离上次更新已经过去",messageNext:"天啦！注意内容可能过时。"},highlight:{plugin:"highlighjs",highlightCopy:!0,highlightLang:!0,highlightHeightLimit:300},copy:{success:"复制成功",error:"复制错误",noSupport:"浏览器不支持"},relativeDate:{homepage:!1,post:!1},runtime:"天",dateSuffix:{just:"刚刚",min:"分钟前",hour:"小时前",day:"天前",month:"个月前"},copyright:void 0,lightbox:"fancybox",Snackbar:void 0,source:{justifiedGallery:{js:"https://unpkg.com/flickr-justified-gallery/dist/fjGallery.min.js",css:"https://unpkg.com/flickr-justified-gallery/dist/fjGallery.css"}},isPhotoFigcaption:!0,islazyload:!1,isAnchor:!0,percent:{toc:!0,rightside:!0},autoDarkmode:!1}</script><script id="config-diff">var GLOBAL_CONFIG_SITE={title:"CoderLLM训练记录",isPost:!0,isHome:!1,isHighlightShrink:!1,isToc:!0,postUpdate:"2025-08-24 13:32:48"}</script><noscript><style type="text/css">#nav{opacity:1}.justified-gallery img{opacity:1}#post-meta time,#recent-posts time{display:inline!important}</style></noscript><script>(e=>{e.saveToLocal={set:function(e,t,a){0!==a&&(a=864e5*a,t={value:t,expiry:(new Date).getTime()+a},localStorage.setItem(e,JSON.stringify(t)))},get:function(e){var t=localStorage.getItem(e);if(t){t=JSON.parse(t);if(!((new Date).getTime()>t.expiry))return t.value;localStorage.removeItem(e)}}},e.getScript=o=>new Promise((t,e)=>{const a=document.createElement("script");a.src=o,a.async=!0,a.onerror=e,a.onload=a.onreadystatechange=function(){var e=this.readyState;e&&"loaded"!==e&&"complete"!==e||(a.onload=a.onreadystatechange=null,t())},document.head.appendChild(a)}),e.getCSS=(o,n=!1)=>new Promise((t,e)=>{const a=document.createElement("link");a.rel="stylesheet",a.href=o,n&&(a.id=n),a.onerror=e,a.onload=a.onreadystatechange=function(){var e=this.readyState;e&&"loaded"!==e&&"complete"!==e||(a.onload=a.onreadystatechange=null,t())},document.head.appendChild(a)}),e.activateDarkMode=function(){document.documentElement.setAttribute("data-theme","dark"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#0d0d0d")},e.activateLightMode=function(){document.documentElement.setAttribute("data-theme","light"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","ffffff")};e=saveToLocal.get("theme"),"dark"===e?activateDarkMode():"light"===e&&activateLightMode(),e=saveToLocal.get("aside-status");void 0!==e&&("hide"===e?document.documentElement.classList.add("hide-aside"):document.documentElement.classList.remove("hide-aside"));/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)&&document.documentElement.classList.add("apple")})(window)</script><link rel="stylesheet" href="/css/transpancy.css"><link rel="stylesheet" href="/css/iconfont.css"><link rel="stylesheet" href="/css/rightmenu.css"><link rel="stylesheet" href="/css/loadimg.css"><link rel="stylesheet" href="/css/project.css"><link type="text/html" rel="stylesheet" href="/css/wide_screen.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-double-row-display@1.00/cardlistpost.min.css"><style>#recent-posts>.recent-post-item>.recent-post-info>.article-meta-wrap>.tags:before{content:"\A";white-space:pre}#recent-posts>.recent-post-item>.recent-post-info>.article-meta-wrap>.tags>.article-meta__separator{display:none}</style><meta name="generator" content="Hexo 5.4.0"></head><body><div id="loading-box" onclick="document.getElementById(&quot;loading-box&quot;).classList.add(&quot;loaded&quot;)"><div class="loading-bg"><img class="loading-img nolazyload" src="/img/favicon.webp"><div class="loading-image-dot"></div><div id="loading-percentage"></div></div></div><script>const loadingPercentage=document.getElementById("loading-percentage");loadingPercentage.style.color="black";let loadingPercentageTimer=setInterval(function(){var e=document.querySelector(".pace-progress");e&&(e=e.getAttribute("data-progress-text"))!==loadingPercentage.textContent&&"60%"===(loadingPercentage.textContent=e)&&clearInterval(loadingPercentageTimer)},100);const preloader={endLoading:()=>{document.body.style.overflow="auto",document.getElementById("loading-box").classList.add("loaded")},initLoading:()=>{document.body.style.overflow="",document.getElementById("loading-box").classList.remove("loaded")}};window.addEventListener("load",()=>{preloader.endLoading()})</script><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/favicon.webp" onerror='onerror=null,src="/img/friend_404.gif"' alt="avatar"></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">176</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">52</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">8</div></a></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image:url(/img/cover/58.jpg)"><nav id="nav"><span id="blog-info"><a href="/" title="ZWN's blog"><span class="site-name">ZWN's blog</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);" rel="external nofollow noreferrer"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);" rel="external nofollow noreferrer"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">CoderLLM训练记录</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-06-15T12:11:50.000Z" title="发表于 2025-06-15 20:11:50">2025-06-15</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-08-24T05:32:48.593Z" title="更新于 2025-08-24 13:32:48">2025-08-24</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">8.7k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>33分钟</span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1>CoderLLM训练记录</h1><p>torchrun的时候执行rsync命令会导致NCCL通信超时，rsync 大文件传输会吃满节点间网络带宽，导致 NCCL 通信包排队等待。但是先rsync再torchrun就没事，有趣。</p><h2 id="预训练-Dense">预训练-Dense</h2><p>首先基于已有的chat-LLM的代码进行了训练，使用了 <a target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/jingyaogong/minimind">miniMind</a> 的Dense模型代码，架构上来讲也是比较经典易懂的Decoder-Only结构，使用CLM任务训练，原模型在成熟的对话数据集下训练效果也不错。具体架构如下：</p><img src="LLM-structure.png" alt="structure" style="zoom:51%"><h3 id="一个低级但又不太低级的错误">一个低级但又不太低级的错误</h3><p>数据集选用的是hf上的 ZhentingNLP/code_pretraining_data 这个数据集，一共16G数据，但后来数据集就被作者删了。</p><p>训练任务的选择上，上来就犯了个低级错误。某天跟Qwen聊天，Qwen让我试一试加入MLM，我感觉不太对劲，转头问了问Deepseek，Deepseek也认可，于是我也没多想，只是觉得有道理，就在原有的CLM基础上，使用了15%的MLM，剩余的85%仍然是CLM，但训练结果并不理想，但是看loss似乎并没有什么问题，于是只用CLM进行训练，发现效果竟然比MLM+CLM要好。</p><p>其实这属于经典的想当然的低级问题，因为MLM本就是用于编码-解码架构的模型，没听说过哪个解码模型用MLM训练，但具体是为什么呢，其实思考一下答案也很简单，我们还是回到模型本身上来。</p><p>简言之，根本原因在于<strong>Decoder-Only架构的模型与MLM任务存在根本性不匹配</strong>。MLM需要双向上下文，目标是预测被掩码的token，但必须基于<strong>完整的前后上下文</strong>，这要求模型使用非因果注意力机制，允许每个token访问序列中所有其他token。但Decoder-Only架构模型强制使用因果掩码，模型在设计上是自回归的，注意力机制通过因果掩码确保每个token只能看到左侧历史信息，不能访问右侧未来信息。</p><p>这其实就导致模型无法访问被掩码位置的右侧上下文（因为因果掩码阻止了向后看），所以，MLM任务退化为一个<strong>单向预测任务</strong>（仅基于左侧上下文），这也就导致模型在MLM任务中学习到的表示是<strong>有偏的</strong>，因为它被迫用单向上下文解决一个需要双向上下文的任务。</p><p>所以这也就解释了为什么混合训练时模型的Loss波动要剧烈，而且Log中的MLM的loss一直相对较高：</p><img src="W&B 6月训练结果.png" alt="Loss CLM&MLM" style="zoom:25%"> <img src="W&B 8月训练结果.png" alt="Loss CLM" style="zoom:25%"><p>但实际上Coder LLM的训练中是有过类似任务的，DeepSeek Coder 的技术报告中就提到过类似的任务，只不过并非MLM：</p><blockquote><p>由于编程语言中的特定依赖性，仅根据上文预测下文是不够的，典型的常见如代码补全，需要基于给定<strong>上文和后续文本生成相应插入代码</strong>。因此我们沿用前人提出的提出了<strong>FIM</strong>（Fill-in-the-Middle）方法，即：填补中间代码的预训练方法。</p><p>这种方法涉及<strong>将文本随机分成三部分（Prefix、Middle、Suffix），然后将Prefix和Suffix顺序打乱来预测Middle</strong>。具体来说，我们采用了两种不同新的数据拼接模式：PSM（Prefix-Suffix-Middle）和SPM（Suffix-Prefix-Middle）。这两种模式对于增强模型处理代码中各种结构排列的能力非常重要。考虑到尽量保持自然序列关系，最终我们选择了PSM模式。</p><img src="v2-c53531daa20218174228b1209bddd4fb_1440w.jpg" style="zoom:100%"><p>上图设计了消融实验对比FIM数据占比对训练的影响，发现<strong>FIM数据50%占比（红色）能更好兼顾代码生成</strong>（HumanEval、MBPP）<strong>和代码补全</strong>（HumanFIM）类任务。</p></blockquote><p>这与MLM虽然看起来很像，但还是有很大区别的，从目标上来讲，我们需要预测被挖掉的中间部分 (<code>middle</code>)，但<strong>关键前提是模型已经被显式提供了 <code>suffix</code>（右侧上下文）作为输入的一部分</strong>。</p><p>从机制上来说，原始序列 <code>[prefix][middle][suffix]</code> 被重组为 <code>[&lt;FIM_PREFIX&gt;][prefix][&lt;FIM_SUFFIX&gt;][suffix][&lt;FIM_MIDDLE&gt;][?]</code>，模型在生成 <code>middle</code> 的每一个 token 时，它的输入序列中<strong>已经包含了完整的 <code>prefix</code> 和完整的 <code>suffix</code></strong>，并且它们位于当前生成位置 (<code>&lt;FIM_MIDDLE&gt;</code> 之后) 的<strong>左侧</strong>。当模型开始预测 <code>&lt;FIM_MIDDLE&gt;</code> 之后的第一个 token (即 <code>middle</code> 的开始) 时，都能访问到完整的 <code>prefix</code> (左侧原始上下文) 和完整的 <code>suffix</code> (右侧原始上下文)。简言之，FIM <strong>巧妙地利用序列重组和特殊标记，将原本在“未来”的 <code>suffix</code> 信息移动到了需要预测的 <code>middle</code> 的“过去”</strong>。</p><p>后来我又想了想，为啥大模型会犯这种错误呢，我也没太理解，而且Deepseek信誓旦旦的告诉我Deepseek使用MLM+CLM提升了性能。直到我打开了Deepseek的联网搜索，看了一眼搜索结果，发现这个混合任务指向的其实是Deepseek引入的MTP。只能说模型有幻觉，采纳需谨慎。</p><hr><p>但除此之外还存在一些问题，我觉得最大的问题在于Tokenizer，训练时我直接使用了原有的词表，但觉得针对对话数据训练的词表直接用于代码任务并不是非常合适。所以我考虑了如下两个方案：</p><ul><li>直接用Qwen-Coder 3 的词表</li><li>自己训练。</li></ul><p>现有词表长度为6400，使得LLM总参数量只有25.8M，如果直接用Qwen-Coder 3 的词表，长度变为151643，会使得词嵌入embedding层参数在LLM占比太高，而且更大的词表需要更多样本来充分训练所有token，显然我也没有这么多算力，最终也与我训练小模型的目标相悖，所以最终还是没有考虑。</p><blockquote><p>在这期间我也学习了一些相关的知识，老实说以前是不怎么关心词表的，只是了解了一些分词算法什么的就草草略过了，现在看来非常可笑。</p></blockquote><h3 id="基于-CodeSearchNet-数据集的预训练">基于 CodeSearchNet 数据集的预训练</h3><h4 id="直接训练">直接训练</h4><p>换用了CodeSearchNet中的java和python部分进行预训练，首先直接使用原数据集进行训练，输入文本构造为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">f&quot;<span class="subst">&#123;self.tokenizer.bos_token&#125;</span><span class="subst">&#123;sample[<span class="string">&#x27;docstring&#x27;</span>]&#125;</span>\n```<span class="subst">&#123;sample[<span class="string">&#x27;language&#x27;</span>]&#125;</span>\n<span class="subst">&#123;sample[<span class="string">&#x27;function&#x27;</span>]&#125;</span>\n```<span class="subst">&#123;self.tokenizer.eos_token&#125;</span>&quot;</span></span><br></pre></td></tr></table></figure><p>同时调整了超参数：</p><ul><li><p>调整Transformer层数，由8调整为6，这主要是目前训练数据量很小很小，只有1G（但是后来觉得这个改动不是很妥当，为了训练速度牺牲了效果）</p></li><li><p>调整学习率，5e-4调整为7e-4，这主要为了对应梯度累积步数与预热的调整</p></li><li><p>调整最大序列长度，由512调整为1024</p></li><li><p>调整梯度裁剪阈值，由1调整为1.2，提升收敛速度</p></li><li><p>调整学习率预热，由0调整为1000</p></li><li><p>调整梯度累积步数，由8调整为16，提升收敛稳定性</p></li></ul><img src="W&B Chart1.png" style="zoom:25%"> <img src="W&B Chart2.png" style="zoom:25%"><p>测试了一下结果并不是很好</p><h4 id="数据集优化后的训练">数据集优化后的训练</h4><p>使用上面数据构造后，过滤掉了长度大于1024 的数据，并将短数据进行了拼接（拼接后长度不超过1024）</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">============================================================</span><br><span class="line">SUMMARY</span><br><span class="line">============================================================</span><br><span class="line">Original samples: 1,156,085</span><br><span class="line">Samples after filtering (≤1024 chars): 860,887</span><br><span class="line">Removed samples (&gt;1024 chars): 295,198</span><br><span class="line">Final concatenated samples: 484,856</span><br><span class="line">Data reduction ratio: 41.94%</span><br></pre></td></tr></table></figure><p>训练了24个epoch，第9个epoch触发了早停，测试了一下，学到了一些语法，比之前训练好一些，不过HumanEval测试就很难pass了，top3都是0%：</p><p>![](W&amp;B Chart3.png)</p><img src="W&B Chart4.png" style="zoom:25%"><h3 id="FIM">FIM</h3><p>介绍部分摘自https://zhuanlan.zhihu.com/p/3217226274。参考OpenAI的《Efficient Training of Language Models to Fill in the Middle》来介绍一下。</p><h4 id="FIM效果">FIM效果</h4><p>为了让模型同时具备正常的从左到右的生成能力，需要使用left-to-right和FIM两个方式混合的数据，FIM数据的比例成为FIM rate。</p><p>在实际训练模型中，OpenAI使用FIM rate = 0.5，即训练数据中一半进行了这种切分和转换，另一半保持正常的从左到右顺序。</p><p>实验中发现，混入FIM数据之后，模型在正常left-to-right的能力上基本上没有收到任何损害，如下图</p><img src="v2-cc7644a4e5e6bb8b8cc2205cd79bf61f_1440w.jpg" style="zoom:50%"><p>相当于模型没有付出任何代价就多学到了FIM的能力，OpenAI称之为FIM-for-free property。</p><p>通常的PPL测试不能看出FIM带来的收益，为了评测模型FIM，OpenAI专门构建一个infilling benchmark。infilling benchmark中的数据来源于HumanEval，通过删除中间的部分代码，要求模型补全来检验FIM能力。</p><p>有无使用FIM数据的模型，在FIM测试上的对比如下：</p><img src="v2-a0c13b308f8454c3d1d86d0814c4adc6_1440w.jpg" style="zoom:50%"><p>加入FIM明显地提升模型的infilling能力。</p><h4 id="训练">训练</h4><p>训练的时候，不止有middle部分的loss会bp，prefix和suffix也和left-to-right的数据一样会进行训练，这样FIM相比left-to-right并不会损失loss信号的量。</p><p>前面这种拼接方式，数据的顺序是Prefix、Suffix、Middle，简称为PSM。PSM是最符合直觉的一种拼接方式。而除了PSM，还可以使用SPM的拼接顺序。文中提到，SPM相比PSM有一个好处，那就是在推理的时候前面已经计算过的KV cache可以复用。（不过这里感觉有点奇怪，只要不把新生成的token拼接到Prefix部分，其实PSM的KV cache也是可以服用的）</p><p>那么PSM和SPM的效果如何？实验了SPM、PSM和二者一起训练，效果如下：</p><img src="v2-26ded05d13c3ff99d0c2bec98fe5cbd0_1440w.jpg" style="zoom:50%"><p>从结果上看，二者都用的效果是最好的。</p><h4 id="FIM-rate">FIM rate</h4><p>FIM rate应该设置为多少合适？文中做了消融实验，对比FIM rate = (0, 0.25, 0.5, 0.75, 0.9, 1.0)的效果。结果如下：</p><img src="v2-de7a85ba14db7c09f405f3a690781fd9_1440w.jpg" style="zoom:50%"><p>不同的FIM rate对left-to-right几乎没有什么影响（除了FIM rate = 1.0），而FIM loss则是只要使用FIM数据，就有明显提升。FIM rate = 0.5和0.9的效果差不多，最终使用的是0.5。</p><h4 id="数据切分">数据切分</h4><p>前面说了数据要被切成三部分，那么具体怎么切？论文提供了三种粒度的对比，Line-level random span、Token-level random span、Character-level random span。三种粒度的切分都保证prefix、suffix、middle的期望长度都是总长度的1/3。结果如下：</p><img src="v2-4027d1c1f7d14a469eac14040b252ddb_1440w.jpg" style="zoom:50%"><p>character level的整体效果最好。</p><h4 id="训练结果">训练结果</h4><p>这里依然使用了前面拼接后的数据集，将其中的部分数据替换为了FIM，不过这样带来的一个问题就是，FIM会有新的标记填充，可能导致单个序列长度超过1024（可能导致触发<code>CUDA error: device-side assert triggered</code>，虽然这个报错的触发原因很多），所以额外加了FIM任务数量上限，即代码中的如下部分：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 保证拼接后的长度不超过max_length</span></span><br><span class="line">available_length = self.max_length - fim_token_length</span><br><span class="line">max_fim_number = available_length // fim_token_length</span><br><span class="line"></span><br><span class="line"><span class="comment"># 至少保留一个content不变</span></span><br><span class="line">max_fim_contents = <span class="built_in">max</span>(<span class="number">1</span>, <span class="built_in">min</span>(<span class="number">2</span>, num_contents // <span class="number">2</span>))</span><br><span class="line">max_fim_contents = <span class="built_in">min</span>(max_fim_contents, max_fim_number)</span><br><span class="line">num_fim_contents = random.randint(<span class="number">1</span>, max_fim_contents)</span><br></pre></td></tr></table></figure><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">FIMPretrainDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, data_path, tokenizer, max_length=<span class="number">1024</span>, fim_ratio=<span class="number">0.5</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.tokenizer = tokenizer</span><br><span class="line">        self.max_length = max_length</span><br><span class="line">        self.fim_ratio = fim_ratio  <span class="comment"># FIM任务的比例</span></span><br><span class="line">        self.samples = self.load_data(data_path)</span><br><span class="line">          <span class="comment"># 确保FIM特殊标记在tokenizer词汇表中</span></span><br><span class="line">        self._add_fim_tokens()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_add_fim_tokens</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;添加FIM特殊标记到tokenizer中&quot;&quot;&quot;</span></span><br><span class="line">        special_tokens = [FIM_PREFIX, FIM_MIDDLE, FIM_SUFFIX]</span><br><span class="line">        new_tokens = []</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> token <span class="keyword">in</span> special_tokens:</span><br><span class="line">            <span class="keyword">if</span> token <span class="keyword">not</span> <span class="keyword">in</span> self.tokenizer.get_vocab():</span><br><span class="line">                new_tokens.append(token)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> new_tokens:</span><br><span class="line">            self.tokenizer.add_tokens(new_tokens)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Added FIM tokens to tokenizer: <span class="subst">&#123;new_tokens&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_parse_concatenated_text</span>(<span class="params">self, text</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;解析拼接的文本，返回各个content段落的列表&quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># 使用正则表达式匹配 &lt;s&gt;content&lt;/s&gt; 格式</span></span><br><span class="line">        pattern = <span class="string">r&#x27;&lt;s&gt;(.*?)&lt;/s&gt;&#x27;</span></span><br><span class="line">        matches = re.findall(pattern, text, re.DOTALL)</span><br><span class="line">        <span class="keyword">return</span> matches</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_apply_fim_to_content</span>(<span class="params">self, content</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;对单个content应用FIM变换&quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># 将content编码为tokens来更精确地控制分割点</span></span><br><span class="line">        tokens = self.tokenizer.encode(content, add_special_tokens=<span class="literal">False</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(tokens) &lt; <span class="number">40</span>:  <span class="comment"># 文本太短，不适合FIM</span></span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 随机选择分割点</span></span><br><span class="line">        <span class="comment"># prefix: 10%-60%, middle: 10%-60%, suffix: 10%-60%</span></span><br><span class="line">        total_len = <span class="built_in">len</span>(tokens)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 确保每部分至少有一些内容</span></span><br><span class="line">        min_part_len = <span class="built_in">max</span>(<span class="number">1</span>, total_len // <span class="number">10</span>)</span><br><span class="line">        max_prefix_len = <span class="built_in">max</span>(min_part_len, <span class="built_in">int</span>(total_len * <span class="number">0.6</span>))</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 随机选择prefix长度</span></span><br><span class="line">        prefix_len = random.randint(min_part_len, max_prefix_len)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 为middle和suffix留出空间</span></span><br><span class="line">        remaining_len = total_len - prefix_len</span><br><span class="line">        <span class="keyword">if</span> remaining_len &lt; <span class="number">2</span> * min_part_len:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        </span><br><span class="line">        max_middle_len = <span class="built_in">max</span>(min_part_len, remaining_len - min_part_len)</span><br><span class="line">        middle_len = random.randint(min_part_len, max_middle_len)</span><br><span class="line">        </span><br><span class="line">        suffix_start = prefix_len + middle_len</span><br><span class="line">        <span class="keyword">if</span> suffix_start &gt;= total_len:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 分割tokens</span></span><br><span class="line">        prefix_tokens = tokens[:prefix_len]</span><br><span class="line">        middle_tokens = tokens[prefix_len:suffix_start]</span><br><span class="line">        suffix_tokens = tokens[suffix_start:]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 解码回文本</span></span><br><span class="line">        prefix = self.tokenizer.decode(prefix_tokens, skip_special_tokens=<span class="literal">True</span>)</span><br><span class="line">        middle = self.tokenizer.decode(middle_tokens, skip_special_tokens=<span class="literal">True</span>)</span><br><span class="line">        suffix = self.tokenizer.decode(suffix_tokens, skip_special_tokens=<span class="literal">True</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 创建FIM格式的序列: [&lt;FIM_PREFIX&gt;][prefix][&lt;FIM_SUFFIX&gt;][suffix][&lt;FIM_MIDDLE&gt;][middle]</span></span><br><span class="line">        fim_content = <span class="string">f&quot;<span class="subst">&#123;FIM_PREFIX&#125;</span><span class="subst">&#123;prefix&#125;</span><span class="subst">&#123;FIM_SUFFIX&#125;</span><span class="subst">&#123;suffix&#125;</span><span class="subst">&#123;FIM_MIDDLE&#125;</span><span class="subst">&#123;middle&#125;</span>&quot;</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> fim_content</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_create_mixed_sequence</span>(<span class="params">self, original_text</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;创建混合了FIM和CLM的序列&quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># 解析拼接的文本</span></span><br><span class="line">        contents = self._parse_concatenated_text(original_text)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> contents:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 随机选择一些content进行FIM变换</span></span><br><span class="line">        num_contents = <span class="built_in">len</span>(contents)</span><br><span class="line"></span><br><span class="line">        fim_token_length = <span class="built_in">len</span>(FIM_PREFIX) + <span class="built_in">len</span>(FIM_SUFFIX) + <span class="built_in">len</span>(FIM_MIDDLE)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 保证拼接后的长度不超过max_length</span></span><br><span class="line">        available_length = self.max_length - fim_token_length</span><br><span class="line">        max_fim_number = available_length // fim_token_length</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 至少保留一个content不变</span></span><br><span class="line">        max_fim_contents = <span class="built_in">max</span>(<span class="number">1</span>, <span class="built_in">min</span>(<span class="number">2</span>, num_contents // <span class="number">2</span>))</span><br><span class="line">        max_fim_contents = <span class="built_in">min</span>(max_fim_contents, max_fim_number)</span><br><span class="line">        num_fim_contents = random.randint(<span class="number">1</span>, max_fim_contents)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 随机选择要进行FIM变换的content索引</span></span><br><span class="line">        fim_indices = random.sample(<span class="built_in">range</span>(num_contents), num_fim_contents)</span><br><span class="line">          <span class="comment"># 构建新的sequence</span></span><br><span class="line">        new_contents = []</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i, content <span class="keyword">in</span> <span class="built_in">enumerate</span>(contents):</span><br><span class="line">            <span class="keyword">if</span> i <span class="keyword">in</span> fim_indices:</span><br><span class="line">                <span class="comment"># 应用FIM变换</span></span><br><span class="line">                fim_content = self._apply_fim_to_content(content)</span><br><span class="line">                <span class="keyword">if</span> fim_content <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                    new_contents.append(<span class="string">f&quot;&lt;s&gt;<span class="subst">&#123;fim_content&#125;</span>&lt;/s&gt;&quot;</span>)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    new_contents.append(<span class="string">f&quot;&lt;s&gt;<span class="subst">&#123;content&#125;</span>&lt;/s&gt;&quot;</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                new_contents.append(<span class="string">f&quot;&lt;s&gt;<span class="subst">&#123;content&#125;</span>&lt;/s&gt;&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;&#x27;</span>.join(new_contents)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">load_data</span>(<span class="params">self, path</span>):</span><br><span class="line">        files = [<span class="string">&#x27;python_all_concatenated.jsonl&#x27;</span>] <span class="comment"># ,&#x27;java_all.jsonl&#x27;</span></span><br><span class="line">        samples = []</span><br><span class="line">        data_dir = path <span class="keyword">if</span> os.path.isdir(path) <span class="keyword">else</span> os.path.dirname(path)</span><br><span class="line">        <span class="keyword">for</span> file <span class="keyword">in</span> files:</span><br><span class="line">            file_path = os.path.join(data_dir, file)</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(file_path):</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">                </span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                <span class="keyword">with</span> <span class="built_in">open</span>(file_path, <span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">                    <span class="keyword">for</span> line_num, line <span class="keyword">in</span> <span class="built_in">enumerate</span>(f, <span class="number">1</span>):</span><br><span class="line">                        data = json.loads(line.strip())</span><br><span class="line">                        samples.append(data)</span><br><span class="line">            <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">                </span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> samples:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">f&quot;No valid data found in <span class="subst">&#123;data_dir&#125;</span>&quot;</span>)</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">return</span> samples</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.samples)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">        sample = self.samples[index]</span><br><span class="line">        original_text = sample[<span class="string">&#x27;text&#x27;</span>]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 随机决定使用CLM还是FIM任务</span></span><br><span class="line">        use_fim = random.random() &lt; self.fim_ratio</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> use_fim:</span><br><span class="line">            mixed_text = self._create_mixed_sequence(original_text)</span><br><span class="line">            <span class="keyword">if</span> mixed_text <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                text = mixed_text</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                text = original_text</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            text = original_text</span><br><span class="line">            </span><br><span class="line">        encoding = self.tokenizer(</span><br><span class="line">            text,</span><br><span class="line">            max_length=self.max_length,</span><br><span class="line">            padding=<span class="string">&#x27;max_length&#x27;</span>,</span><br><span class="line">            truncation=<span class="literal">True</span>,</span><br><span class="line">            return_tensors=<span class="string">&#x27;pt&#x27;</span></span><br><span class="line">        )</span><br><span class="line">        input_ids = encoding.input_ids.squeeze()</span><br><span class="line">        <span class="comment"># 所有非padding token都参与损失计算</span></span><br><span class="line">        loss_mask = (input_ids != self.tokenizer.pad_token_id)</span><br><span class="line"></span><br><span class="line">        X = input_ids[:-<span class="number">1</span>].clone().detach()</span><br><span class="line">        Y = input_ids[<span class="number">1</span>:].clone().detach()</span><br><span class="line">        loss_mask = loss_mask[<span class="number">1</span>:].clone().detach().long()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> X, Y, loss_mask</span><br></pre></td></tr></table></figure><p>Loss跟之前基本一致：</p><p>![](W&amp;B Chart5.png)</p><p>测试结果上还没有之前生成的质量好，反思了一下，感觉主要还是掩码的问题，FIM也使用了CLM的掩码，主要是看到前文提到：</p><blockquote><p>训练的时候，不止有middle部分的loss会bp，prefix和suffix也和left-to-right的数据一样会进行训练，这样FIM相比left-to-right并不会损失loss信号的量</p></blockquote><p>但是我觉得对于打乱后的psm序列，无法直接与CLM任务等价，毕竟是乱序的输入，虽然添加了标识分割，但不确定是否会导致模型学习到错误的语法，尤其是对于极小的模型。于是还是决定只计算middle的损失。不过这样的话，原有的逻辑也需要改，原本是将拼接后的数据块中的部分替换为FIM，但这样导致掩码计算很复杂，于是在替换后长度不超限制的前提下，直接将整块数据全部使用FIM或不使用，掩码计算上也方便很多。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">FIMPretrainDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, data_path, tokenizer, max_length=<span class="number">1024</span>, fim_ratio=<span class="number">0.5</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.tokenizer = tokenizer</span><br><span class="line">        self.max_length = max_length</span><br><span class="line">        self.fim_ratio = fim_ratio  <span class="comment"># FIM任务的比例</span></span><br><span class="line">        self.samples = self.load_data(data_path)</span><br><span class="line">          <span class="comment"># 确保FIM特殊标记在tokenizer词汇表中</span></span><br><span class="line">        self._add_fim_tokens()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_add_fim_tokens</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;添加FIM特殊标记到tokenizer中&quot;&quot;&quot;</span></span><br><span class="line">        special_tokens = [FIM_PREFIX, FIM_MIDDLE, FIM_SUFFIX]</span><br><span class="line">        new_tokens = []</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> token <span class="keyword">in</span> special_tokens:</span><br><span class="line">            <span class="keyword">if</span> token <span class="keyword">not</span> <span class="keyword">in</span> self.tokenizer.get_vocab():</span><br><span class="line">                new_tokens.append(token)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> new_tokens:</span><br><span class="line">            self.tokenizer.add_tokens(new_tokens)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Added FIM tokens to tokenizer: <span class="subst">&#123;new_tokens&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_parse_concatenated_text</span>(<span class="params">self, text</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;解析拼接的文本，返回各个content段落的列表&quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># 使用正则表达式匹配 &lt;s&gt;content&lt;/s&gt; 格式</span></span><br><span class="line">        pattern = <span class="string">r&#x27;&lt;s&gt;(.*?)&lt;/s&gt;&#x27;</span></span><br><span class="line">        matches = re.findall(pattern, text, re.DOTALL)</span><br><span class="line">        <span class="keyword">return</span> matches     </span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_apply_fim_to_content</span>(<span class="params">self, content</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;对单个content应用FIM变换，返回FIM内容和middle部分信息&quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># 将content编码为tokens来更精确地控制分割点</span></span><br><span class="line">        tokens = self.tokenizer.encode(content, add_special_tokens=<span class="literal">False</span>)</span><br><span class="line">        </span><br><span class="line">        total_len = <span class="built_in">len</span>(tokens)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 如果tokens太少，直接返回原内容但保持FIM格式</span></span><br><span class="line">        <span class="keyword">if</span> total_len &lt; <span class="number">6</span>:  <span class="comment"># 需要至少6个tokens才能进行合理的分割（每部分至少2个token）不过数据集过滤后不会出现这种情况</span></span><br><span class="line">            <span class="comment"># 前1/3为prefix，中间1/3为middle，后1/3为suffix</span></span><br><span class="line">            prefix_len = <span class="built_in">max</span>(<span class="number">1</span>, total_len // <span class="number">3</span>)</span><br><span class="line">            middle_len = <span class="built_in">max</span>(<span class="number">1</span>, total_len // <span class="number">3</span>)</span><br><span class="line">            suffix_start = prefix_len + middle_len</span><br><span class="line">            </span><br><span class="line">            prefix_tokens = tokens[:prefix_len]</span><br><span class="line">            middle_tokens = tokens[prefix_len:suffix_start]</span><br><span class="line">            suffix_tokens = tokens[suffix_start:]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 正常的FIM分割逻辑</span></span><br><span class="line">            <span class="comment"># 确保每部分至少有一些内容</span></span><br><span class="line">            min_part_len = <span class="built_in">max</span>(<span class="number">1</span>, total_len // <span class="number">10</span>)</span><br><span class="line">            max_prefix_len = <span class="built_in">max</span>(min_part_len, <span class="built_in">int</span>(total_len * <span class="number">0.6</span>))</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 随机选择prefix长度</span></span><br><span class="line">            prefix_len = random.randint(min_part_len, max_prefix_len)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 为middle和suffix留出空间</span></span><br><span class="line">            remaining_len = total_len - prefix_len</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 如果剩余长度不够，调整prefix长度</span></span><br><span class="line">            <span class="keyword">if</span> remaining_len &lt; <span class="number">2</span> * min_part_len:</span><br><span class="line">                prefix_len = <span class="built_in">max</span>(min_part_len, total_len - <span class="number">2</span> * min_part_len)</span><br><span class="line">                remaining_len = total_len - prefix_len</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 确保middle和suffix都有合理的长度</span></span><br><span class="line">            max_middle_len = <span class="built_in">max</span>(min_part_len, remaining_len - min_part_len)</span><br><span class="line">            middle_len = random.randint(min_part_len, max_middle_len)</span><br><span class="line">            </span><br><span class="line">            suffix_start = prefix_len + middle_len</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 如果suffix_start超出范围，调整middle_len</span></span><br><span class="line">            <span class="keyword">if</span> suffix_start &gt;= total_len:</span><br><span class="line">                middle_len = <span class="built_in">max</span>(min_part_len, total_len - prefix_len - min_part_len)</span><br><span class="line">                suffix_start = prefix_len + middle_len</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 分割tokens</span></span><br><span class="line">            prefix_tokens = tokens[:prefix_len]</span><br><span class="line">            middle_tokens = tokens[prefix_len:suffix_start]</span><br><span class="line">            suffix_tokens = tokens[suffix_start:]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 解码回文本</span></span><br><span class="line">        prefix = self.tokenizer.decode(prefix_tokens, skip_special_tokens=<span class="literal">True</span>)</span><br><span class="line">        middle = self.tokenizer.decode(middle_tokens, skip_special_tokens=<span class="literal">True</span>)</span><br><span class="line">        suffix = self.tokenizer.decode(suffix_tokens, skip_special_tokens=<span class="literal">True</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 创建FIM格式的序列: [&lt;FIM_PREFIX&gt;][prefix][&lt;FIM_SUFFIX&gt;][suffix][&lt;FIM_MIDDLE&gt;][middle]</span></span><br><span class="line">        fim_content = <span class="string">f&quot;<span class="subst">&#123;FIM_PREFIX&#125;</span><span class="subst">&#123;prefix&#125;</span><span class="subst">&#123;FIM_SUFFIX&#125;</span><span class="subst">&#123;suffix&#125;</span><span class="subst">&#123;FIM_MIDDLE&#125;</span><span class="subst">&#123;middle&#125;</span>&quot;</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 返回FIM内容和middle部分文本（用于损失掩码计算）        </span></span><br><span class="line">        <span class="keyword">return</span> fim_content, middle</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_create_mixed_sequence</span>(<span class="params">self, original_text</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;将整个序列全部替换为FIM格式，返回FIM序列和middle部分列表&quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># 解析拼接的文本</span></span><br><span class="line">        contents = self._parse_concatenated_text(original_text)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> contents:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span>, []</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 确保FIM标记添加后长度不长于max_length</span></span><br><span class="line">        fim_token_length = <span class="built_in">len</span>(FIM_PREFIX) + <span class="built_in">len</span>(FIM_SUFFIX) + <span class="built_in">len</span>(FIM_MIDDLE)</span><br><span class="line">        content_num = <span class="built_in">len</span>(contents)</span><br><span class="line">        <span class="keyword">if</span> fim_token_length * content_num + <span class="built_in">len</span>(original_text) &gt; self.max_length:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span>, []</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 将所有content都进行FIM变换</span></span><br><span class="line">        new_contents = []</span><br><span class="line">        middle_parts = []</span><br><span class="line">        <span class="keyword">for</span> content <span class="keyword">in</span> contents:</span><br><span class="line">            <span class="comment"># 对每个content应用FIM变换（总是返回有效结果）</span></span><br><span class="line">            fim_content, middle = self._apply_fim_to_content(content)</span><br><span class="line">            new_contents.append(<span class="string">f&quot;&lt;s&gt;<span class="subst">&#123;fim_content&#125;</span>&lt;/s&gt;&quot;</span>)</span><br><span class="line">            middle_parts.append(middle)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;&#x27;</span>.join(new_contents), middle_parts    </span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_create_fim_loss_mask</span>(<span class="params">self, input_ids, middle_parts</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;为FIM任务创建损失掩码，仅对middle部分计算损失&quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># 初始化损失掩码为0（不计算损失）</span></span><br><span class="line">        loss_mask = torch.zeros_like(input_ids, dtype=torch.<span class="built_in">bool</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 如果没有middle部分，返回全零掩码</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> middle_parts:</span><br><span class="line">            <span class="keyword">return</span> loss_mask</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 将input_ids转换为文本用于查找middle部分</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            full_text = self.tokenizer.decode(input_ids, skip_special_tokens=<span class="literal">False</span>)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 查找所有&lt;FIM_MIDDLE&gt;标记的位置</span></span><br><span class="line">            fim_middle_positions = []</span><br><span class="line">            search_pos = <span class="number">0</span></span><br><span class="line">            <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">                pos = full_text.find(FIM_MIDDLE, search_pos)</span><br><span class="line">                <span class="keyword">if</span> pos == -<span class="number">1</span>:</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">                fim_middle_positions.append(pos)</span><br><span class="line">                search_pos = pos + <span class="built_in">len</span>(FIM_MIDDLE)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 为每个middle部分查找对应的&lt;FIM_MIDDLE&gt;位置</span></span><br><span class="line">            <span class="keyword">for</span> i, middle_text <span class="keyword">in</span> <span class="built_in">enumerate</span>(middle_parts):</span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> middle_text.strip():</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                </span><br><span class="line">                <span class="comment"># 确保有足够的&lt;FIM_MIDDLE&gt;位置</span></span><br><span class="line">                <span class="keyword">if</span> i &gt;= <span class="built_in">len</span>(fim_middle_positions):</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">                    </span><br><span class="line">                fim_middle_pos = fim_middle_positions[i]</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># 在对应的&lt;FIM_MIDDLE&gt;之后查找middle文本</span></span><br><span class="line">                search_start = fim_middle_pos + <span class="built_in">len</span>(FIM_MIDDLE)</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># 确定搜索范围的结束位置（下一个&lt;FIM_MIDDLE&gt;或文本结束）</span></span><br><span class="line">                search_end = fim_middle_positions[i + <span class="number">1</span>] <span class="keyword">if</span> i + <span class="number">1</span> &lt; <span class="built_in">len</span>(fim_middle_positions) <span class="keyword">else</span> <span class="built_in">len</span>(full_text)</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># 在限定范围内查找middle文本</span></span><br><span class="line">                middle_start_pos = full_text.find(middle_text, search_start, search_end)</span><br><span class="line">                </span><br><span class="line">                <span class="keyword">if</span> middle_start_pos == -<span class="number">1</span>:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                </span><br><span class="line">                <span class="comment"># 编码到middle开始位置的前缀部分以找到token位置</span></span><br><span class="line">                prefix_text = full_text[:middle_start_pos]</span><br><span class="line">                prefix_tokens = self.tokenizer.encode(prefix_text, add_special_tokens=<span class="literal">False</span>)</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># 编码middle部分</span></span><br><span class="line">                middle_tokens = self.tokenizer.encode(middle_text, add_special_tokens=<span class="literal">False</span>)</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># 计算middle部分在token序列中的起始和结束位置</span></span><br><span class="line">                start_idx = <span class="built_in">len</span>(prefix_tokens)</span><br><span class="line">                end_idx = start_idx + <span class="built_in">len</span>(middle_tokens)</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># 确保索引在有效范围内</span></span><br><span class="line">                start_idx = <span class="built_in">max</span>(<span class="number">0</span>, <span class="built_in">min</span>(start_idx, <span class="built_in">len</span>(input_ids)))</span><br><span class="line">                end_idx = <span class="built_in">max</span>(start_idx, <span class="built_in">min</span>(end_idx, <span class="built_in">len</span>(input_ids)))</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># 设置middle部分的掩码为True</span></span><br><span class="line">                loss_mask[start_idx:end_idx] = <span class="literal">True</span></span><br><span class="line">                </span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="comment"># 如果解码或查找失败，回退到全零掩码</span></span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> loss_mask</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">load_data</span>(<span class="params">self, path</span>):</span><br><span class="line">        files = [<span class="string">&#x27;python_all_concatenated.jsonl&#x27;</span>] <span class="comment"># ,&#x27;java_all.jsonl&#x27;</span></span><br><span class="line">        samples = []</span><br><span class="line">        data_dir = path <span class="keyword">if</span> os.path.isdir(path) <span class="keyword">else</span> os.path.dirname(path)</span><br><span class="line">        <span class="keyword">for</span> file <span class="keyword">in</span> files:</span><br><span class="line">            file_path = os.path.join(data_dir, file)</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(file_path):</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">                </span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                <span class="keyword">with</span> <span class="built_in">open</span>(file_path, <span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">                    <span class="keyword">for</span> line_num, line <span class="keyword">in</span> <span class="built_in">enumerate</span>(f, <span class="number">1</span>):</span><br><span class="line">                        data = json.loads(line.strip())</span><br><span class="line">                        samples.append(data)</span><br><span class="line">            <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">                </span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> samples:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">f&quot;No valid data found in <span class="subst">&#123;data_dir&#125;</span>&quot;</span>)</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">return</span> samples</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.samples)    </span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">        sample = self.samples[index]</span><br><span class="line">        original_text = sample[<span class="string">&#x27;text&#x27;</span>]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 随机决定使用CLM还是FIM任务</span></span><br><span class="line">        use_fim = random.random() &lt; self.fim_ratio</span><br><span class="line">        </span><br><span class="line">        middle_parts = []  <span class="comment"># 用于存储FIM任务的middle部分</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> use_fim:</span><br><span class="line">            mixed_text, middle_parts = self._create_mixed_sequence(original_text)</span><br><span class="line">            <span class="keyword">if</span> mixed_text <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                text = mixed_text</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                text = original_text</span><br><span class="line">                use_fim = <span class="literal">False</span>  <span class="comment"># 如果FIM创建失败，回退到CLM（这部分主要是长度超限制）</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            text = original_text</span><br><span class="line">            </span><br><span class="line">        encoding = self.tokenizer(</span><br><span class="line">            text,</span><br><span class="line">            max_length=self.max_length,</span><br><span class="line">            padding=<span class="string">&#x27;max_length&#x27;</span>,</span><br><span class="line">            truncation=<span class="literal">True</span>,</span><br><span class="line">            return_tensors=<span class="string">&#x27;pt&#x27;</span></span><br><span class="line">        )</span><br><span class="line">        input_ids = encoding.input_ids.squeeze()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 根据任务类型创建损失掩码</span></span><br><span class="line">        <span class="keyword">if</span> use_fim <span class="keyword">and</span> middle_parts:</span><br><span class="line">            <span class="comment"># FIM任务：仅对middle部分计算损失</span></span><br><span class="line">            loss_mask = self._create_fim_loss_mask(input_ids, middle_parts)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># CLM任务：所有非padding token都参与损失计算</span></span><br><span class="line">            loss_mask = (input_ids != self.tokenizer.pad_token_id)</span><br><span class="line"></span><br><span class="line">        X = input_ids[:-<span class="number">1</span>].clone().detach()</span><br><span class="line">        Y = input_ids[<span class="number">1</span>:].clone().detach()</span><br><span class="line">        loss_mask = loss_mask[<span class="number">1</span>:].clone().detach().long()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> X, Y, loss_mask</span><br></pre></td></tr></table></figure><p>训练数据上也是一如既往，测试结果也是一如既往：</p><p>![](W&amp;B Chart6.png)</p><h3 id="混合精度训练">混合精度训练</h3><p>这部分主要是AMP自动实现的，不过代码里有一点小瑕疵，即 ：<code>loss = (loss * loss_mask).sum() / loss_mask.sum()</code> 这部分仍处在混合精度上下文中，可能会导致一些精度上的损失。</p><p>直接从网上博客里摘了一部分，来自https://blog.csdn.net/m0_61899108/article/details/122801824</p><h4 id="权重备份（Weight-Backup）">权重备份（Weight Backup）</h4><p>权重备份主要用于解决舍入误差的问题。其主要思路是把神经网络训练过程中产生的激活activations、梯度 gradients、中间变量等数据，在训练中都利用FP16来存储，同时复制一份FP32的权重参数weights，用于训练时候的更新。具体如下图所示。</p><img src="672e28e9a7d1035f7168e4e0d39b8760.png" style="zoom:80%"><p>从图中可以了解，在计算过程中所产生的权重weights，激活activations，梯度gradients等均使用 FP16 来进行存储和计算，其中权重使用FP32额外进行备份。由于在更新权重公式为:</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>w</mi><mi>e</mi><mi>i</mi><mi>g</mi><mi>h</mi><mi>t</mi><mo>=</mo><mi>w</mi><mi>e</mi><mi>i</mi><mi>g</mi><mi>h</mi><mi>t</mi><mo>+</mo><mi>η</mi><mo>∗</mo><mi>g</mi><mi>r</mi><mi>a</mi><mi>d</mi><mi>i</mi><mi>e</mi><mi>n</mi><mi>t</mi></mrow><annotation encoding="application/x-tex">weight=weight+\eta*gradient</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="mord mathnormal" style="margin-right:.02691em">w</span><span class="mord mathnormal">e</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:.03588em">g</span><span class="mord mathnormal">h</span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="mord mathnormal" style="margin-right:.02691em">w</span><span class="mord mathnormal">e</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:.03588em">g</span><span class="mord mathnormal">h</span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.6597200000000001em;vertical-align:-.19444em"></span><span class="mord mathnormal" style="margin-right:.03588em">η</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="mord mathnormal" style="margin-right:.03588em">g</span><span class="mord mathnormal" style="margin-right:.02778em">r</span><span class="mord mathnormal">a</span><span class="mord mathnormal">d</span><span class="mord mathnormal">i</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span></span></span></span></span></p><p>深度模型中，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi><mi>r</mi><mo>×</mo><mi>g</mi><mi>r</mi><mi>a</mi><mi>d</mi><mi>e</mi><mi>n</mi><mi>t</mi></mrow><annotation encoding="application/x-tex">lr \times gradent</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.77777em;vertical-align:-.08333em"></span><span class="mord mathnormal" style="margin-right:.01968em">l</span><span class="mord mathnormal" style="margin-right:.02778em">r</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="mord mathnormal" style="margin-right:.03588em">g</span><span class="mord mathnormal" style="margin-right:.02778em">r</span><span class="mord mathnormal">a</span><span class="mord mathnormal">d</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span></span></span></span> 的参数值可能会非常小，利用FP16来进行相加的话，则很可能会出现舍入误差问题，导致更新无效。因此通过将权重weights拷贝成FP32格式，并且确保整个更新过程是在 fp32 格式下进行的。即：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>w</mi><mi>e</mi><mi>i</mi><mi>g</mi><mi>h</mi><msub><mi>t</mi><mn>32</mn></msub><mo>=</mo><mi>w</mi><mi>e</mi><mi>i</mi><mi>g</mi><mi>h</mi><msub><mi>t</mi><mn>32</mn></msub><mo>+</mo><mi>η</mi><mo>∗</mo><mi>g</mi><mi>r</mi><mi>a</mi><mi>d</mi><mi>i</mi><mi>e</mi><mi>n</mi><msub><mi>t</mi><mn>16</mn></msub></mrow><annotation encoding="application/x-tex">weight_{32}=weight_{32}+\eta*gradient_{16}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="mord mathnormal" style="margin-right:.02691em">w</span><span class="mord mathnormal">e</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:.03588em">g</span><span class="mord mathnormal">h</span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">32</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="mord mathnormal" style="margin-right:.02691em">w</span><span class="mord mathnormal">e</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:.03588em">g</span><span class="mord mathnormal">h</span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">32</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.6597200000000001em;vertical-align:-.19444em"></span><span class="mord mathnormal" style="margin-right:.03588em">η</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="mord mathnormal" style="margin-right:.03588em">g</span><span class="mord mathnormal" style="margin-right:.02778em">r</span><span class="mord mathnormal">a</span><span class="mord mathnormal">d</span><span class="mord mathnormal">i</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">16</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span></span></p><p>权重用FP32格式备份一次，那岂不是使得内存占用反而更高了呢？是的，额外拷贝一份weight的确增加了训练时候内存的占用。 但是实际上，在训练过程中内存中分为动态内存和静态内容，其中动态内存是静态内存的3-4倍，主要是中间变量值和激活activations的值。而这里备份的权重增加的主要是静态内存。只要动态内存的值基本都是使用FP16来进行存储，则最终模型与整网使用FP32进行训练相比起来， 内存占用也基本能够减半。</p><h4 id="损失缩放（Loss-Scaling）">损失缩放（Loss Scaling）</h4><p>如图所示，如果仅仅使用FP32训练，模型收敛得比较好，但是如果用了混合精度训练，会存在网络模型无法收敛的情况。原因是梯度的值太小，使用FP16表示会造成了数据下溢出（Underflow）的问题，导致模型不收敛，如图中灰色的部分。于是需要引入损失缩放（Loss Scaling）技术。</p><img src="2c70ef3303b43e16316c9f947531a77a.png" style="zoom:80%"><p>下面是在网络模型训练阶段， 某一层的激活函数梯度分布式中，其中有68%的网络模型激活参数位0，另外有4%的精度在2^-32~2^-20这个区间内，直接使用FP16对这里面的数据进行表示，会截断下溢的数据，所有的梯度值都会变为0。</p><img src="93c35891bc0f988293a959c0c1dbf3fc.png" style="zoom:67%"><p>为了解决梯度过小数据下溢的问题，对前向计算出来的Loss值进行放大操作，也就是把FP32的参数乘以某一个因子系数后，把可能溢出的小数位数据往前移，平移到FP16能表示的数据范围内。根据链式求导法则，放大Loss后会作用在反向传播的每一层梯度，这样比在每一层梯度上进行放大更加高效。</p><img src="16dead68abdc121952cadb9e32c0ff04.png" style="zoom:67%"><p>损失放大是需要结合混合精度实现的，其主要的主要思路是：</p><ul><li><strong>Scale up阶段</strong>，网络模型前向计算后在反响传播前，将得到的损失变化值DLoss增大2^K倍。</li><li><strong>Scale down阶段</strong>，反向传播后，将权重梯度缩2^K倍，恢复FP32值进行存储。</li></ul><p>动态损失缩放（Dynamic Loss Scaling）：上面提到的损失缩放都是使用一个默认值对损失值进行缩放，为了充分利用FP16的动态范围，可以更好地缓解舍入误差，尽量使用比较大的放大倍数。总结动态损失缩放算法，就是每当梯度溢出时候减少损失缩放规模，并且间歇性地尝试增加损失规模，从而实现在不引起溢出的情况下使用最高损失缩放因子，更好地恢复精度。</p><p><strong>动态损失缩放的算法如下：</strong></p><ol><li>动态损失缩放的算法会从比较高的缩放因子开始（如2^24），然后开始进行训练迭代中检查数是否会溢出（Infs/Nans）；</li><li>如果没有梯度溢出，则不进行缩放，继续进行迭代；如果检测到梯度溢出，则缩放因子会减半，重新确认梯度更新情况，直到数不产生溢出的范围内；</li><li>在训练的后期，loss已经趋近收敛稳定，梯度更新的幅度往往小了，这个时候可以允许更高的损失缩放因子来再次防止数据下溢。</li><li>因此，动态损失缩放算法会尝试在每N（N=2000）次迭代将损失缩放增加F倍数，然后执行步骤2检查是否溢出。</li></ol><h4 id="精度累加（Precision-Accumulated）">精度累加（Precision Accumulated）</h4><p>在混合精度的模型训练过程中，使用FP16进行矩阵乘法运算，利用FP32来进行矩阵乘法中间的累加（accumulated），然后再将FP32的值转化为FP16进行存储。简单而言，就是利用FP16进行矩阵相乘，利用FP32来进行加法计算弥补丢失的精度。 这样可以有效减少计算过程中的舍入误差，尽量减缓精度损失的问题。</p><p>例如在Nvidia Volta 结构中带有Tensor Core，可以利用FP16混合精度来进行加速，还能保持精度。Tensor Core主要用于实现FP16的矩阵相乘，在利用FP16或者FP32进行累加和存储。在累加阶段能够使用FP32大幅减少混合精度训练的精度损失。</p><img src="4944aaec9a261198618232b93f2a4525.png" style="zoom:75%"><h3 id="MTP">MTP</h3><blockquote><p>摘自：<a target="_blank" rel="noopener external nofollow noreferrer" href="https://zhuanlan.zhihu.com/p/14890557782">https://zhuanlan.zhihu.com/p/14890557782</a></p><p>DeepSeek-V3 创新性地采用了 MTP 目标，将预测范围<strong>扩展到每个位置的多个后续 token</strong>。</p><p>这种设计具有双重优势：</p><p>首先，MTP 目标通过增加训练信号的密度可能提高数据利用效率；其次，它使模型能够提前规划表征，从而更准确地预测后续 token。</p><p>如图3所示，该实现方案与先前研究的方法有所不同：前者使用独立输出头并行预测 DD 个额外 token，而 DeepSeek-V3 采用顺序预测方式，并在每个预测层级保持完整的因果关系链。</p><p><img src="https://pica.zhimg.com/v2-c4fddc1aec3cd7f899700cb806b2b7ce_1440w.jpg" alt=""></p><p>图3：MTP实现示意图。V3在每个深度上保持每个 token 预测过程中的完整因果依赖链。</p><p>MTP 模块架构：具体实现中，模型采用 D 个串联模块来预测 D 个额外的 token。每个 MTP 模块（第 k 个）包含以下组件：</p><ul><li>共享向量层 Emb(·)</li><li>共享输出头 OutHead(·)</li><li>Transformer 处理单元 TRM(·)</li><li>维度映射矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>M</mi><mi>k</mi></msub><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>d</mi><mo>×</mo><mn>2</mn><mi>d</mi></mrow></msup></mrow><annotation encoding="application/x-tex">M_k \in \mathbb{R}^{d \times 2d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.83333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.10903em">M</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.33610799999999996em"><span style="top:-2.5500000000000003em;margin-left:-.10903em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.8491079999999999em;vertical-align:0"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8491079999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mbin mtight">×</span><span class="mord mtight">2</span><span class="mord mathnormal mtight">d</span></span></span></span></span></span></span></span></span></span></span></span><br>对于输入序列中的第 i 个 token <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>t</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">t_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.76508em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span>，在第 k 层预测时，模型首先将两个向量进行组合：该 token 在第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>k</mi><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(k-1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:.03148em">k</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord">1</span><span class="mclose">)</span></span></span></span> 层的特征表示 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>h</mi><mi>i</mi><mrow><mi>k</mi><mo>−</mo><mn>1</mn></mrow></msubsup><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mi>d</mi></msup></mrow><annotation encoding="application/x-tex">h_i^{k-1} \in \mathbb{R}^d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.166103em;vertical-align:-.276864em"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8892389999999999em"><span style="top:-2.4231360000000004em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.1031310000000003em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.276864em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.849108em;vertical-align:0"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.849108em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span></span></span></span></span></span></span></span> 和第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>i</mi><mo>+</mo><mi>k</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(i+k)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.03148em">k</span><span class="mclose">)</span></span></span></span> 个 token 的向量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mi>m</mi><mi>b</mi><mo stretchy="false">(</mo><msub><mi>t</mi><mrow><mi>i</mi><mo>+</mo><mi>k</mi></mrow></msub><mo stretchy="false">)</mo><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mi>d</mi></msup></mrow><annotation encoding="application/x-tex">Emb(t_{i+k}) \in \mathbb{R}^d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.05764em">E</span><span class="mord mathnormal">mb</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3361079999999999em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.208331em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.849108em;vertical-align:0"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.849108em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span></span></span></span></span></span></span></span>，通过线性变换进行融合：</li></ul><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msubsup><mi mathvariant="bold">h</mi><mi>i</mi><mi>k</mi></msubsup><mo>=</mo><msub><mi>M</mi><mi>k</mi></msub><mo stretchy="false">[</mo><mtext>RMSNorm</mtext><mo stretchy="false">(</mo><msubsup><mi mathvariant="bold">h</mi><mi>i</mi><mrow><mi>k</mi><mo>−</mo><mn>1</mn></mrow></msubsup><mo stretchy="false">)</mo><mo separator="true">;</mo><mtext>RMSNorm</mtext><mo stretchy="false">(</mo><mi>E</mi><mi>m</mi><mi>b</mi><mo stretchy="false">(</mo><msub><mi>t</mi><mrow><mi>i</mi><mo>+</mo><mi>k</mi></mrow></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo separator="true">,</mo></mrow><annotation encoding="application/x-tex">\mathbf{h}_i^{k} = M_k [\text{RMSNorm}(\mathbf{h}_i^{k-1}); \text{RMSNorm}(Emb(t_{i+k}))],</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.146108em;vertical-align:-.247em"></span><span class="mord"><span class="mord mathbf">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8991079999999998em"><span style="top:-2.4530000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.247em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.1661029999999997em;vertical-align:-.266995em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.10903em">M</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.33610799999999996em"><span style="top:-2.5500000000000003em;margin-left:-.10903em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mopen">[</span><span class="mord text"><span class="mord">RMSNorm</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathbf">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8991079999999998em"><span style="top:-2.433005em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.266995em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">;</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord text"><span class="mord">RMSNorm</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:.05764em">E</span><span class="mord mathnormal">mb</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3361079999999999em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.208331em"><span></span></span></span></span></span></span><span class="mclose">))]</span><span class="mpunct">,</span></span></span></span></span></p><p>其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mo>⋅</mo><mo separator="true">;</mo><mo>⋅</mo><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[ \cdot; \cdot ]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">[</span><span class="mord">⋅</span><span class="mpunct">;</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord">⋅</span><span class="mclose">]</span></span></span></span> 表示向量拼接操作。需要特别说明的是，在 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">k = 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.03148em">k</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">1</span></span></span></span> 时，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>h</mi><mi>i</mi><mrow><mi>k</mi><mo>−</mo><mn>1</mn></mrow></msubsup></mrow><annotation encoding="application/x-tex">h_i^{k-1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.166103em;vertical-align:-.276864em"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8892389999999999em"><span style="top:-2.4231360000000004em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.1031310000000003em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.276864em"><span></span></span></span></span></span></span></span></span></span> 代表主模型输出的特征表示。值得注意的是，每个 MTP 模块都与主模型共享同一个向量层。经过组合的特征向量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi mathvariant="bold">h</mi><mi>i</mi><mi>k</mi></msubsup></mrow><annotation encoding="application/x-tex">\mathbf{h}_i^{k}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.107772em;vertical-align:-.258664em"></span><span class="mord"><span class="mord mathbf">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.849108em"><span style="top:-2.441336em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.258664em"><span></span></span></span></span></span></span></span></span></span> 随后输入到第 k 层的 Transformer 处理单元，生成该层的输出特征表示 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>h</mi><mi>i</mi><mi>k</mi></msubsup></mrow><annotation encoding="application/x-tex">h_i^k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.107772em;vertical-align:-.258664em"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.849108em"><span style="top:-2.441336em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.258664em"><span></span></span></span></span></span></span></span></span></span>：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msubsup><mi mathvariant="bold">h</mi><mrow><mn>1</mn><mo>:</mo><mi>T</mi><mo>−</mo><mi>k</mi></mrow><mi>k</mi></msubsup><mo>=</mo><msub><mtext>TRM</mtext><mi>k</mi></msub><mo stretchy="false">(</mo><msubsup><mi mathvariant="bold">h</mi><mrow><mn>1</mn><mo>:</mo><mi>T</mi><mo>−</mo><mi>k</mi></mrow><mi>k</mi></msubsup><mo stretchy="false">)</mo><mo separator="true">,</mo></mrow><annotation encoding="application/x-tex">\mathbf{h}_{1:T-k}^k = \text{TRM}_k(\mathbf{h}_{1:T-k}^{k}),</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.204439em;vertical-align:-.305331em"></span><span class="mord"><span class="mord mathbf">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.899108em"><span style="top:-2.4530000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight" style="margin-right:.13889em">T</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span></span></span></span><span style="top:-3.1130000000000004em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.305331em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.204439em;vertical-align:-.305331em"></span><span class="mord"><span class="mord text"><span class="mord">TRM</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.33610799999999996em"><span style="top:-2.5500000000000003em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathbf">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.899108em"><span style="top:-2.4530000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight" style="margin-right:.13889em">T</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span></span></span></span><span style="top:-3.1130000000000004em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.305331em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">,</span></span></span></span></span></p><p>其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi></mrow><annotation encoding="application/x-tex">T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.13889em">T</span></span></span></span> 代表输入序列的长度，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mo>:</mo><mi>j</mi></mrow><annotation encoding="application/x-tex">i:j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.65952em;vertical-align:0"></span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">:</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.85396em;vertical-align:-.19444em"></span><span class="mord mathnormal" style="margin-right:.05724em">j</span></span></span></span> 表示包含两端的切片操作。接着，系统将 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>h</mi><mi>i</mi><mi>k</mi></msubsup></mrow><annotation encoding="application/x-tex">h_i^k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.107772em;vertical-align:-.258664em"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.849108em"><span style="top:-2.441336em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.258664em"><span></span></span></span></span></span></span></span></span></span> 输入到共享输出层，计算第 k 个预测 token 的概率分布 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>P</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn><mo>+</mo><mi>k</mi></mrow><mi>k</mi></msubsup><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mi>V</mi></msup></mrow><annotation encoding="application/x-tex">P_{i+1+k}^k \in \mathbb{R}^V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.190547em;vertical-align:-.34143899999999994em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.849108em"><span style="top:-2.4168920000000003em;margin-left:-.13889em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span></span></span></span><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.34143899999999994em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.8413309999999999em;vertical-align:0"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8413309999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.22222em">V</span></span></span></span></span></span></span></span></span></span></span>（V 为词表大小）：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msubsup><mi>P</mi><mrow><mi>i</mi><mo>+</mo><mi>k</mi><mo>+</mo><mn>1</mn></mrow><mi>k</mi></msubsup><mo>=</mo><mtext>OutHead</mtext><mo stretchy="false">(</mo><msubsup><mi mathvariant="bold">h</mi><mi>i</mi><mi>k</mi></msubsup><mo stretchy="false">)</mo><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">P_{i+k+1}^k = \text{OutHead}(\mathbf{h}_i^k).</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.204439em;vertical-align:-.305331em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.899108em"><span style="top:-2.4530000000000003em;margin-left:-.13889em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.1130000000000004em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.305331em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.1491079999999998em;vertical-align:-.25em"></span><span class="mord text"><span class="mord">OutHead</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathbf">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8991079999999998em"><span style="top:-2.4530000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.247em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord">.</span></span></span></span></span></p><p>输出层 OutHead(·) 首先通过线性变换将特征表示转换为 logits，然后使用 Softmax(·) 函数计算第 k 个预测 token 的概率分布。与向量层类似，每个 MTP 模块的输出层也与主模型共享。这种保持预测因果链的设计思路与 EAGLE 相近，但两者目标不同：EAGLE 主要用于推测解码，而本研究中的 MTP 主要用于优化训练效果。<br>MTP 训练目标优化：系统为每个预测层级计算交叉熵损失 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi mathvariant="script">L</mi><mrow><mi>M</mi><mi>T</mi><mi>P</mi></mrow><mi>k</mi></msubsup></mrow><annotation encoding="application/x-tex">\mathcal{L}_{MTP}^k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.124439em;vertical-align:-.275331em"></span><span class="mord"><span class="mord mathcal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.849108em"><span style="top:-2.424669em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.13889em">MTP</span></span></span></span><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.275331em"><span></span></span></span></span></span></span></span></span></span>：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msubsup><mi mathvariant="script">L</mi><mrow><mi>M</mi><mi>T</mi><mi>P</mi></mrow><mi>k</mi></msubsup><mo>=</mo><mtext>CrossEntropy</mtext><mo stretchy="false">(</mo><msubsup><mi>P</mi><mrow><mn>2</mn><mo>+</mo><mi>k</mi><mo>:</mo><mi>T</mi><mo>+</mo><mn>1</mn></mrow><mi>k</mi></msubsup><mo separator="true">,</mo><msub><mi>t</mi><mrow><mn>2</mn><mo>+</mo><mi>k</mi><mo>:</mo><mi>T</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo><mo>=</mo><mo>−</mo><mfrac><mn>1</mn><mi>T</mi></mfrac><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>2</mn><mo>+</mo><mi>k</mi></mrow><mrow><mi>T</mi><mo>+</mo><mn>1</mn></mrow></munderover><mi>log</mi><mo>⁡</mo><msubsup><mi>P</mi><mi>i</mi><mi>k</mi></msubsup><mo stretchy="false">[</mo><msub><mi>t</mi><mi>i</mi></msub><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{L}_{MTP}^k = \text{CrossEntropy}(P_{2+k:T+1}^k, t_{2+k:T+1}) = -\frac{1}{T} \sum_{i=2+k}^{T+1} \log P_i^k[t_i]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.146108em;vertical-align:-.247em"></span><span class="mord"><span class="mord mathcal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8991079999999998em"><span style="top:-2.4530000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.13889em">MTP</span></span></span></span><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.247em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.204439em;vertical-align:-.305331em"></span><span class="mord text"><span class="mord">CrossEntropy</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.899108em"><span style="top:-2.4530000000000003em;margin-left:-.13889em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight" style="margin-right:.13889em">T</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.1130000000000004em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.305331em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3361079999999999em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight" style="margin-right:.13889em">T</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.208331em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:3.1887800000000004em;vertical-align:-1.360444em"></span><span class="mord">−</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">T</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.686em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283360000000002em"><span style="top:-1.8478869999999998em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">2</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span></span></span></span><span style="top:-3.0500049999999996em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.300005em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.13889em">T</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.360444em"><span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mop">lo<span style="margin-right:.01389em">g</span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8991079999999998em"><span style="top:-2.4530000000000003em;margin-left:-.13889em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.247em"><span></span></span></span></span></span></span><span class="mopen">[</span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">]</span></span></span></span></span></p><p>其中，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi></mrow><annotation encoding="application/x-tex">T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.13889em">T</span></span></span></span> 表示输入序列长度，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>t</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">t_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.76508em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 代表第 i 个位置的目标 token，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>P</mi><mi>i</mi><mi>k</mi></msubsup><mo stretchy="false">[</mo><msub><mi>t</mi><mi>i</mi></msub><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">P_i^k[t_i]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.107772em;vertical-align:-.258664em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.849108em"><span style="top:-2.441336em;margin-left:-.13889em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.258664em"><span></span></span></span></span></span></span><span class="mopen">[</span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">]</span></span></span></span> 表示第 k 个 MTP 模块对 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>t</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">t_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.76508em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 的预测概率。最终，通过计算所有层级 MTP 损失的平均值并乘以权重系数 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord mathnormal">λ</span></span></span></span>，得到总体 MTP 损失 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="script">L</mi><mrow><mi>M</mi><mi>T</mi><mi>P</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\mathcal{L}_{MTP}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.83333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathcal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.32833099999999993em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.13889em">MTP</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span>，作为 DeepSeek-V3 的补充训练目标：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="script">L</mi><mrow><mi>M</mi><mi>T</mi><mi>P</mi></mrow></msub><mo>=</mo><mfrac><mi>λ</mi><mi>D</mi></mfrac><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>D</mi></munderover><msubsup><mi mathvariant="script">L</mi><mrow><mi>M</mi><mi>T</mi><mi>P</mi></mrow><mi>k</mi></msubsup><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">\mathcal{L}_{MTP} = \frac{\lambda}{D} \sum_{k=1}^D \mathcal{L}_{MTP}^k.</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.83333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathcal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.32833099999999993em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.13889em">MTP</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:3.1304490000000005em;vertical-align:-1.302113em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.37144em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.02778em">D</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal">λ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.686em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283360000000002em"><span style="top:-1.8478869999999998em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.0500049999999996em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.300005em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.02778em">D</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.302113em"><span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathcal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8991079999999998em"><span style="top:-2.4530000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.13889em">MTP</span></span></span></span><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.247em"><span></span></span></span></span></span></span><span class="mord">.</span></span></span></span></span></p><p>推理阶段的MTP：应用 MTP 机制的主要目的是提升基础模型的性能，因此在实际推理阶段可以不使用 MTP 模块，基础模型能够独立完成正常推理。此外，这些 MTP 模块也可以被重新配置用于推理解码，从而降低模型生成的时间延迟。</p></blockquote><h3 id="数据集扩充">数据集扩充</h3><p>使用如下两个数据集进行数据扩充：</p><p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://huggingface.co/datasets/angie-chen55/python-github-code">https://huggingface.co/datasets/angie-chen55/python-github-code</a></p><p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://huggingface.co/datasets/Shuu12121/python-treesitter-filtered-datasetsV2">https://huggingface.co/datasets/Shuu12121/python-treesitter-filtered-datasetsV2</a></p><p>流程依旧是：构造，筛选，去重，拼接</p><ol><li>然后，加载三份筛选过数据集，统一构造为<code>&#123;“text”：“data”&#125;</code>的格式，其中，code_search_net的构造格式为<code>&quot;&lt;s&gt; &#123;sample['docstring']&#125;&#123;sample['language']&#125;\n&#123;sample['function']&#125;&lt;/s&gt;&quot;</code>，python-treesitter-filtered 数据集的构造格式为<code>&quot;&lt;s&gt; &#123;sample['docstring']&#125;&#123;sample['language']&#125;\n&#123;sample['code']&#125;&lt;/s&gt;&quot;</code>，python-github-code 数据集已经是<code>&#123;“text”：“data”&#125;</code>格式。</li><li>其次，将构造好的三份数据集合并成一份数据，遍历所有数据，去除data长度小于48且大于1024数据的数据。</li><li>最后，对所有数据进行去重。</li></ol><h4 id="数据集去重实践">数据集去重实践</h4><blockquote><p>这块是真不熟，以前没怎么注意过。</p></blockquote><p>刚开始想着直接TF-IDF+FAISS招呼一下得了，结果慢爆了，就想着拿ANN优化一下，于是试了一下HNSW，直接爆内存了（但其实内存上限没有达到，可能还是代码有问题），于是又使用<code>IndexFlatIP</code>替代HNSW，但其实还是换汤不换药，主要还是用了<code>range_search</code>太费时间，而且维护大量索引非常占内存，实测在1000维特征下占用到了约十倍数据集大小的内存。在16核的情况下，最开始时每处理1000个数据就要花费约80秒（当然这个会越来越快），</p><p>最后还是老老实实去看论文，比较新的应该是字节的<a target="_blank" rel="noopener external nofollow noreferrer" href="https://arxiv.org/pdf/2506.03524">SeedCoder</a>，预训练使用规则提取+FastText召回，后训练结合规则（Tree-sitter去语法错误）和模型（LLM评估正确性）进行质量过滤，好吧，这个有点跑题。</p><p>最后选择使用的是<a target="_blank" rel="noopener external nofollow noreferrer" href="https://arxiv.org/pdf/2411.04905">OpenCoder</a>建议的去重方案，即exact-dedup + file-level minhash+LSH，当然OpenCoder中的数据工作还是使用了非常多的启发式规则，而且也提到了Star高的代码总体质量在经过LLM打分后并不一定好。</p><p>最后主要耗时还是在生成MinHash签名的部分，主要也是没用并行优化，300W量级的数据一共生成了2个小时还多。最终结果如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">生成 MinHash 签名...</span><br><span class="line">生成MinHash: <span class="number">100</span>%|███████████████████████████████████████████████████████████████████████████████████████| <span class="number">3066083</span>/<span class="number">3066083</span> [<span class="number">2</span>:<span class="number">35</span>:<span class="number">39</span>&lt;<span class="number">00</span>:<span class="number">00</span>, <span class="number">328.29</span>it/s]</span><br><span class="line">构建 LSH 索引...</span><br><span class="line">构建LSH索引: <span class="number">100</span>%|███████████████████████████████████████████████████████████████████████████████████████| <span class="number">3066083</span>/<span class="number">3066083</span> [01:<span class="number">26</span>&lt;<span class="number">00</span>:<span class="number">00</span>, <span class="number">35530.14</span>it/s]</span><br><span class="line">查找相似样本...</span><br><span class="line">查找相似样本: <span class="number">100</span>%|██████████████████████████████████████████████████████████████████████████████████████| <span class="number">3066083</span>/<span class="number">3066083</span> [<span class="number">00</span>:<span class="number">54</span>&lt;<span class="number">00</span>:<span class="number">00</span>, <span class="number">55827.35</span>it/s]</span><br><span class="line">生成最终结果...</span><br><span class="line">===== 去重完成 =====</span><br><span class="line">总耗时: <span class="number">9489.78</span> 秒</span><br><span class="line">原始样本: <span class="number">3</span>,<span class="number">178</span>,<span class="number">796</span></span><br><span class="line">精确重复: <span class="number">112</span>,<span class="number">713</span></span><br><span class="line">相似重复: <span class="number">347</span>,<span class="number">412</span></span><br><span class="line">总计去除: <span class="number">460</span>,<span class="number">125</span></span><br><span class="line">剩余样本: <span class="number">2</span>,<span class="number">718</span>,<span class="number">671</span></span><br><span class="line">去重率: <span class="number">14.47</span>%</span><br></pre></td></tr></table></figure><p>总体的去重结果：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">原始数据量: 3,202,132</span><br><span class="line">长度筛选后: 3,178,796</span><br><span class="line">去重后: 2,718,671</span><br><span class="line">总去除比例: 15.10%</span><br></pre></td></tr></table></figure><p>这里有很多精确重复，主要是<code>python-treesitter-filtered</code>包含了很多<code>code_search_net</code>中的数据。</p><h2 id="SFT">SFT</h2><h3 id="数据集">数据集</h3><p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://huggingface.co/datasets/saurabh5/correct-python-sft-187k">https://huggingface.co/datasets/saurabh5/correct-python-sft-187k</a></p><p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://huggingface.co/datasets/saurabh5/rlvr-code-data-python-sft">https://huggingface.co/datasets/saurabh5/rlvr-code-data-python-sft</a></p><h2 id="评估：HumanEval">评估：HumanEval</h2><p>这部分主要是参考https://github.com/abacaj/code-eval进行评估的执行</p><p>有个bug，应该跟pip版本有关系：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># setup.py:没标入口函数</span></span><br><span class="line">entry_points=&#123;</span><br><span class="line">    <span class="string">&quot;console_scripts&quot;</span>: [</span><br><span class="line">        <span class="string">&quot;evaluate_functional_correctness = human_eval.evaluate_functional_correctness:main&quot;</span>,</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>结果是挺惨淡的</p><h2 id="Reference">Reference</h2><p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://zhuanlan.zhihu.com/p/14890557782">https://zhuanlan.zhihu.com/p/14890557782</a></p><p>FIM：<a target="_blank" rel="noopener external nofollow noreferrer" href="https://arxiv.org/pdf/2207.14255">https://arxiv.org/pdf/2207.14255</a></p><p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://zhuanlan.zhihu.com/p/3217226274">https://zhuanlan.zhihu.com/p/3217226274</a></p><p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://blog.csdn.net/m0_61899108/article/details/122801824">https://blog.csdn.net/m0_61899108/article/details/122801824</a></p><p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://arxiv.org/pdf/2506.03524">https://arxiv.org/pdf/2506.03524</a></p><p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://arxiv.org/pdf/2411.04905">https://arxiv.org/pdf/2411.04905</a></p></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://zwn2001.space">琉璃月</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://zwn2001.space/posts/Graduate-Works/Works/CoderLLM%E8%AE%AD%E7%BB%83%E8%AE%B0%E5%BD%951/">https://zwn2001.space/posts/Graduate-Works/Works/CoderLLM%E8%AE%AD%E7%BB%83%E8%AE%B0%E5%BD%951/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="external nofollow noreferrer" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://zwn2001.space" target="_blank">ZWN's blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="/img/cover/58.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://unpkg.com/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload='this.media="all"'><script src="https://unpkg.com/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/posts/Graduate-Works/Paper-Read/%E8%AF%BBpaper23-arxiv%E4%BB%A3%E7%A0%81%E4%BF%AE%E5%A4%8D%E8%AE%BA%E6%96%87%E7%BB%842/" title="读paper23-arxiv代码修复论文组2"><img class="cover" src="/img/cover/50.jpg" onerror='onerror=null,src="/img/404.webp"' alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">读paper23-arxiv代码修复论文组2</div></div></a></div><div class="next-post pull-right"><a href="/posts/Graduate-Works/Works/%E9%92%88%E5%AF%B9d4j%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/" title="针对d4j的一些思考"><img class="cover" src="/img/cover/8.jpg" onerror='onerror=null,src="/img/404.webp"' alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">针对d4j的一些思考</div></div></a></div></nav><hr><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="giscus-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/favicon.webp" onerror='this.onerror=null,this.src="/img/friend_404.gif"' alt="avatar"></div><div class="author-info__name">琉璃月</div><div class="author-info__description">我虽无意逐鹿，却知苍生苦楚</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">176</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">52</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">8</div></a></div><a id="card-info-btn" target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/ZWN2001"><i class="fab fa-github"></i><span>我的Github</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/ZWN2001" rel="external nofollow noreferrer" target="_blank" title="Github"><i class="fab fa-github"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">新域名：www.zwn2001.space，有效期：10年。https://www.zwn-blog.xyz已过期。访问时建议科学上网，否则博客内公式渲染会出现问题且速度慢。Ctrl+shift+r可强制刷新网站以避免浏览器缓存造成的更新不及时</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">CoderLLM训练记录</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%A2%84%E8%AE%AD%E7%BB%83-Dense"><span class="toc-number">1.1.</span> <span class="toc-text">预训练-Dense</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%80%E4%B8%AA%E4%BD%8E%E7%BA%A7%E4%BD%86%E5%8F%88%E4%B8%8D%E5%A4%AA%E4%BD%8E%E7%BA%A7%E7%9A%84%E9%94%99%E8%AF%AF"><span class="toc-number">1.1.1.</span> <span class="toc-text">一个低级但又不太低级的错误</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E-CodeSearchNet-%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E9%A2%84%E8%AE%AD%E7%BB%83"><span class="toc-number">1.1.2.</span> <span class="toc-text">基于 CodeSearchNet 数据集的预训练</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%9B%B4%E6%8E%A5%E8%AE%AD%E7%BB%83"><span class="toc-number">1.1.2.1.</span> <span class="toc-text">直接训练</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BC%98%E5%8C%96%E5%90%8E%E7%9A%84%E8%AE%AD%E7%BB%83"><span class="toc-number">1.1.2.2.</span> <span class="toc-text">数据集优化后的训练</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#FIM"><span class="toc-number">1.1.3.</span> <span class="toc-text">FIM</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#FIM%E6%95%88%E6%9E%9C"><span class="toc-number">1.1.3.1.</span> <span class="toc-text">FIM效果</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83"><span class="toc-number">1.1.3.2.</span> <span class="toc-text">训练</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#FIM-rate"><span class="toc-number">1.1.3.3.</span> <span class="toc-text">FIM rate</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%88%87%E5%88%86"><span class="toc-number">1.1.3.4.</span> <span class="toc-text">数据切分</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E7%BB%93%E6%9E%9C"><span class="toc-number">1.1.3.5.</span> <span class="toc-text">训练结果</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B7%B7%E5%90%88%E7%B2%BE%E5%BA%A6%E8%AE%AD%E7%BB%83"><span class="toc-number">1.1.4.</span> <span class="toc-text">混合精度训练</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9D%83%E9%87%8D%E5%A4%87%E4%BB%BD%EF%BC%88Weight-Backup%EF%BC%89"><span class="toc-number">1.1.4.1.</span> <span class="toc-text">权重备份（Weight Backup）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8D%9F%E5%A4%B1%E7%BC%A9%E6%94%BE%EF%BC%88Loss-Scaling%EF%BC%89"><span class="toc-number">1.1.4.2.</span> <span class="toc-text">损失缩放（Loss Scaling）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%B2%BE%E5%BA%A6%E7%B4%AF%E5%8A%A0%EF%BC%88Precision-Accumulated%EF%BC%89"><span class="toc-number">1.1.4.3.</span> <span class="toc-text">精度累加（Precision Accumulated）</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#MTP"><span class="toc-number">1.1.5.</span> <span class="toc-text">MTP</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E6%89%A9%E5%85%85"><span class="toc-number">1.1.6.</span> <span class="toc-text">数据集扩充</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E5%8E%BB%E9%87%8D%E5%AE%9E%E8%B7%B5"><span class="toc-number">1.1.6.1.</span> <span class="toc-text">数据集去重实践</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#SFT"><span class="toc-number">1.2.</span> <span class="toc-text">SFT</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">1.2.1.</span> <span class="toc-text">数据集</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AF%84%E4%BC%B0%EF%BC%9AHumanEval"><span class="toc-number">1.3.</span> <span class="toc-text">评估：HumanEval</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Reference"><span class="toc-number">1.4.</span> <span class="toc-text">Reference</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/posts/Graduate-Works/Paper-Read/%E8%AF%BBpaper23-arxiv%E4%BB%A3%E7%A0%81%E4%BF%AE%E5%A4%8D%E8%AE%BA%E6%96%87%E7%BB%842/" title="读paper23-arxiv代码修复论文组2"><img src="/img/cover/50.jpg" onerror='this.onerror=null,this.src="/img/404.webp"' alt="读paper23-arxiv代码修复论文组2"></a><div class="content"><a class="title" href="/posts/Graduate-Works/Paper-Read/%E8%AF%BBpaper23-arxiv%E4%BB%A3%E7%A0%81%E4%BF%AE%E5%A4%8D%E8%AE%BA%E6%96%87%E7%BB%842/" title="读paper23-arxiv代码修复论文组2">读paper23-arxiv代码修复论文组2</a><time datetime="2025-07-12T07:50:19.000Z" title="发表于 2025-07-12 15:50:19">2025-07-12</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/Graduate-Works/Works/CoderLLM%E8%AE%AD%E7%BB%83%E8%AE%B0%E5%BD%951/" title="CoderLLM训练记录"><img src="/img/cover/58.jpg" onerror='this.onerror=null,this.src="/img/404.webp"' alt="CoderLLM训练记录"></a><div class="content"><a class="title" href="/posts/Graduate-Works/Works/CoderLLM%E8%AE%AD%E7%BB%83%E8%AE%B0%E5%BD%951/" title="CoderLLM训练记录">CoderLLM训练记录</a><time datetime="2025-06-15T12:11:50.000Z" title="发表于 2025-06-15 20:11:50">2025-06-15</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/Graduate-Works/Works/%E9%92%88%E5%AF%B9d4j%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/" title="针对d4j的一些思考"><img src="/img/cover/8.jpg" onerror='this.onerror=null,this.src="/img/404.webp"' alt="针对d4j的一些思考"></a><div class="content"><a class="title" href="/posts/Graduate-Works/Works/%E9%92%88%E5%AF%B9d4j%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/" title="针对d4j的一些思考">针对d4j的一些思考</a><time datetime="2025-06-04T04:56:57.000Z" title="发表于 2025-06-04 12:56:57">2025-06-04</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/Graduate-Works/Paper-Read/%E8%AF%BBpaper22-arxiv%E4%BB%A3%E7%A0%81%E4%BF%AE%E5%A4%8D%E8%AE%BA%E6%96%87%E7%BB%84/" title="读paper22-arxiv代码修复论文组"><img src="/img/cover/15.jpg" onerror='this.onerror=null,this.src="/img/404.webp"' alt="读paper22-arxiv代码修复论文组"></a><div class="content"><a class="title" href="/posts/Graduate-Works/Paper-Read/%E8%AF%BBpaper22-arxiv%E4%BB%A3%E7%A0%81%E4%BF%AE%E5%A4%8D%E8%AE%BA%E6%96%87%E7%BB%84/" title="读paper22-arxiv代码修复论文组">读paper22-arxiv代码修复论文组</a><time datetime="2025-06-03T13:50:38.000Z" title="发表于 2025-06-03 21:50:38">2025-06-03</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/Graduate-Works/Paper-Read/%E8%AF%BBpaper21-%E9%80%9A%E8%BF%87%E8%87%AA%E9%80%82%E5%BA%94%E6%A0%91%E9%81%8D%E5%8E%86%E8%BF%9B%E8%A1%8C%E5%8A%A8%E6%80%81%E5%8A%A8%E4%BD%9C%E9%87%8D%E9%87%87%E6%A0%B7%E4%BB%A5%E6%8F%90%E9%AB%98%E7%BC%96%E7%A0%81%E6%99%BA%E8%83%BD%E4%BD%93%E6%80%A7%E8%83%BD/" title="读paper21-通过自适应树遍历进行动态动作重采样以提高编码智能体性能"><img src="/img/cover/12.jpg" onerror='this.onerror=null,this.src="/img/404.webp"' alt="读paper21-通过自适应树遍历进行动态动作重采样以提高编码智能体性能"></a><div class="content"><a class="title" href="/posts/Graduate-Works/Paper-Read/%E8%AF%BBpaper21-%E9%80%9A%E8%BF%87%E8%87%AA%E9%80%82%E5%BA%94%E6%A0%91%E9%81%8D%E5%8E%86%E8%BF%9B%E8%A1%8C%E5%8A%A8%E6%80%81%E5%8A%A8%E4%BD%9C%E9%87%8D%E9%87%87%E6%A0%B7%E4%BB%A5%E6%8F%90%E9%AB%98%E7%BC%96%E7%A0%81%E6%99%BA%E8%83%BD%E4%BD%93%E6%80%A7%E8%83%BD/" title="读paper21-通过自适应树遍历进行动态动作重采样以提高编码智能体性能">读paper21-通过自适应树遍历进行动态动作重采样以提高编码智能体性能</a><time datetime="2025-05-18T07:12:34.000Z" title="发表于 2025-05-18 15:12:34">2025-05-18</time></div></div></div></div></div></div></main><footer id="footer" style="background:0 0"></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">简</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span> 数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"></div></div><hr><div class="no-result" id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div><div class="js-pjax" id="rightMenu"><div class="rightMenu-group rightMenu-small"><a class="rightMenu-item" href="javascript:window.history.back();" rel="external nofollow noreferrer"><i class="fa fa-arrow-left"></i></a><a class="rightMenu-item" href="javascript:window.history.forward();" rel="external nofollow noreferrer"><i class="fa fa-arrow-right"></i></a><a class="rightMenu-item" href="javascript:window.location.reload();" rel="external nofollow noreferrer"><i class="fa fa-refresh"></i></a><a class="rightMenu-item" href="javascript:rmf.scrollToTop();" rel="external nofollow noreferrer"><i class="fa fa-arrow-up"></i></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-text"><a class="rightMenu-item" href="javascript:rmf.copySelect();" rel="external nofollow noreferrer"><i class="fa fa-copy"></i><span>复制</span></a><a class="rightMenu-item" href="javascript:window.open(&quot;https://www.google.com/search?q=&quot;+window.getSelection().toString());" rel="external nofollow noreferrer"><i class="iconfont icon-baidu"></i><span>搜索</span></a><a class="rightMenu-item" href="javascript:rmf.searchinThisPage();" rel="external nofollow noreferrer"><i class="fas fa-search"></i><span>站内搜索</span></a><a class="rightMenu-item" href="#post-comment" onclick="rmf.yinyong()"><i class="fa-solid fa-message"></i><span>引用文本评论</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-too"><a class="rightMenu-item" href="javascript:window.open(window.getSelection().toString());window.location.reload();" rel="external nofollow noreferrer"><i class="fa fa-link"></i><span>转到链接</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-paste"><a class="rightMenu-item" href="javascript:rmf.paste()" rel="external nofollow noreferrer"><i class="fa fa-copy"></i><span>粘贴</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-to"><a class="rightMenu-item" href="javascript:rmf.openWithNewTab()" rel="external nofollow noreferrer"><i class="fa fa-window-restore"></i><span>新窗口打开</span></a><a class="rightMenu-item" id="menu-too" href="javascript:rmf.open()" rel="external nofollow noreferrer"><i class="fa fa-link"></i><span>转到链接</span></a><a class="rightMenu-item" href="javascript:rmf.copyLink()" rel="external nofollow noreferrer"><i class="fa fa-copy"></i><span>复制链接</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-img"><a class="rightMenu-item" href="javascript:rmf.saveAs()" rel="external nofollow noreferrer"><i class="fa fa-download"></i><span>保存图片</span></a><a class="rightMenu-item" href="javascript:rmf.openWithNewTab()" rel="external nofollow noreferrer"><i class="fa fa-window-restore"></i><span>在新窗口打开</span></a><a class="rightMenu-item" href="javascript:rmf.click()" rel="external nofollow noreferrer"><i class="fa fa-arrows-alt"></i><span>全屏显示</span></a><a class="rightMenu-item" href="javascript:rmf.copyLink()" rel="external nofollow noreferrer"><i class="fa fa-copy"></i><span>复制图片链接</span></a></div><div class="rightMenu-group rightMenu-line"><a class="rightMenu-item" href="javascript:rmf.switchDarkMode();" rel="external nofollow noreferrer"><i class="fa fa-moon"></i><span>昼夜切换</span></a><a class="rightMenu-item" href="javascript:rmf.translate();" rel="external nofollow noreferrer"><i class="iconfont icon-fanti"></i><span>繁简转换</span></a><a class="rightMenu-item" href="javascript:rmf.switchReadMode();" rel="external nofollow noreferrer"><i class="fa fa-book"></i><span>阅读模式</span></a><a class="rightMenu-item" href="javascript:fullScreen();" rel="external nofollow noreferrer"><i class="fas fa-expand"></i><span>进入全屏</span></a></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://unpkg.com/@fancyapps/ui/dist/fancybox/fancybox.umd.js"></script><script>function panguFn(){"object"==typeof pangu?pangu.autoSpacingPage():getScript("https://unpkg.com/pangu/dist/browser/pangu.min.js").then(()=>{pangu.autoSpacingPage()})}function panguInit(){GLOBAL_CONFIG_SITE.isPost&&panguFn()}document.addEventListener("DOMContentLoaded",panguInit)</script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://unpkg.com/katex/dist/katex.min.css"><script src="https://unpkg.com/katex/dist/contrib/copy-tex.min.js"></script><script>document.querySelectorAll("#article-container span.katex-display").forEach(a=>{btf.wrap(a,"div",{class:"katex-wrap"})})</script><script>function getGiscusTheme(e){return"dark"===e?"dark":"light"}function loadGiscus(){var e,t=Object.assign({src:"https://giscus.app/client.js","data-repo":"ZWN2001/ZWN2001.github.io","data-repo-id":"R_kgDOGH1XWg","data-category-id":"DIC_kwDOGH1XWs4CXnHJ","data-mapping":"pathname","data-theme":getGiscusTheme(document.documentElement.getAttribute("data-theme")),"data-reactions-enabled":"1",crossorigin:"anonymous",async:!0},{"data-lang":"zh-CN","data-loading":"lazy",crossorigin:"anonymous","data-mapping":"og:title","data-input-position":"top","data-category":"Announcements"}),a=document.createElement("script");for(e in t)a.setAttribute(e,t[e]);document.getElementById("giscus-wrap").insertAdjacentElement("afterbegin",a)}function changeGiscusTheme(e){var t;e={setConfig:{theme:getGiscusTheme(e)}},(t=document.querySelector("iframe.giscus-frame"))&&t.contentWindow.postMessage({giscus:e},"https://giscus.app")}function loadOtherComment(){loadGiscus()}btf.addModeChange("giscus",changeGiscusTheme),btf.loadComment(document.getElementById("giscus-wrap"),loadGiscus)</script></div><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.7.1/jquery.min.js"></script><script type="text/javascript" src="/js/rightmenu.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span> 数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"></div></div><hr><div class="no-result" id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div><script data-pjax>var parent,child;document.getElementById("recent-posts")&&"/"===location.pathname&&(parent=document.getElementById("recent-posts"),child='<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="https://zwn2001.space/categories/编程知识/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📚 琉璃月の编程知识 (13)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://zwn2001.space/categories/实用知识/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">💡 琉璃月の实用知识 (10)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://zwn2001.space/categories/学习-课外拓展/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">👩‍💻 琉璃月の学习-课外拓展 (39)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://zwn2001.space/categories/学习-课内知识/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📒 琉璃月の学习-课内知识 (59)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><a class="magnet_link_more"  href="https://zwn2001.space/categories" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>',console.log("已挂载magnet"),parent.insertAdjacentHTML("afterbegin",child))</script><style>#catalog_magnet{flex-wrap:wrap;display:flex;width:100%;justify-content:space-between;padding:10px 10px 0 10px;align-content:flex-start}.magnet_item{flex-basis:calc(50% - 5px);background:#f2f2f2;margin-bottom:10px;border-radius:8px;transition:all .2s ease-in-out}.magnet_item:hover{background:#b30070}.magnet_link_more{color:#555}.magnet_link{color:#000}.magnet_link:hover{color:#fff}@media screen and (max-width:600px){.magnet_item{flex-basis:100%}}.magnet_link_context{display:flex;padding:10px;font-size:16px;transition:all .2s ease-in-out}.magnet_link_context:hover{padding:10px 20px}</style><style></style></body></html>