<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover"><title>读paper1-针对DL的缺陷分类与修复 | ZWN's blog</title><meta name="author" content="琉璃月"><meta name="copyright" content="琉璃月"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="读paper1-针对DL的缺陷分类与修复 缺陷分类：An Empirical Study on TensorFlow Program Bugs 与传统程序的比较 与传统应用程序的编程范式相比，DL应用程序的编程范式存在显著差异。在传统应用程序中，程序是直接编写解决目标问题的模型。 然而，DL应用程序的程序并不直接编码问题解决模型。相反，DL应用程序的程序编码了一个理想的DL模型的网络结构，以及利用"><meta property="og:type" content="article"><meta property="og:title" content="读paper1-针对DL的缺陷分类与修复"><meta property="og:url" content="https://zwn2001.space/posts/Graduate-Works/Paper-Read/%E8%AF%BBpaper1-%E9%92%88%E5%AF%B9DL%E7%9A%84%E7%BC%BA%E9%99%B7%E5%88%86%E7%B1%BB%E4%B8%8E%E4%BF%AE%E5%A4%8D/index.html"><meta property="og:site_name" content="ZWN&#39;s blog"><meta property="og:description" content="读paper1-针对DL的缺陷分类与修复 缺陷分类：An Empirical Study on TensorFlow Program Bugs 与传统程序的比较 与传统应用程序的编程范式相比，DL应用程序的编程范式存在显著差异。在传统应用程序中，程序是直接编写解决目标问题的模型。 然而，DL应用程序的程序并不直接编码问题解决模型。相反，DL应用程序的程序编码了一个理想的DL模型的网络结构，以及利用"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://zwn2001.space/img/cover/39.jpg"><meta property="article:published_time" content="2024-05-26T10:06:30.000Z"><meta property="article:modified_time" content="2024-10-30T10:05:00.295Z"><meta property="article:author" content="琉璃月"><meta property="article:tag" content="论文"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://zwn2001.space/img/cover/39.jpg"><link rel="shortcut icon" href="/img/favicon.webp"><link rel="canonical" href="https://zwn2001.space/posts/Graduate-Works/Paper-Read/%E8%AF%BBpaper1-%E9%92%88%E5%AF%B9DL%E7%9A%84%E7%BC%BA%E9%99%B7%E5%88%86%E7%B1%BB%E4%B8%8E%E4%BF%AE%E5%A4%8D/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://unpkg.com/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://unpkg.com/@fancyapps/ui/dist/fancybox/fancybox.css" media="print" onload='this.media="all"'><script>const GLOBAL_CONFIG={root:"/",algolia:void 0,localSearch:{path:"/search.xml",preload:!0,top_n_per_article:-1,unescape:!1,languages:{hits_empty:"找不到您查询的内容：${query}",hits_stats:"共找到 ${hits} 篇文章"}},translate:{defaultEncoding:2,translateDelay:0,msgToTraditionalChinese:"繁",msgToSimplifiedChinese:"简"},noticeOutdate:{limitDay:200,position:"top",messagePrev:"距离上次更新已经过去",messageNext:"天啦！注意内容可能过时。"},highlight:{plugin:"highlighjs",highlightCopy:!0,highlightLang:!0,highlightHeightLimit:300},copy:{success:"复制成功",error:"复制错误",noSupport:"浏览器不支持"},relativeDate:{homepage:!1,post:!1},runtime:"天",dateSuffix:{just:"刚刚",min:"分钟前",hour:"小时前",day:"天前",month:"个月前"},copyright:void 0,lightbox:"fancybox",Snackbar:void 0,source:{justifiedGallery:{js:"https://unpkg.com/flickr-justified-gallery/dist/fjGallery.min.js",css:"https://unpkg.com/flickr-justified-gallery/dist/fjGallery.css"}},isPhotoFigcaption:!0,islazyload:!1,isAnchor:!0,percent:{toc:!0,rightside:!0},autoDarkmode:!1}</script><script id="config-diff">var GLOBAL_CONFIG_SITE={title:"读paper1-针对DL的缺陷分类与修复",isPost:!0,isHome:!1,isHighlightShrink:!1,isToc:!0,postUpdate:"2024-10-30 18:05:00"}</script><noscript><style type="text/css">#nav{opacity:1}.justified-gallery img{opacity:1}#post-meta time,#recent-posts time{display:inline!important}</style></noscript><script>(e=>{e.saveToLocal={set:function(e,t,a){0!==a&&(a=864e5*a,t={value:t,expiry:(new Date).getTime()+a},localStorage.setItem(e,JSON.stringify(t)))},get:function(e){var t=localStorage.getItem(e);if(t){t=JSON.parse(t);if(!((new Date).getTime()>t.expiry))return t.value;localStorage.removeItem(e)}}},e.getScript=o=>new Promise((t,e)=>{const a=document.createElement("script");a.src=o,a.async=!0,a.onerror=e,a.onload=a.onreadystatechange=function(){var e=this.readyState;e&&"loaded"!==e&&"complete"!==e||(a.onload=a.onreadystatechange=null,t())},document.head.appendChild(a)}),e.getCSS=(o,n=!1)=>new Promise((t,e)=>{const a=document.createElement("link");a.rel="stylesheet",a.href=o,n&&(a.id=n),a.onerror=e,a.onload=a.onreadystatechange=function(){var e=this.readyState;e&&"loaded"!==e&&"complete"!==e||(a.onload=a.onreadystatechange=null,t())},document.head.appendChild(a)}),e.activateDarkMode=function(){document.documentElement.setAttribute("data-theme","dark"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#0d0d0d")},e.activateLightMode=function(){document.documentElement.setAttribute("data-theme","light"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","ffffff")};e=saveToLocal.get("theme"),"dark"===e?activateDarkMode():"light"===e&&activateLightMode(),e=saveToLocal.get("aside-status");void 0!==e&&("hide"===e?document.documentElement.classList.add("hide-aside"):document.documentElement.classList.remove("hide-aside"));/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)&&document.documentElement.classList.add("apple")})(window)</script><link rel="stylesheet" href="/css/transpancy.css"><link rel="stylesheet" href="/css/iconfont.css"><link rel="stylesheet" href="/css/rightmenu.css"><link rel="stylesheet" href="/css/loadimg.css"><link rel="stylesheet" href="/css/project.css"><link type="text/html" rel="stylesheet" href="/css/wide_screen.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-double-row-display@1.00/cardlistpost.min.css"><style>#recent-posts>.recent-post-item>.recent-post-info>.article-meta-wrap>.tags:before{content:"\A";white-space:pre}#recent-posts>.recent-post-item>.recent-post-info>.article-meta-wrap>.tags>.article-meta__separator{display:none}</style><meta name="generator" content="Hexo 5.4.0"></head><body><div id="loading-box" onclick="document.getElementById(&quot;loading-box&quot;).classList.add(&quot;loaded&quot;)"><div class="loading-bg"><img class="loading-img nolazyload" src="/img/favicon.webp"><div class="loading-image-dot"></div><div id="loading-percentage"></div></div></div><script>const loadingPercentage=document.getElementById("loading-percentage");loadingPercentage.style.color="black";let loadingPercentageTimer=setInterval(function(){var e=document.querySelector(".pace-progress");e&&(e=e.getAttribute("data-progress-text"))!==loadingPercentage.textContent&&"60%"===(loadingPercentage.textContent=e)&&clearInterval(loadingPercentageTimer)},100);const preloader={endLoading:()=>{document.body.style.overflow="auto",document.getElementById("loading-box").classList.add("loaded")},initLoading:()=>{document.body.style.overflow="",document.getElementById("loading-box").classList.remove("loaded")}};window.addEventListener("load",()=>{preloader.endLoading()})</script><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/favicon.webp" onerror='onerror=null,src="/img/friend_404.gif"' alt="avatar"></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">160</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">51</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">9</div></a></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image:url(/img/cover/39.jpg)"><nav id="nav"><span id="blog-info"><a href="/" title="ZWN's blog"><span class="site-name">ZWN's blog</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);" rel="external nofollow noreferrer"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);" rel="external nofollow noreferrer"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">读paper1-针对DL的缺陷分类与修复</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-05-26T10:06:30.000Z" title="发表于 2024-05-26 18:06:30">2024-05-26</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-10-30T10:05:00.295Z" title="更新于 2024-10-30 18:05:00">2024-10-30</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E7%A0%94%E7%A9%B6%E7%94%9F%E5%B7%A5%E4%BD%9C/">研究生工作</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">5.8k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>17分钟</span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1>读paper1-针对DL的缺陷分类与修复</h1><h2 id="缺陷分类：An-Empirical-Study-on-TensorFlow-Program-Bugs">缺陷分类：An Empirical Study on TensorFlow Program Bugs</h2><h3 id="与传统程序的比较">与传统程序的比较</h3><p>与传统应用程序的编程范式相比，DL应用程序的编程范式存在显著差异。在传统应用程序中，程序是直接编写解决目标问题的模型。</p><p>然而，DL应用程序的程序并不直接编码问题解决模型。相反，DL应用程序的程序编码了一个理想的DL模型的网络结构，以及利用大量数据进行训练的过程。网络结构和训练过程都需仔细设置超参数。DL应用程序的开发往往面临着开发传统应用程序中很少遇到的任务，例如配置由节点层组成的复杂网络结构（也称为计算图）。此外，训练过程包含着依赖于超参数调整的计算密集型循环，如学习率和丢弃率的调整。</p><h3 id="出现Bug的几个原因">出现Bug的几个原因</h3><ul><li><p>错误的模型参数或结构（IPS）</p><ul><li>不恰当的模型参数（如学习率）或错误的模型结构（如缺失节点或层）</li><li>或者说是模型本身就是有问题或者是将模型编码为代码时出现错误（比如少打了一个参数或者忘记平方）</li></ul></li><li><p>不对齐的张量（UT）</p><ul><li>输入张量的形状与预期的形状不匹配</li></ul></li><li><p>与TensorFlow计算模型的混淆（CCM）</p><ul><li>当TensorFlow用户不熟悉TensorFlow所假设的底层计算模型时，就会出现错误。这种类型错误的主要症状是准确度和损失结果不佳，被归类为“低效性”。当TensorFlow用户在TensorFlow计算语义上出现混淆时，程序不会编码一个有效的深度学习模型。因此，基于无效深度学习模型的训练过程是不有效的，即使它不一定会导致TensorFlow错误。</li></ul></li><li><p>TF API的改变（APIC）</p><ul><li>老API被弃用或者迁移到新API造成的问题</li></ul></li><li><p>TF API的误用（APIM）</p></li><li><p>结构低效（SI）</p><ul><li>SI和IPS之间的主要区别在于，SI会导致性能低效，而IPS会导致功能上的错误。</li></ul></li></ul><p> </p><h3 id="Bug之外的新挑战-错误检测（有的Bug并不导致崩溃）">Bug之外的新挑战-错误检测（有的Bug并不导致崩溃）</h3><p>在该文的工作中，46.9% 的bug总是导致程序崩溃并且一定能够被检测到。作者在检测其余53.1%的bug时，总结了三个新的挑战。</p><h4 id="概率性正确性。">概率性正确性。</h4><p>由于DL本身就是黑盒以及模型并不能做到100%准确，导致在出现错误的结果时很难确定是模型的低效（没有很好的进行学习）还是出现bug。基于此作者提出了几个解决策略：</p><ul><li><p>使用固定阈值比较整体准确度和损失。</p><ul><li>当训练模型在训练集或测试集上无法达到预期的准确度或损失时，认为模型存在 bug。</li><li>或者说，我们认为模型学习率很低时与存在Bug无异。</li><li>问题在于，模型的训练可能花费很长时间，导致这个过程很低效。</li></ul></li><li><p>比较迭代中准确度和损失的相对变化。</p><ul><li>预期准确度在迭代过程中呈增长趋势，而损失预期呈下降趋势。如果在多个迭代中没有观察到明显的增长或下降趋势，TF 用户将认为模型存在错误。</li><li>问题在于，这些挑战和策略需要新的测试技术和框架。首先，大多数测试框架不支持统计正确性，需要开发确定统计正确性的机制。其次，传统的测试生成技术是为了绝对正确性而设计的，如何高效地触发具有统计正确性特征的错误尚不清楚。第三，统计正确性只是概率正确性的近似，但如何衡量置信度尚不明确。可以开发新的理论来衡量测试 TensorFlow 程序的置信度。</li></ul></li></ul><h4 id="巧合的正确性。">巧合的正确性。</h4><p>虽然在训练过程中触发了错误，但训练模型在测试集上仍然达到了理想的准确度和损失。这些错误最终是通过代码审查发现的。</p><p>TF 程序的计算是由张量驱动的，这些张量通常由具有大尺寸的多维数组建模。经过多次计算迭代后，数组中个别元素的值对最终分类结果（例如汽车前方是否有障碍物）的影响较小。此外，大多数计算采用非线性激活函数，其输出对某些输入范围不敏感。因此，计算错误更有可能对最终结果产生不可观察的影响。换句话说，<strong>TF 程序对计算错误更具容忍性</strong>。因此，与传统对应程序相比，<strong>TF 程序的巧合正确性发生的规模更大</strong>。</p><h4 id="随机执行。">随机执行。</h4><p>由于训练阶段的随机性质，可能会出现两次执行表现不同的情况，这使得复现错误变得困难。</p><p>许多传统程序也具有非确定性，然而，在 TF 应用中，这个问题更加严重，因为几乎任何执行都受到非确定性的影响。需要进行更多研究来处理 TF 应用中的非确定性问题。</p><p> </p><h3 id="Bug定位的挑战">Bug定位的挑战</h3><p>作者认为，在<strong>构建阶段</strong>引发错误时，bug通常可以确定地定位。在这种情况下，跟踪依赖距离较短，相比于涉及大量迭代和概率计算的执行阶段中的依赖距离。此外，错误消息中嵌入的信息可以帮助定位bug。可以通过从错误消息提供的有问题的语句反向跟踪依赖来检查程序。</p><p>而当故障执行涉及到<strong>执行阶段</strong>时，错误行为变得随机，导致故障定位工作量的大幅增加。与传统程序相比，作者确定了在定位这些bug时面临的两个主要挑战。</p><h4 id="高度相互依赖的神经网络。">高度相互依赖的神经网络。</h4><p>传统程序中的元素/模块的耦合度往往很低。如果我们从发生错误或产生不正确输出的地方进行动态切片，切片结果通常只包含程序中的一小部分编码实体。</p><p>然而，在神经网络中，当前层中的节点通常高度依赖于上一层的节点。此外，在训练阶段，由于反向传播，依赖关系变得双向。因此，切片在提供帮助方面很有限，切片通常包含神经网络中所有节点，对调试没有帮助。</p><h4 id="神经网络行为的不确定性">神经网络行为的不确定性</h4><p>调试传统程序的一种典型方法是通过比较变量的值和它们的期望值来检查特定程序点上的程序状态。然而，在神经网络中，由于程序行为对训练过程中赋予的超参数很敏感，程序员很难预测某一特定程序点的期望值。因此，尽管可以在训练过程中访问神经网络的中间状态，但往往很难根据这些状态来判断其正确性。</p><p>同时，作者也列举了三个常用的Bug定位策略：</p><ul><li>超参数替换</li><li>检查变量值的分布</li><li>切换训练数据集</li></ul><p> </p><h2 id="缺陷分类：A-Comprehensive-Study-on-Deep-Learning-Bug-Characteristics">缺陷分类：A Comprehensive Study on Deep Learning Bug Characteristics</h2><p>该文指出，<strong>数据Bug和逻辑Bug</strong>是深度学习软件中最严重的Bug类型，出现频率超过48%，这些Bug的主要根本原因是<strong>模型参数不正确</strong>（IPS）和<strong>结构效率低下</strong>（SI），出现频率超过43%。作者还发现，在使用深度学习库时存在一些常见的<strong>反模式</strong>。研究结果显示，bug的分布与反模式之间存在很强的相关性。</p><p>该文对缺陷的分类与上一文类似。在分类中，作者关注三个准则，即bug类型、根本原因和bug的影响</p><h3 id="深度学习软件中的缺陷的类型">深度学习软件中的缺陷的类型</h3><ul><li>API 缺陷：即由DL框架的API引发的Bug</li><li>编码缺陷：编码错误造成的Bug</li><li>数据缺陷：数据集格式问题/脏数据</li><li>结构性缺陷：大部分深度学习bug是由于深度学习模型结构的不正确定义而导致的。这包括深度学习模型不同层之间的维度不匹配、训练和测试数据集之间存在异常、在实现特定函数时使用了不正确的数据结构等。进一步细分：<ul><li>控制流和序列化的缺陷。</li><li>数据流缺陷。</li><li>初始化缺陷。</li><li>逻辑缺陷。</li><li>处理策略缺陷</li></ul></li><li>非模型结构性缺陷：也就是说在模型建模之外的缺陷</li></ul><h3 id="根据缺陷的根本原因进行分类">根据缺陷的根本原因进行分类</h3><ul><li>缺乏类型检查</li><li>API的修改</li><li>API误用</li><li>计算模型的混淆。</li><li>错误的模型参数或结构</li><li>其他：一些开发过程中的错误（如语法错误）</li><li>结构低效（SI）</li><li>不对齐的张量（UT）</li><li>错误的文档</li></ul><p>作者还将这些bug分类到深度学习流程的不同阶段，以了解哪些阶段更容易受到bug的影响。</p><h3 id="根据缺陷的影响进行分类">根据缺陷的影响进行分类</h3><ul><li>模型表现不佳（性能差</li><li>崩溃</li><li>数据损坏</li><li>卡死</li><li>功能错误</li><li>内存越界</li></ul><blockquote><p>同时，根据作者的收集情况，作者给出了如下几个发现：（感觉不是很重要）</p><ul><li><p>从缺陷的出现频率来看：</p><ul><li>数据错误出现的频率超过26％</li><li>Caffe 有更多的结构逻辑错误</li><li>Torch、Keras和Tensorflow分别具有16%、11%和11%的API错误</li><li>所有的 bug 类型在 Github 和 Stack Overflow 中对于所有的库都有类似的模式</li></ul></li><li><p>从缺陷出现的根本原因来看：</p><ul><li>IPS是导致 bug 最常见的根本原因，平均约占 bug 的 24%。IPS 导致的 bug 会在运行时使程序崩溃，执行失败。</li><li>Keras和Caffe中有25%和37%的bug源自结构效率不佳(SI)。SI类型的bug不会导致程序崩溃，而是经常导致深度学习模型性能不佳。这些bug与质量服务(QoS)或非功能性需求有更多关联。</li><li>Torch中28%的bug是由于未对齐的Tensor（UT）引起的。</li><li>Theano中30%的错误是由于缺乏类型检查</li><li>Tensorflow 和 Kera 有9% 和7% 的 bug是由于API的改变</li><li>除了 API 滥误用所有其他根本原因在 Github 和 Stack Overflow 中都有类似的模式，这是 bug 的根本原因（与上一点钟的第四条对应的）</li><li>SI 贡献了3% -53% ，IPS 贡献了24% -62% 的模型相关错误</li></ul></li><li><p>从缺陷导致的影响来看：</p><ul><li>超过66％的缺陷导致崩溃。</li><li>在Caffe、Keras、Tensorflow、Theano和Torch中，31%、16%、8%、11%和8%的错误导致了性能不佳</li><li>12％的错误导致功能不正确</li><li>对于所有的库来说，Stack Overflow 和 Github bug 效应的 P 值拒绝了 null 假设，以确认这些 bug 与 Stack Overflow 和 Github bug 具有相似的效果（没看懂这个）</li></ul></li><li><p>从深度学习的不同学习阶段来看：</p><ul><li>32%的缺陷出现在数据准备阶段</li><li>27%出现在训练阶段</li><li>23%出现在模型选择阶段</li></ul></li><li><p>缺陷的一些共性：Tensorflow 和 Kera 具有相似的反模式分布，而 Torch 具有不同的反模式分布</p></li><li><p>缺陷的演变：结构缺陷在增加、数据缺陷在减少</p></li></ul></blockquote><p>作者认为开发数据验证工具可以帮助程序员解决大量的数据bug。由于深度学习模型与数据密切相关，因此开发模型分析工具来探索特定模型是否适合手头的数据，可以帮助解决数据和模型相关问题的耦合性。</p><p>同时作者认为，结构逻辑缺陷这类问题可以通过一些自动化的模型和参数推荐工具来解决。如何开发这类工具需要进一步的研究。一种方法是使用Python数据集挖掘大规模的开源代码库，识别最常见的代码模式，并从常见的代码模式中提供示例。</p><p> </p><h2 id="缺陷（修复）分类：Repairing-Deep-Neural-Networks-Fix-Patterns-and-Challenges">缺陷（修复）分类：Repairing Deep Neural Networks Fix Patterns and Challenges</h2><p>由于修复使用DNN的软件是一个明显的SE需求，自动化工具可能非常有帮助，因此充分了解修复DNN中的错误时的挑战和使用的模式是至关重要的。自动修复工具应该解决哪些挑战？哪些修复模式可以帮助开发人员自动化修复？哪些修复模式应该优先考虑？</p><p>该研究发现，与传统的错误修复模式相比，DNN的错误修复模式是独特的；最常见的错误修复模式是修复数据尺寸和网络连接；DNN错误修复有可能引入对抗性漏洞；DNN错误修复经常引入新的错误；当修复错误时，DNN错误定位、训练模型的重复使用和应对频繁发布是开发人员面临的主要挑战。</p><h3 id="缺陷修复范式分类">缺陷修复范式分类</h3><ul><li>损失函数：在训练过程中添加、删除或更新损失函数</li><li>改变DNN中节点之间的连接</li><li>增加中间层（隐藏层）</li><li>数据维度：将DNN的输入维度与数据维度对齐</li><li>准确度指标：针对不同类型的问题选用不同指标进行评估，使得指标能更好的描述模型的效能</li><li>选用正确的数据类型</li><li>调整激活函数</li><li>调整训练过程运行的次数</li><li>版本相关：正确的版本，正确的API使用</li><li>Data Wrangling. （数据清洗？）</li><li>训练过程中进行监控：并不修复代码中的缺陷，但有助于定位错误</li><li>优化算法进行优化</li><li>改变神经结构</li></ul><h3 id="深度神经网络中最常见的错误修复模式">深度神经网络中最常见的错误修复模式</h3><ul><li><p>针对数据维度</p><ul><li>修复数据维度是最常见的错误修复模式（占18.8%），可能影响DNN模型的稳健性。</li><li>（<strong>Resize</strong>，调整输入数据的大小）在Stack Overflow中，63%与调整大小相关的帖子利用了降采样/降维？（downscaling）的方法，这可能会降低DNN的稳健性。</li><li>（<strong>Reshape</strong>，输入向量的形状发生变化时进行重塑；<strong>Reorder</strong>，重排）在Stack Overflow中，重排和重塑（79.7％的数据维度修复）需要对DNN层的规格以及库有一定的了解。</li></ul></li><li><p>针对层次维度</p><ul><li>在GitHub上，15.6%的修复操作是针对与层维度相关的错误（75.9%的崩溃错误）进行的。</li><li>这些修复操作通常包括<strong>根据相邻层的结构进行维度的减少或添加</strong>。然而，这些修复操作可以通过改变数据维度以使其与层维度匹配。可能出现维度灾难。</li></ul></li><li><p>版本相关修复</p><ul><li>在GitHub上，版本相关的bug修复占比最高（17.6%）</li></ul></li><li><p>针对神经网络连接的修复</p><ul><li>网络连接是在Stack Overflow（17.8％）和GitHub（14.1％）中普遍出现的修复方法，用于修复崩溃（57.14％），功能不正确（16.19％）和性能不佳（12.38％）的问题。</li><li>合并层</li><li>添加反馈循环和输入层</li><li>迁移学习</li></ul></li><li><p>增加层：但是可能增加训练时间</p></li><li><p>针对损失函数：添加或修正</p></li></ul><p>作者提及了通过缺陷类型、库进行修复，但同时，现有的很多缺陷修复引入了新缺陷</p><h3 id="修复DNN-Bug的主要挑战">修复DNN Bug的主要挑战</h3><ul><li>Bug定位：由于错误与其原因之间的复杂关系，定位Bug特别具有挑战性。</li><li>频繁发布：DNN库（尤其是TensorFlow）的快速发布周期导致了高维护负担，特别是由于频繁的向后不兼容更改。</li><li>模型重用：在重用预训练模型时，开发者常常面临与新应用程序意图不匹配的问题，导致模型过拟合或引入偏差。</li></ul><p> </p><h2 id="总结">总结</h2><p>前两篇给出了几个主要原因：</p><ul><li>错误的模型参数或结构</li><li>不对齐的张量</li><li>API的改变（不同版本）与API的误用（misuse）</li><li>数据缺陷：数据集格式问题/脏数据</li><li>结构性缺陷</li><li>编码缺陷：编码错误造成的Bug</li></ul><p>第三篇针对缺陷的一些主要原因，如模型问题、结构性问题、API问题以及数据集问题给出了相应的一些解决方案</p><h2 id="缺陷检测：DeepDiagnosis-Automatically-Diagnosing-Faults-and-Recommending-Actionable-Fixes-in-Deep-Learning-Programs">缺陷检测：DeepDiagnosis: Automatically Diagnosing Faults and Recommending Actionable Fixes in Deep Learning Programs</h2><p>针对DNN的缺陷定位与修复</p><p>作者总结了先前工作的8种常见缺陷：</p><ul><li><p>死节点</p><ul><li>学习率过高/过低（过拟合/欠拟合）。</li><li>存在较大的负偏差</li><li>权重或偏差初始化不当。</li></ul></li><li><p>饱和激活</p><ul><li>输入数据过大或过小；</li><li>权重或偏置初始化不当；</li><li>学习率过高或过低。</li></ul></li><li><p>数值爆炸（Exploding Tensor</p><ul><li>学习率过大；</li><li>权重或偏差初始化不当，或者输入数据不当</li></ul></li><li><p>准确率不增加 &amp; Loss没有减少</p><ul><li>存在不适当的训练数据；</li><li>层数过多/过少；</li><li>学习率过高/过低；</li><li>存在不正确的激活函数</li></ul></li><li><p>不变的权重（随着模型学习/训练</p><ul><li>学习率非常低；</li><li>优化器选择不正确；</li><li>存在错误的权重初始化；</li><li>最后一层存在错误的损失函数/激活函数</li></ul></li><li><p>梯度爆炸</p><ul><li>学习率过高；</li><li>权重或偏置初始化不当；</li><li>数据输入存在问题；</li><li>batch size 非常大。</li></ul></li><li><p>梯度消失</p><ul><li>网络层数过多；</li><li>学习率过低；</li><li>隐藏层不适当地使用了Tanh或Sigmoid函数；</li><li>存在不正确的权重初始化问题</li></ul></li></ul><p><img src="3.png" alt=""></p><h3 id="缺陷检测算法">缺陷检测算法</h3><p>总的思路是根据不同的缺陷检测函数（针对上面提到的缺陷）返回缺陷检测结果（Table5中的内容），然后提供必要参数来调用决策树中的<code>Mapping()</code>函数（在图2中）。决策树将为模型返回最佳的可操作修复。</p><p>主要分为两个阶段：第一阶段是前向阶段，在此阶段算法执行动态分析和症状检测，包括数值错误、死节点、饱和激活和超出范围，在第4-12行。第二阶段是反向阶段，在此阶段算法执行动态分析以检测附加的症状，如数值错误、梯度消失和权重不变，在第23-28行。</p><ol><li><p><strong>初始化训练周期和数据批次</strong>：</p><ul><li>在所有训练周期中（从第0周期到最大周期<code>epochs</code>），对于每个输入数据批次（从第0到输入数据的长度，步长为批次大小<code>batchsize</code>），提取输入数据<code>X</code>和标签<code>Y</code>。</li></ul></li><li><p><strong>前向传播阶段</strong>：</p><ul><li>对于每一层，从第0层到网络层的长度：<ol><li>计算当前层的前向输出<code>V1</code>。</li><li>计算应用激活函数后的输出<code>V2</code>。</li><li>检测是否存在数值错误（Exploding Tensor），如果是，返回NS错误症状并调用<code>Mapping</code>函数进行故障定位。</li><li>检测是否存在未变化的权重（Unchanged Weight），如果是，返回UCS错误症状并调用<code>Mapping</code>函数进行故障定位。</li><li>检测是否存在饱和激活（Saturated Activation），如果是，返回SAS错误症状并调用<code>Mapping</code>函数进行故障定位。</li><li>检测是否存在死节点（Dead Node），如果是，返回DNS错误症状并调用<code>Mapping</code>函数进行故障定位。</li><li>检测是否存在超出范围的值（Out of Range），如果是，返回ORS错误症状并调用<code>Mapping</code>函数进行故障定位。</li><li>将当前层的输出<code>V2</code>作为下一层的输入<code>X</code>。</li></ol></li></ul></li><li><p><strong>计算损失和准确率</strong>：</p><ul><li>计算当前模型的损失值<code>Loss</code>和准确率<code>Accuracy</code>。</li><li>如果损失值是NaN或无穷大，返回ILS错误症状并调用<code>Mapping</code>函数进行故障定位。</li><li>如果准确率是NaN、无穷大或0，返回IAS错误症状并调用<code>Mapping</code>函数进行故障定位。</li><li>检查损失值是否未减少，如果是，返回LNDS错误症状并调用<code>Mapping</code>函数进行故障定位。</li><li>检查准确率是否未增加，如果是，返回ANIS错误症状并调用<code>Mapping</code>函数进行故障定位。</li></ul></li><li><p><strong>反向传播阶段</strong>：</p><ul><li>计算损失函数相对于权重的梯度（<code>dy</code>）。</li><li>对于每一层，从最后一层到第0层：<ol><li>计算当前层的反向传播输出<code>V3</code>和权重梯度<code>W</code>。</li><li>检测是否存在消失梯度（Vanishing Gradient），如果是，返回VGS错误症状并调用<code>Mapping</code>函数进行故障定位。</li><li>检测是否存在数值错误（Exploding Tensor），如果是，返回NS错误症状并调用<code>Mapping</code>函数进行故障定位。</li><li>检测是否存在未变化的权重（Unchanged Weight），如果是，返回UCS错误症状并调用<code>Mapping</code>函数进行故障定位。</li><li>将当前层的输出<code>V3</code>作为下一层的输入<code>dy</code>。</li></ol></li></ul></li><li><p><strong>完成训练</strong>：</p><ul><li>如果未检测到任何错误症状，算法返回正确模型（CM）。</li></ul></li></ol><p><img src="1.png" alt=""></p><h3 id="缺陷修复">缺陷修复</h3><p>上面提到决策树将为模型返回最佳的可操作修复。</p><p><img src="2.png" alt=""></p><p>每个规则根据失败症状和检测到的位置提供了可操作的更改。该树定义了一个将问题实例（症状、位置、层级）映射到七类更改之一的二进制分类规则（表4）。在决策树中，根节点代表问题，橙色节点代表症状，蓝色节点代表位置，灰色节点代表层级类型，绿色节点代表条件，红色节点代表可操作的更改。表3展示了计算条件的方法<code>Data()</code>、<code>Weight()</code>和<code>Learn()</code>。每个决策树实例将路径从根节点映射到叶节点之一。</p><p> </p><h2 id="缺陷检测：DeepLocalize-Fault-Localization-for-Deep-Neural-Networks">缺陷检测：DeepLocalize: Fault Localization for Deep Neural Networks</h2><p>研究引入了一种基于白盒的深度神经网络故障定位技术。给定源代码，实现对深度神经网络的动态跟踪收集。</p><p>该研究提出了两种技术。第一种将代码转换为深度神经网络的命令式表示形式。命令式表示的目的是确保深度神经网络的内部状态是可观测的，属于一种白盒方法。将代码转换为命令式表示形式使之能够插入探针，从而在深度神经网络在训练数据上进行训练时实现对生成轨迹的动态分析。第二种技术使用一种新颖的回调机制来插入探针，也达到了同样的目的。然后对生成轨迹进行动态分析，以识别导致错误的故障层或超参数。该研究还提出了一种算法，通过捕获任何数值错误并在训练过程中监视模型，找到每个层次/参数对深度神经网络结果的相关性，以确定根本原因。</p></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://zwn2001.space">琉璃月</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://zwn2001.space/posts/Graduate-Works/Paper-Read/%E8%AF%BBpaper1-%E9%92%88%E5%AF%B9DL%E7%9A%84%E7%BC%BA%E9%99%B7%E5%88%86%E7%B1%BB%E4%B8%8E%E4%BF%AE%E5%A4%8D/">https://zwn2001.space/posts/Graduate-Works/Paper-Read/%E8%AF%BBpaper1-%E9%92%88%E5%AF%B9DL%E7%9A%84%E7%BC%BA%E9%99%B7%E5%88%86%E7%B1%BB%E4%B8%8E%E4%BF%AE%E5%A4%8D/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="external nofollow noreferrer" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://zwn2001.space" target="_blank">ZWN's blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E8%AE%BA%E6%96%87/">论文</a></div><div class="post_share"><div class="social-share" data-image="/img/cover/39.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://unpkg.com/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload='this.media="all"'><script src="https://unpkg.com/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/posts/Graduate-Works/DL/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E6%B1%87%E7%BC%961-1%EF%BC%9A%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" title="吴恩达深度学习笔记汇编1-1：神经网络和深度学习"><img class="cover" src="/img/cover/1.jpg" onerror='onerror=null,src="/img/404.webp"' alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">吴恩达深度学习笔记汇编1-1：神经网络和深度学习</div></div></a></div><div class="next-post pull-right"><a href="/posts/Graduate-Works/Experiences/2024BUAA%E8%BD%AF%E9%99%A2%E4%B8%93%E7%A1%95%E8%80%83%E7%A0%94tips/" title="2024BUAA软院专硕考研tips"><img class="cover" src="/img/cover/44.jpg" onerror='onerror=null,src="/img/404.webp"' alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">2024BUAA软院专硕考研tips</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/posts/Graduate-Works/Paper-Read/%E8%AF%BBpaper7-RAP-Gen-Retrieval-Augmented-Patch-Generation-with-CodeT5/" title="读paper7-RAP-Gen_Retrieval_Augmented_Patch_Generation_with_CodeT5"><img class="cover" src="/img/cover/35.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-09-17</div><div class="title">读paper7-RAP-Gen_Retrieval_Augmented_Patch_Generation_with_CodeT5</div></div></a></div><div><a href="/posts/Graduate-Works/Paper-Read/%E8%AF%BBpaper5-%E5%9F%BA%E4%BA%8E%E5%9B%BE%E7%9A%84%E7%BC%BA%E9%99%B7%E6%A3%80%E6%B5%8B%E4%B8%8E%E4%BF%AE%E5%A4%8D%E4%B8%A4%E7%AF%87/" title="读paper5-基于图的缺陷检测与修复两篇"><img class="cover" src="/img/cover/53.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-09-04</div><div class="title">读paper5-基于图的缺陷检测与修复两篇</div></div></a></div><div><a href="/posts/Graduate-Works/Paper-Read/%E8%AF%BBpaper6-%E7%BC%BA%E9%99%B7%E6%A0%B7%E6%9C%AC%E7%94%9F%E6%88%90/" title="读paper6-缺陷样本生成"><img class="cover" src="/img/cover/23.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-09-05</div><div class="title">读paper6-缺陷样本生成</div></div></a></div><div><a href="/posts/Graduate-Works/Paper-Read/%E8%AF%BBpaper8-Copiloting-the-Copilots/" title="读paper8-Copiloting_the_Copilots"><img class="cover" src="/img/cover/21.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-09-18</div><div class="title">读paper8-Copiloting_the_Copilots</div></div></a></div><div><a href="/posts/Graduate-Works/Paper-Read/%E8%AF%BBpaper2-%E5%9F%BA%E4%BA%8ELLM%E7%9A%84%E7%BC%BA%E9%99%B7%E4%BF%AE%E5%A4%8D/" title="读paper2-基于LLM的缺陷修复"><img class="cover" src="/img/cover/10.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-08-09</div><div class="title">读paper2-基于LLM的缺陷修复</div></div></a></div><div><a href="/posts/Graduate-Works/Paper-Read/%E8%AF%BBpaper4-%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%85%A5%E6%89%8B%E4%B8%8E%E8%AE%BA%E6%96%87%E9%9B%86/" title="读paper4-多智能体强化学习入手与论文集"><img class="cover" src="/img/cover/46.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-08-21</div><div class="title">读paper4-多智能体强化学习入手与论文集</div></div></a></div></div></div><hr><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="giscus-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/favicon.webp" onerror='this.onerror=null,this.src="/img/friend_404.gif"' alt="avatar"></div><div class="author-info__name">琉璃月</div><div class="author-info__description">我虽无意逐鹿，却知苍生苦楚</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">160</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">51</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">9</div></a></div><a id="card-info-btn" target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/ZWN2001"><i class="fab fa-github"></i><span>我的Github</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/ZWN2001" rel="external nofollow noreferrer" target="_blank" title="Github"><i class="fab fa-github"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">新域名：www.zwn2001.space，有效期：10年。https://www.zwn-blog.xyz已过期。访问时建议科学上网，否则博客内公式渲染会出现问题且速度慢。Ctrl+shift+r可强制刷新网站以避免浏览器缓存造成的更新不及时</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">读paper1-针对DL的缺陷分类与修复</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BC%BA%E9%99%B7%E5%88%86%E7%B1%BB%EF%BC%9AAn-Empirical-Study-on-TensorFlow-Program-Bugs"><span class="toc-number">1.1.</span> <span class="toc-text">缺陷分类：An Empirical Study on TensorFlow Program Bugs</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%8E%E4%BC%A0%E7%BB%9F%E7%A8%8B%E5%BA%8F%E7%9A%84%E6%AF%94%E8%BE%83"><span class="toc-number">1.1.1.</span> <span class="toc-text">与传统程序的比较</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%87%BA%E7%8E%B0Bug%E7%9A%84%E5%87%A0%E4%B8%AA%E5%8E%9F%E5%9B%A0"><span class="toc-number">1.1.2.</span> <span class="toc-text">出现Bug的几个原因</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Bug%E4%B9%8B%E5%A4%96%E7%9A%84%E6%96%B0%E6%8C%91%E6%88%98-%E9%94%99%E8%AF%AF%E6%A3%80%E6%B5%8B%EF%BC%88%E6%9C%89%E7%9A%84Bug%E5%B9%B6%E4%B8%8D%E5%AF%BC%E8%87%B4%E5%B4%A9%E6%BA%83%EF%BC%89"><span class="toc-number">1.1.3.</span> <span class="toc-text">Bug之外的新挑战-错误检测（有的Bug并不导致崩溃）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A6%82%E7%8E%87%E6%80%A7%E6%AD%A3%E7%A1%AE%E6%80%A7%E3%80%82"><span class="toc-number">1.1.3.1.</span> <span class="toc-text">概率性正确性。</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B7%A7%E5%90%88%E7%9A%84%E6%AD%A3%E7%A1%AE%E6%80%A7%E3%80%82"><span class="toc-number">1.1.3.2.</span> <span class="toc-text">巧合的正确性。</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9A%8F%E6%9C%BA%E6%89%A7%E8%A1%8C%E3%80%82"><span class="toc-number">1.1.3.3.</span> <span class="toc-text">随机执行。</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Bug%E5%AE%9A%E4%BD%8D%E7%9A%84%E6%8C%91%E6%88%98"><span class="toc-number">1.1.4.</span> <span class="toc-text">Bug定位的挑战</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%AB%98%E5%BA%A6%E7%9B%B8%E4%BA%92%E4%BE%9D%E8%B5%96%E7%9A%84%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E3%80%82"><span class="toc-number">1.1.4.1.</span> <span class="toc-text">高度相互依赖的神经网络。</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%A1%8C%E4%B8%BA%E7%9A%84%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7"><span class="toc-number">1.1.4.2.</span> <span class="toc-text">神经网络行为的不确定性</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BC%BA%E9%99%B7%E5%88%86%E7%B1%BB%EF%BC%9AA-Comprehensive-Study-on-Deep-Learning-Bug-Characteristics"><span class="toc-number">1.2.</span> <span class="toc-text">缺陷分类：A Comprehensive Study on Deep Learning Bug Characteristics</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%BD%AF%E4%BB%B6%E4%B8%AD%E7%9A%84%E7%BC%BA%E9%99%B7%E7%9A%84%E7%B1%BB%E5%9E%8B"><span class="toc-number">1.2.1.</span> <span class="toc-text">深度学习软件中的缺陷的类型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A0%B9%E6%8D%AE%E7%BC%BA%E9%99%B7%E7%9A%84%E6%A0%B9%E6%9C%AC%E5%8E%9F%E5%9B%A0%E8%BF%9B%E8%A1%8C%E5%88%86%E7%B1%BB"><span class="toc-number">1.2.2.</span> <span class="toc-text">根据缺陷的根本原因进行分类</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A0%B9%E6%8D%AE%E7%BC%BA%E9%99%B7%E7%9A%84%E5%BD%B1%E5%93%8D%E8%BF%9B%E8%A1%8C%E5%88%86%E7%B1%BB"><span class="toc-number">1.2.3.</span> <span class="toc-text">根据缺陷的影响进行分类</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BC%BA%E9%99%B7%EF%BC%88%E4%BF%AE%E5%A4%8D%EF%BC%89%E5%88%86%E7%B1%BB%EF%BC%9ARepairing-Deep-Neural-Networks-Fix-Patterns-and-Challenges"><span class="toc-number">1.3.</span> <span class="toc-text">缺陷（修复）分类：Repairing Deep Neural Networks Fix Patterns and Challenges</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%BA%E9%99%B7%E4%BF%AE%E5%A4%8D%E8%8C%83%E5%BC%8F%E5%88%86%E7%B1%BB"><span class="toc-number">1.3.1.</span> <span class="toc-text">缺陷修复范式分类</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%AD%E6%9C%80%E5%B8%B8%E8%A7%81%E7%9A%84%E9%94%99%E8%AF%AF%E4%BF%AE%E5%A4%8D%E6%A8%A1%E5%BC%8F"><span class="toc-number">1.3.2.</span> <span class="toc-text">深度神经网络中最常见的错误修复模式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BF%AE%E5%A4%8DDNN-Bug%E7%9A%84%E4%B8%BB%E8%A6%81%E6%8C%91%E6%88%98"><span class="toc-number">1.3.3.</span> <span class="toc-text">修复DNN Bug的主要挑战</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">1.4.</span> <span class="toc-text">总结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BC%BA%E9%99%B7%E6%A3%80%E6%B5%8B%EF%BC%9ADeepDiagnosis-Automatically-Diagnosing-Faults-and-Recommending-Actionable-Fixes-in-Deep-Learning-Programs"><span class="toc-number">1.5.</span> <span class="toc-text">缺陷检测：DeepDiagnosis: Automatically Diagnosing Faults and Recommending Actionable Fixes in Deep Learning Programs</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%BA%E9%99%B7%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95"><span class="toc-number">1.5.1.</span> <span class="toc-text">缺陷检测算法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%BA%E9%99%B7%E4%BF%AE%E5%A4%8D"><span class="toc-number">1.5.2.</span> <span class="toc-text">缺陷修复</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BC%BA%E9%99%B7%E6%A3%80%E6%B5%8B%EF%BC%9ADeepLocalize-Fault-Localization-for-Deep-Neural-Networks"><span class="toc-number">1.6.</span> <span class="toc-text">缺陷检测：DeepLocalize: Fault Localization for Deep Neural Networks</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/posts/Graduate-Works/Course-Notes/%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97-%E7%89%87%E4%B8%8A%E5%A4%9A%E5%A4%84%E7%90%86%E5%99%A8/" title="并行计算-片上多处理器"><img src="/img/cover/27.jpg" onerror='this.onerror=null,this.src="/img/404.webp"' alt="并行计算-片上多处理器"></a><div class="content"><a class="title" href="/posts/Graduate-Works/Course-Notes/%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97-%E7%89%87%E4%B8%8A%E5%A4%9A%E5%A4%84%E7%90%86%E5%99%A8/" title="并行计算-片上多处理器">并行计算-片上多处理器</a><time datetime="2024-11-26T11:14:47.000Z" title="发表于 2024-11-26 19:14:47">2024-11-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/Graduate-Works/Paper-Read/%E8%AF%BBpaper13-Multi-Agent%E7%9B%98%E7%82%B9/" title="读paper13-Multi-Agent盘点"><img src="/img/cover/38.jpg" onerror='this.onerror=null,this.src="/img/404.webp"' alt="读paper13-Multi-Agent盘点"></a><div class="content"><a class="title" href="/posts/Graduate-Works/Paper-Read/%E8%AF%BBpaper13-Multi-Agent%E7%9B%98%E7%82%B9/" title="读paper13-Multi-Agent盘点">读paper13-Multi-Agent盘点</a><time datetime="2024-11-17T03:13:47.000Z" title="发表于 2024-11-17 11:13:47">2024-11-17</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/Graduate-Works/Course-Notes/%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90%E5%A4%A7%E4%BD%9C%E4%B8%9A-PageRank/" title="数值分析大作业-PageRank"><img src="/img/cover/51.jpg" onerror='this.onerror=null,this.src="/img/404.webp"' alt="数值分析大作业-PageRank"></a><div class="content"><a class="title" href="/posts/Graduate-Works/Course-Notes/%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90%E5%A4%A7%E4%BD%9C%E4%B8%9A-PageRank/" title="数值分析大作业-PageRank">数值分析大作业-PageRank</a><time datetime="2024-11-11T07:40:59.000Z" title="发表于 2024-11-11 15:40:59">2024-11-11</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/Graduate-Works/Course-Notes/%E9%BB%98%E8%AE%A4%E5%8F%82%E6%95%B0%E7%9A%84%E6%9C%80%E4%BC%98%E5%8C%96/" title="默认参数的最优化"><img src="/img/cover/20.jpg" onerror='this.onerror=null,this.src="/img/404.webp"' alt="默认参数的最优化"></a><div class="content"><a class="title" href="/posts/Graduate-Works/Course-Notes/%E9%BB%98%E8%AE%A4%E5%8F%82%E6%95%B0%E7%9A%84%E6%9C%80%E4%BC%98%E5%8C%96/" title="默认参数的最优化">默认参数的最优化</a><time datetime="2024-10-30T02:57:03.000Z" title="发表于 2024-10-30 10:57:03">2024-10-30</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/Graduate-Works/Paper-Read/%E8%AF%BBpaper12-%E9%9D%99%E6%80%81%E8%AD%A6%E6%8A%A5%E8%87%AA%E5%8A%A8%E7%A1%AE%E8%AE%A4%E4%B8%8ELLM%E4%BB%A3%E7%A0%81%E7%94%9F%E6%88%90%E7%9A%84%E6%AD%A3%E7%A1%AE%E6%80%A7%E8%AF%84%E4%BC%B0/" title="读paper12-静态警报自动确认与LLM代码生成的正确性评估"><img src="/img/cover/31.jpg" onerror='this.onerror=null,this.src="/img/404.webp"' alt="读paper12-静态警报自动确认与LLM代码生成的正确性评估"></a><div class="content"><a class="title" href="/posts/Graduate-Works/Paper-Read/%E8%AF%BBpaper12-%E9%9D%99%E6%80%81%E8%AD%A6%E6%8A%A5%E8%87%AA%E5%8A%A8%E7%A1%AE%E8%AE%A4%E4%B8%8ELLM%E4%BB%A3%E7%A0%81%E7%94%9F%E6%88%90%E7%9A%84%E6%AD%A3%E7%A1%AE%E6%80%A7%E8%AF%84%E4%BC%B0/" title="读paper12-静态警报自动确认与LLM代码生成的正确性评估">读paper12-静态警报自动确认与LLM代码生成的正确性评估</a><time datetime="2024-10-28T10:21:10.000Z" title="发表于 2024-10-28 18:21:10">2024-10-28</time></div></div></div></div></div></div></main><footer id="footer" style="background:0 0"></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">简</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span> 数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"></div></div><hr><div class="no-result" id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div><div class="js-pjax" id="rightMenu"><div class="rightMenu-group rightMenu-small"><a class="rightMenu-item" href="javascript:window.history.back();" rel="external nofollow noreferrer"><i class="fa fa-arrow-left"></i></a><a class="rightMenu-item" href="javascript:window.history.forward();" rel="external nofollow noreferrer"><i class="fa fa-arrow-right"></i></a><a class="rightMenu-item" href="javascript:window.location.reload();" rel="external nofollow noreferrer"><i class="fa fa-refresh"></i></a><a class="rightMenu-item" href="javascript:rmf.scrollToTop();" rel="external nofollow noreferrer"><i class="fa fa-arrow-up"></i></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-text"><a class="rightMenu-item" href="javascript:rmf.copySelect();" rel="external nofollow noreferrer"><i class="fa fa-copy"></i><span>复制</span></a><a class="rightMenu-item" href="javascript:window.open(&quot;https://www.google.com/search?q=&quot;+window.getSelection().toString());" rel="external nofollow noreferrer"><i class="iconfont icon-baidu"></i><span>搜索</span></a><a class="rightMenu-item" href="javascript:rmf.searchinThisPage();" rel="external nofollow noreferrer"><i class="fas fa-search"></i><span>站内搜索</span></a><a class="rightMenu-item" href="#post-comment" onclick="rmf.yinyong()"><i class="fa-solid fa-message"></i><span>引用文本评论</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-too"><a class="rightMenu-item" href="javascript:window.open(window.getSelection().toString());window.location.reload();" rel="external nofollow noreferrer"><i class="fa fa-link"></i><span>转到链接</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-paste"><a class="rightMenu-item" href="javascript:rmf.paste()" rel="external nofollow noreferrer"><i class="fa fa-copy"></i><span>粘贴</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-to"><a class="rightMenu-item" href="javascript:rmf.openWithNewTab()" rel="external nofollow noreferrer"><i class="fa fa-window-restore"></i><span>新窗口打开</span></a><a class="rightMenu-item" id="menu-too" href="javascript:rmf.open()" rel="external nofollow noreferrer"><i class="fa fa-link"></i><span>转到链接</span></a><a class="rightMenu-item" href="javascript:rmf.copyLink()" rel="external nofollow noreferrer"><i class="fa fa-copy"></i><span>复制链接</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-img"><a class="rightMenu-item" href="javascript:rmf.saveAs()" rel="external nofollow noreferrer"><i class="fa fa-download"></i><span>保存图片</span></a><a class="rightMenu-item" href="javascript:rmf.openWithNewTab()" rel="external nofollow noreferrer"><i class="fa fa-window-restore"></i><span>在新窗口打开</span></a><a class="rightMenu-item" href="javascript:rmf.click()" rel="external nofollow noreferrer"><i class="fa fa-arrows-alt"></i><span>全屏显示</span></a><a class="rightMenu-item" href="javascript:rmf.copyLink()" rel="external nofollow noreferrer"><i class="fa fa-copy"></i><span>复制图片链接</span></a></div><div class="rightMenu-group rightMenu-line"><a class="rightMenu-item" href="javascript:rmf.switchDarkMode();" rel="external nofollow noreferrer"><i class="fa fa-moon"></i><span>昼夜切换</span></a><a class="rightMenu-item" href="javascript:rmf.translate();" rel="external nofollow noreferrer"><i class="iconfont icon-fanti"></i><span>繁简转换</span></a><a class="rightMenu-item" href="javascript:rmf.switchReadMode();" rel="external nofollow noreferrer"><i class="fa fa-book"></i><span>阅读模式</span></a><a class="rightMenu-item" href="javascript:fullScreen();" rel="external nofollow noreferrer"><i class="fas fa-expand"></i><span>进入全屏</span></a></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://unpkg.com/@fancyapps/ui/dist/fancybox/fancybox.umd.js"></script><script>function panguFn(){"object"==typeof pangu?pangu.autoSpacingPage():getScript("https://unpkg.com/pangu/dist/browser/pangu.min.js").then(()=>{pangu.autoSpacingPage()})}function panguInit(){GLOBAL_CONFIG_SITE.isPost&&panguFn()}document.addEventListener("DOMContentLoaded",panguInit)</script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://unpkg.com/katex/dist/katex.min.css"><script src="https://unpkg.com/katex/dist/contrib/copy-tex.min.js"></script><script>document.querySelectorAll("#article-container span.katex-display").forEach(a=>{btf.wrap(a,"div",{class:"katex-wrap"})})</script><script>function getGiscusTheme(e){return"dark"===e?"dark":"light"}function loadGiscus(){var e,t=Object.assign({src:"https://giscus.app/client.js","data-repo":"ZWN2001/ZWN2001.github.io","data-repo-id":"R_kgDOGH1XWg","data-category-id":"DIC_kwDOGH1XWs4CXnHJ","data-mapping":"pathname","data-theme":getGiscusTheme(document.documentElement.getAttribute("data-theme")),"data-reactions-enabled":"1",crossorigin:"anonymous",async:!0},{"data-lang":"zh-CN","data-loading":"lazy",crossorigin:"anonymous","data-mapping":"og:title","data-input-position":"top","data-category":"Announcements"}),a=document.createElement("script");for(e in t)a.setAttribute(e,t[e]);document.getElementById("giscus-wrap").insertAdjacentElement("afterbegin",a)}function changeGiscusTheme(e){var t;e={setConfig:{theme:getGiscusTheme(e)}},(t=document.querySelector("iframe.giscus-frame"))&&t.contentWindow.postMessage({giscus:e},"https://giscus.app")}function loadOtherComment(){loadGiscus()}btf.addModeChange("giscus",changeGiscusTheme),btf.loadComment(document.getElementById("giscus-wrap"),loadGiscus)</script></div><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.7.1/jquery.min.js"></script><script type="text/javascript" src="/js/rightmenu.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span> 数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"></div></div><hr><div class="no-result" id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div><script data-pjax>var parent,child;document.getElementById("recent-posts")&&"/"===location.pathname&&(parent=document.getElementById("recent-posts"),child='<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="https://zwn2001.space/categories/编程知识/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📚 琉璃月の编程知识 (13)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://zwn2001.space/categories/实用知识/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">💡 琉璃月の实用知识 (10)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://zwn2001.space/categories/学习-课外拓展/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">👩‍💻 琉璃月の学习-课外拓展 (34)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://zwn2001.space/categories/学习-课内知识/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📒 琉璃月の学习-课内知识 (59)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><a class="magnet_link_more"  href="https://zwn2001.space/categories" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>',console.log("已挂载magnet"),parent.insertAdjacentHTML("afterbegin",child))</script><style>#catalog_magnet{flex-wrap:wrap;display:flex;width:100%;justify-content:space-between;padding:10px 10px 0 10px;align-content:flex-start}.magnet_item{flex-basis:calc(50% - 5px);background:#f2f2f2;margin-bottom:10px;border-radius:8px;transition:all .2s ease-in-out}.magnet_item:hover{background:#b30070}.magnet_link_more{color:#555}.magnet_link{color:#000}.magnet_link:hover{color:#fff}@media screen and (max-width:600px){.magnet_item{flex-basis:100%}}.magnet_link_context{display:flex;padding:10px;font-size:16px;transition:all .2s ease-in-out}.magnet_link_context:hover{padding:10px 20px}</style><style></style></body></html>